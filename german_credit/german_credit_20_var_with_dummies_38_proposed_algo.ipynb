{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t3-X-PmYsLsZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ZQgzgbBqsU2E",
        "outputId": "188ceecb-d2bd-4b43-e4df-84f688045931"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-99d72376-207d-4fda-91e1-ac39f3671fa4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-99d72376-207d-4fda-91e1-ac39f3671fa4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving training.csv to training.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2D2qKOGdsYIR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "J-dcXkWVtHMf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(io.BytesIO(uploaded['training.csv']), index_col=0)"
      ],
      "metadata": {
        "id": "SO7m9AkFtJoV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08SIT6R-vyK5",
        "outputId": "24ebb411-9f6e-4919-e0ab-5d62c60b8788"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Creditability'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5RnSN-Otchv",
        "outputId": "7a893444-6f7d-4d68-e2f2-ff60aa42a856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    357\n",
              "1    143\n",
              "Name: Creditability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "UVgmgTCatMJR",
        "outputId": "66c4a933-430f-4bdc-a40e-511349fc86ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8242337-e18e-48fe-b376-26036b2c2db1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8242337-e18e-48fe-b376-26036b2c2db1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(io.BytesIO(uploaded['test.csv']), index_col=0)"
      ],
      "metadata": {
        "id": "qNeLzEcLtOVU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['Creditability'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ1UyqeutUFW",
        "outputId": "6dbb2cd4-d0b8-4e15-eaac-6975aa7f9773"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    343\n",
              "1    157\n",
              "Name: Creditability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-sfrgOYuGVa",
        "outputId": "f2b585b8-842d-4c6f-b93f-7ca46322c770"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.set_option('max_columns',50)\n",
        "pd.set_option('display.max_columns', 50)"
      ],
      "metadata": {
        "id": "yXyWW1BDt8Kd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "oVPErKgZtUhw",
        "outputId": "1e698142-8549-4b63-db0f-e7ac98b7adf6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Creditability  Account.Balance  Duration.of.Credit..month.  \\\n",
              "497              0                3                           6   \n",
              "756              1                1                          15   \n",
              "580              1                1                          42   \n",
              "833              1                3                          36   \n",
              "602              0                3                          24   \n",
              "\n",
              "     Payment.Status.of.Previous.Credit  Purpose  Credit.Amount  \\\n",
              "497                                  2        3           2108   \n",
              "756                                  1        4            950   \n",
              "580                                  2        3           7174   \n",
              "833                                  3        4           7980   \n",
              "602                                  3        2           2028   \n",
              "\n",
              "     Value.Savings.Stocks  Length.of.current.employment  Instalment.per.cent  \\\n",
              "497                     1                             3                    2   \n",
              "756                     1                             4                    4   \n",
              "580                     4                             3                    4   \n",
              "833                     4                             1                    4   \n",
              "602                     1                             3                    2   \n",
              "\n",
              "     Sex...Marital.Status  Guarantors  Duration.in.Current.address  \\\n",
              "497                     3           1                            2   \n",
              "756                     2           1                            3   \n",
              "580                     1           1                            3   \n",
              "833                     2           1                            4   \n",
              "602                     2           1                            2   \n",
              "\n",
              "     Most.valuable.available.asset  Age..years.  Concurrent.Credits  \\\n",
              "497                              1           29                   2   \n",
              "756                              3           33                   2   \n",
              "580                              3           30                   2   \n",
              "833                              3           27                   2   \n",
              "602                              2           30                   2   \n",
              "\n",
              "     Type.of.apartment  No.of.Credits.at.this.Bank  Occupation  \\\n",
              "497                  1                           1           1   \n",
              "756                  1                           2           1   \n",
              "580                  2                           1           1   \n",
              "833                  1                           2           1   \n",
              "602                  2                           2           1   \n",
              "\n",
              "     No.of.dependents  Telephone  Foreign.Worker  \n",
              "497                 1          1               1  \n",
              "756                 2          1               1  \n",
              "580                 1          2               1  \n",
              "833                 1          2               1  \n",
              "602                 1          1               1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e96b6603-fb1f-4102-972c-74e4980b3be2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Creditability</th>\n",
              "      <th>Account.Balance</th>\n",
              "      <th>Duration.of.Credit..month.</th>\n",
              "      <th>Payment.Status.of.Previous.Credit</th>\n",
              "      <th>Purpose</th>\n",
              "      <th>Credit.Amount</th>\n",
              "      <th>Value.Savings.Stocks</th>\n",
              "      <th>Length.of.current.employment</th>\n",
              "      <th>Instalment.per.cent</th>\n",
              "      <th>Sex...Marital.Status</th>\n",
              "      <th>Guarantors</th>\n",
              "      <th>Duration.in.Current.address</th>\n",
              "      <th>Most.valuable.available.asset</th>\n",
              "      <th>Age..years.</th>\n",
              "      <th>Concurrent.Credits</th>\n",
              "      <th>Type.of.apartment</th>\n",
              "      <th>No.of.Credits.at.this.Bank</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>No.of.dependents</th>\n",
              "      <th>Telephone</th>\n",
              "      <th>Foreign.Worker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2108</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>950</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7174</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7980</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2028</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e96b6603-fb1f-4102-972c-74e4980b3be2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e96b6603-fb1f-4102-972c-74e4980b3be2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e96b6603-fb1f-4102-972c-74e4980b3be2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3e7c688b-ea6d-4869-ab12-51e6343875a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e7c688b-ea6d-4869-ab12-51e6343875a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3e7c688b-ea6d-4869-ab12-51e6343875a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "CiK6hNM-tUlb",
        "outputId": "69ac0d47-4ada-4e8d-fbc7-106096bd6f3b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   count      mean          std    min  \\\n",
              "Creditability                      500.0     0.286     0.452342    0.0   \n",
              "Account.Balance                    500.0     2.246     0.806713    1.0   \n",
              "Duration.of.Credit..month.         500.0    21.552    12.321645    4.0   \n",
              "Payment.Status.of.Previous.Credit  500.0     2.336     0.609793    1.0   \n",
              "Purpose                            500.0     2.988     0.974554    1.0   \n",
              "Credit.Amount                      500.0  3242.096  2841.763537  276.0   \n",
              "Value.Savings.Stocks               500.0     1.874     1.198749    1.0   \n",
              "Length.of.current.employment       500.0     2.454     1.090992    1.0   \n",
              "Instalment.per.cent                500.0     2.992     1.118229    1.0   \n",
              "Sex...Marital.Status               500.0     1.746     0.624712    1.0   \n",
              "Guarantors                         500.0     1.088     0.283579    1.0   \n",
              "Duration.in.Current.address        500.0     2.832     1.100089    1.0   \n",
              "Most.valuable.available.asset      500.0     2.378     1.057048    1.0   \n",
              "Age..years.                        500.0    35.458    11.419152   19.0   \n",
              "Concurrent.Credits                 500.0     1.836     0.370646    1.0   \n",
              "Type.of.apartment                  500.0     1.930     0.534482    1.0   \n",
              "No.of.Credits.at.this.Bank         500.0     1.360     0.480481    1.0   \n",
              "Occupation                         500.0     1.000     0.000000    1.0   \n",
              "No.of.dependents                   500.0     1.144     0.351441    1.0   \n",
              "Telephone                          500.0     1.398     0.489976    1.0   \n",
              "Foreign.Worker                     500.0     1.034     0.181411    1.0   \n",
              "\n",
              "                                       25%     50%     75%      max  \n",
              "Creditability                         0.00     0.0     1.0      1.0  \n",
              "Account.Balance                       2.00     2.0     3.0      3.0  \n",
              "Duration.of.Credit..month.           12.00    18.0    24.0     60.0  \n",
              "Payment.Status.of.Previous.Credit     2.00     2.0     3.0      3.0  \n",
              "Purpose                               2.00     3.0     4.0      4.0  \n",
              "Credit.Amount                      1360.75  2243.5  3983.5  18424.0  \n",
              "Value.Savings.Stocks                  1.00     1.0     3.0      4.0  \n",
              "Length.of.current.employment          2.00     2.0     3.0      4.0  \n",
              "Instalment.per.cent                   2.00     3.0     4.0      4.0  \n",
              "Sex...Marital.Status                  1.00     2.0     2.0      3.0  \n",
              "Guarantors                            1.00     1.0     1.0      2.0  \n",
              "Duration.in.Current.address           2.00     3.0     4.0      4.0  \n",
              "Most.valuable.available.asset         1.00     3.0     3.0      4.0  \n",
              "Age..years.                          27.00    33.0    41.0     75.0  \n",
              "Concurrent.Credits                    2.00     2.0     2.0      2.0  \n",
              "Type.of.apartment                     2.00     2.0     2.0      3.0  \n",
              "No.of.Credits.at.this.Bank            1.00     1.0     2.0      2.0  \n",
              "Occupation                            1.00     1.0     1.0      1.0  \n",
              "No.of.dependents                      1.00     1.0     1.0      2.0  \n",
              "Telephone                             1.00     1.0     2.0      2.0  \n",
              "Foreign.Worker                        1.00     1.0     1.0      2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e661973c-1f94-4479-90f1-e66dba13e70a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Creditability</th>\n",
              "      <td>500.0</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.452342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Account.Balance</th>\n",
              "      <td>500.0</td>\n",
              "      <td>2.246</td>\n",
              "      <td>0.806713</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Duration.of.Credit..month.</th>\n",
              "      <td>500.0</td>\n",
              "      <td>21.552</td>\n",
              "      <td>12.321645</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>18.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Payment.Status.of.Previous.Credit</th>\n",
              "      <td>500.0</td>\n",
              "      <td>2.336</td>\n",
              "      <td>0.609793</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Purpose</th>\n",
              "      <td>500.0</td>\n",
              "      <td>2.988</td>\n",
              "      <td>0.974554</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Credit.Amount</th>\n",
              "      <td>500.0</td>\n",
              "      <td>3242.096</td>\n",
              "      <td>2841.763537</td>\n",
              "      <td>276.0</td>\n",
              "      <td>1360.75</td>\n",
              "      <td>2243.5</td>\n",
              "      <td>3983.5</td>\n",
              "      <td>18424.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Value.Savings.Stocks</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.874</td>\n",
              "      <td>1.198749</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Length.of.current.employment</th>\n",
              "      <td>500.0</td>\n",
              "      <td>2.454</td>\n",
              "      <td>1.090992</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Instalment.per.cent</th>\n",
              "      <td>500.0</td>\n",
              "      <td>2.992</td>\n",
              "      <td>1.118229</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex...Marital.Status</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.746</td>\n",
              "      <td>0.624712</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Guarantors</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.088</td>\n",
              "      <td>0.283579</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Duration.in.Current.address</th>\n",
              "      <td>500.0</td>\n",
              "      <td>2.832</td>\n",
              "      <td>1.100089</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Most.valuable.available.asset</th>\n",
              "      <td>500.0</td>\n",
              "      <td>2.378</td>\n",
              "      <td>1.057048</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age..years.</th>\n",
              "      <td>500.0</td>\n",
              "      <td>35.458</td>\n",
              "      <td>11.419152</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.00</td>\n",
              "      <td>33.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Concurrent.Credits</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.836</td>\n",
              "      <td>0.370646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Type.of.apartment</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.930</td>\n",
              "      <td>0.534482</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>No.of.Credits.at.this.Bank</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.360</td>\n",
              "      <td>0.480481</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Occupation</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>No.of.dependents</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.144</td>\n",
              "      <td>0.351441</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Telephone</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.398</td>\n",
              "      <td>0.489976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foreign.Worker</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.034</td>\n",
              "      <td>0.181411</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e661973c-1f94-4479-90f1-e66dba13e70a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e661973c-1f94-4479-90f1-e66dba13e70a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e661973c-1f94-4479-90f1-e66dba13e70a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34b8a4bc-7874-47ea-9400-f94136ec99e3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34b8a4bc-7874-47ea-9400-f94136ec99e3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34b8a4bc-7874-47ea-9400-f94136ec99e3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuPKJpDDtU59",
        "outputId": "05834727-7a6c-4ea6-d374-7e6c602034a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 500 entries, 497 to 385\n",
            "Data columns (total 21 columns):\n",
            " #   Column                             Non-Null Count  Dtype\n",
            "---  ------                             --------------  -----\n",
            " 0   Creditability                      500 non-null    int64\n",
            " 1   Account.Balance                    500 non-null    int64\n",
            " 2   Duration.of.Credit..month.         500 non-null    int64\n",
            " 3   Payment.Status.of.Previous.Credit  500 non-null    int64\n",
            " 4   Purpose                            500 non-null    int64\n",
            " 5   Credit.Amount                      500 non-null    int64\n",
            " 6   Value.Savings.Stocks               500 non-null    int64\n",
            " 7   Length.of.current.employment       500 non-null    int64\n",
            " 8   Instalment.per.cent                500 non-null    int64\n",
            " 9   Sex...Marital.Status               500 non-null    int64\n",
            " 10  Guarantors                         500 non-null    int64\n",
            " 11  Duration.in.Current.address        500 non-null    int64\n",
            " 12  Most.valuable.available.asset      500 non-null    int64\n",
            " 13  Age..years.                        500 non-null    int64\n",
            " 14  Concurrent.Credits                 500 non-null    int64\n",
            " 15  Type.of.apartment                  500 non-null    int64\n",
            " 16  No.of.Credits.at.this.Bank         500 non-null    int64\n",
            " 17  Occupation                         500 non-null    int64\n",
            " 18  No.of.dependents                   500 non-null    int64\n",
            " 19  Telephone                          500 non-null    int64\n",
            " 20  Foreign.Worker                     500 non-null    int64\n",
            "dtypes: int64(21)\n",
            "memory usage: 85.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wsEXsblzrLC",
        "outputId": "077d7912-f274-436e-9adb-dd673caa2881"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 500 entries, 2 to 1000\n",
            "Data columns (total 21 columns):\n",
            " #   Column                             Non-Null Count  Dtype\n",
            "---  ------                             --------------  -----\n",
            " 0   Creditability                      500 non-null    int64\n",
            " 1   Account.Balance                    500 non-null    int64\n",
            " 2   Duration.of.Credit..month.         500 non-null    int64\n",
            " 3   Payment.Status.of.Previous.Credit  500 non-null    int64\n",
            " 4   Purpose                            500 non-null    int64\n",
            " 5   Credit.Amount                      500 non-null    int64\n",
            " 6   Value.Savings.Stocks               500 non-null    int64\n",
            " 7   Length.of.current.employment       500 non-null    int64\n",
            " 8   Instalment.per.cent                500 non-null    int64\n",
            " 9   Sex...Marital.Status               500 non-null    int64\n",
            " 10  Guarantors                         500 non-null    int64\n",
            " 11  Duration.in.Current.address        500 non-null    int64\n",
            " 12  Most.valuable.available.asset      500 non-null    int64\n",
            " 13  Age..years.                        500 non-null    int64\n",
            " 14  Concurrent.Credits                 500 non-null    int64\n",
            " 15  Type.of.apartment                  500 non-null    int64\n",
            " 16  No.of.Credits.at.this.Bank         500 non-null    int64\n",
            " 17  Occupation                         500 non-null    int64\n",
            " 18  No.of.dependents                   500 non-null    int64\n",
            " 19  Telephone                          500 non-null    int64\n",
            " 20  Foreign.Worker                     500 non-null    int64\n",
            "dtypes: int64(21)\n",
            "memory usage: 85.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_up = pd.get_dummies(df_train, columns = ['Account.Balance', 'Payment.Status.of.Previous.Credit','Purpose','Sex...Marital.Status','Guarantors','Most.valuable.available.asset','Concurrent.Credits','Type.of.apartment','Occupation','Foreign.Worker','Telephone'], drop_first=True)\n",
        "#train_up = pd.get_dummies(df_train, columns = ['Account.Balance', 'Payment.Status.of.Previous.Credit','Purpose','Sex...Marital.Status','Guarantors','Most.valuable.available.asset','Concurrent.Credits','Type.of.apartment','Occupation','Foreign.Worker','Telephone'])"
      ],
      "metadata": {
        "id": "QOhK4ryxzxJZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_up.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFOXxO0l0Mun",
        "outputId": "e2248868-96b5-4d5e-b32f-abe14a2096cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_up = pd.get_dummies(df_test, columns = ['Account.Balance', 'Payment.Status.of.Previous.Credit','Purpose','Sex...Marital.Status','Guarantors','Most.valuable.available.asset','Concurrent.Credits','Type.of.apartment','Occupation','Foreign.Worker','Telephone'], drop_first=True)\n",
        "#test_up = pd.get_dummies(df_test, columns = ['Account.Balance', 'Payment.Status.of.Previous.Credit','Purpose','Sex...Marital.Status','Guarantors','Most.valuable.available.asset','Concurrent.Credits','Type.of.apartment','Occupation','Foreign.Worker','Telephone'])"
      ],
      "metadata": {
        "id": "aFreRYw10Xms"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_up.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SeYF3C80rg9",
        "outputId": "826e6ee9-f266-4759-d878-1f56dbb8d58f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_up.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8OczarQ0tlk",
        "outputId": "1e1ac998-c727-47b9-eb0b-f2c72fde745f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 500 entries, 497 to 385\n",
            "Data columns (total 28 columns):\n",
            " #   Column                               Non-Null Count  Dtype\n",
            "---  ------                               --------------  -----\n",
            " 0   Creditability                        500 non-null    int64\n",
            " 1   Duration.of.Credit..month.           500 non-null    int64\n",
            " 2   Credit.Amount                        500 non-null    int64\n",
            " 3   Value.Savings.Stocks                 500 non-null    int64\n",
            " 4   Length.of.current.employment         500 non-null    int64\n",
            " 5   Instalment.per.cent                  500 non-null    int64\n",
            " 6   Duration.in.Current.address          500 non-null    int64\n",
            " 7   Age..years.                          500 non-null    int64\n",
            " 8   No.of.Credits.at.this.Bank           500 non-null    int64\n",
            " 9   No.of.dependents                     500 non-null    int64\n",
            " 10  Account.Balance_2                    500 non-null    uint8\n",
            " 11  Account.Balance_3                    500 non-null    uint8\n",
            " 12  Payment.Status.of.Previous.Credit_2  500 non-null    uint8\n",
            " 13  Payment.Status.of.Previous.Credit_3  500 non-null    uint8\n",
            " 14  Purpose_2                            500 non-null    uint8\n",
            " 15  Purpose_3                            500 non-null    uint8\n",
            " 16  Purpose_4                            500 non-null    uint8\n",
            " 17  Sex...Marital.Status_2               500 non-null    uint8\n",
            " 18  Sex...Marital.Status_3               500 non-null    uint8\n",
            " 19  Guarantors_2                         500 non-null    uint8\n",
            " 20  Most.valuable.available.asset_2      500 non-null    uint8\n",
            " 21  Most.valuable.available.asset_3      500 non-null    uint8\n",
            " 22  Most.valuable.available.asset_4      500 non-null    uint8\n",
            " 23  Concurrent.Credits_2                 500 non-null    uint8\n",
            " 24  Type.of.apartment_2                  500 non-null    uint8\n",
            " 25  Type.of.apartment_3                  500 non-null    uint8\n",
            " 26  Foreign.Worker_2                     500 non-null    uint8\n",
            " 27  Telephone_2                          500 non-null    uint8\n",
            "dtypes: int64(10), uint8(18)\n",
            "memory usage: 51.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "cWtqbEk6017O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_non_dominated_sort(data):\n",
        "    # create a list to hold the fronts\n",
        "    fronts = []\n",
        "    fronts_ = []\n",
        "    # create a list to hold the domination counts for each data point\n",
        "    domination_counts = [0] * len(data)\n",
        "    # create a list to hold the domination lists for each data point\n",
        "    domination_lists = [[] for _ in range(len(data))]\n",
        "    # create a list to hold the ranks of each data point\n",
        "    ranks = [0] * len(data)\n",
        "    # loop over each data point\n",
        "    for i in range(len(data)):\n",
        "        # loop over each data point after i\n",
        "        for j in range(i+1, len(data)):\n",
        "            # compare the two data points\n",
        "            if data[i][0] <= data[j][0] and data[i][1] <= data[j][1]:\n",
        "                domination_counts[j] += 1\n",
        "                domination_lists[i].append(j)\n",
        "            elif data[i][0] >= data[j][0] and data[i][1] >= data[j][1]:\n",
        "                domination_counts[i] += 1\n",
        "                domination_lists[j].append(i)\n",
        "    # create a list of points with domination count 0\n",
        "    S = [i for i in range(len(data)) if domination_counts[i] == 0]\n",
        "    S_ = [data[i] for i in range(len(data)) if domination_counts[i] == 0]\n",
        "    # create the first front\n",
        "    fronts.append(S)\n",
        "    #print(data)\n",
        "    #print(S)\n",
        "    fronts_.append(S_)\n",
        "    # loop until the S list is empty\n",
        "    while S:\n",
        "        Q = []\n",
        "        Q_=[]\n",
        "        # loop over each data point in S\n",
        "        for i in S:\n",
        "            # set the rank of the data point\n",
        "            ranks[i] = len(fronts)\n",
        "            # loop over each dominated data point\n",
        "            for j in domination_lists[i]:\n",
        "                domination_counts[j] -= 1\n",
        "                if domination_counts[j] == 0:\n",
        "                    Q.append(j)\n",
        "                    Q_.append(data[j])\n",
        "        # add the next front to the fronts list\n",
        "        fronts.append(Q)\n",
        "        fronts_.append(Q_)\n",
        "        # set S to the next front\n",
        "        S = Q\n",
        "    # return the fronts\n",
        "    return fronts, fronts_\n"
      ],
      "metadata": {
        "id": "VPu0UmY6hfgJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NON DOMINATED SORTING STARTS\n",
        "import numpy as np\n",
        "import math\n",
        "import collections\n",
        "import bisect\n",
        "\n",
        "def dominance_check_between_two_points (point1, point2):\n",
        "\n",
        "    import numpy as np\n",
        "    import math\n",
        "    import collections\n",
        "    import bisect\n",
        "\n",
        "\n",
        "    CP=point1\n",
        "    FP=point2\n",
        "    #print(CP)\n",
        "    #print(point)\n",
        "\n",
        "    CP_dominates_FP=False\n",
        "    FP_dominates_CP=False\n",
        "    CP_and_FP_are_nondominating = False\n",
        "\n",
        "\n",
        "    for i in range(len(CP)):\n",
        "        if(CP[i]<=FP[i]):\n",
        "            CP_better_than_or_equal_FP = True\n",
        "            continue\n",
        "        else:\n",
        "            CP_better_than_or_equal_FP = False\n",
        "            break\n",
        "\n",
        "    if (CP_better_than_or_equal_FP == True):\n",
        "        for i in range(len(CP)):\n",
        "            if(CP[i]==FP[i]):\n",
        "                continue\n",
        "            else:\n",
        "                CP_dominates_FP = True\n",
        "\n",
        "    ###########################################\n",
        "    for i in range(len(CP)):\n",
        "        if(FP[i]<=CP[i]):\n",
        "            FP_better_than_or_equal_CP = True\n",
        "            continue\n",
        "        else:\n",
        "            FP_better_than_or_equal_CP = False\n",
        "            break\n",
        "\n",
        "    if (FP_better_than_or_equal_CP == True):\n",
        "        for i in range(len(CP)):\n",
        "            if(FP[i] == CP[i]):\n",
        "                continue\n",
        "            else:\n",
        "                FP_dominates_CP = True\n",
        "\n",
        "    if(CP_dominates_FP == False and FP_dominates_CP==False):\n",
        "        CP_and_FP_are_nondominating = True\n",
        "\n",
        "    #print( \"CP_dominates_FP :\" + str(CP_dominates_FP))\n",
        "    #print(\"FP_dominates_CP :\" + str(FP_dominates_CP))\n",
        "    #print(\"CP_and_FP_are_nondominating :\" + str(CP_and_FP_are_nondominating))\n",
        "\n",
        "    return FP_dominates_CP, CP_dominates_FP,  CP_and_FP_are_nondominating\n",
        "\n",
        "#For insert in sorted list\n",
        "def insert(list, n):\n",
        "    import bisect\n",
        "    bisect.insort(list, n)\n",
        "    return list\n",
        "\n",
        "def non_dominated_sorting(Input_list_to_be_sorted):\n",
        "\n",
        "    import numpy as np\n",
        "    import math\n",
        "    import collections\n",
        "    import bisect\n",
        "\n",
        "    Input_list = Input_list_to_be_sorted\n",
        "    M = len(Input_list[0])\n",
        "    #print(M)\n",
        "    Input_array = np.array(Input_list)\n",
        "\n",
        "    #For first point of population P\n",
        "    first_point_of_population = Input_array[0]\n",
        "\n",
        "    #Initialize the list \"Front_keys_list\" with first key\n",
        "    Front_keys_list = [1]\n",
        "\n",
        "    #Initia lize the Dictinory \"D\" for first point.\n",
        "    D={Front_keys_list[0]:[list(first_point_of_population)]}\n",
        "    #D={Front_keys_list[0]:[first_point_of_population]}\n",
        "\n",
        "    Counter=0\n",
        "    for point in Input_array[1:]:\n",
        "        #print(\"Current point under consideration\")\n",
        "        #print(point)\n",
        "\n",
        "        CP = point.copy()\n",
        "        current_point_assigned_flag=False\n",
        "\n",
        "        #Largest_value_in_Front_keys_list = max(Front_keys_list)\n",
        "        #Smallest_value_in_Front_keys_list = min(Front_keys_list)\n",
        "\n",
        "        Highest_key_dominated_by_CP = max(Front_keys_list)+1\n",
        "        Highest_key_dominating_to_CP = min(Front_keys_list) - 1\n",
        "\n",
        "        #for key in Front_keys_list[::-1]:\n",
        "        for key in Front_keys_list[:]:\n",
        "            if(key<Highest_key_dominated_by_CP and key>Highest_key_dominating_to_CP):\n",
        "                j=len(D[key])\n",
        "                if(current_point_assigned_flag==False):\n",
        "                    #for point in D[key][::-1]:\n",
        "                    for point in D[key][:]:\n",
        "                        if(current_point_assigned_flag==False):\n",
        "\n",
        "                            #j=len(D[key])\n",
        "                            #last_index=j-1\n",
        "                            #len_of_front= len(D[key])\n",
        "                            #print(j)\n",
        "\n",
        "                            while(j > 0 and current_point_assigned_flag==False):\n",
        "\n",
        "                                #Highest_key_dominated_by_CP = min(Front_keys_list)-1\n",
        "                                #Highest_key_dominating_to_CP = max(Front_keys_list)+1\n",
        "                                result_of_dominance_check = dominance_check_between_two_points(point1=CP, point2=point)\n",
        "                                Counter += 1\n",
        "\n",
        "                                if (result_of_dominance_check[0]==True): # FP_dominates_CP\n",
        "                                    Highest_key_dominated_by_CP = Highest_key_dominated_by_CP\n",
        "                                    Highest_key_dominating_to_CP = max(key, Highest_key_dominating_to_CP)\n",
        "                                    #Break for loop and jump to the next key\n",
        "                                    j = -1 #This condition will Break the while loop during next comparison\n",
        "\n",
        "                                elif (result_of_dominance_check[1]==True): # CP_dominates_FP\n",
        "                                    Highest_key_dominated_by_CP = min(key,Highest_key_dominated_by_CP)\n",
        "                                    Highest_key_dominating_to_CP = Highest_key_dominating_to_CP\n",
        "                                    #Break for loop and jump to the next key\n",
        "                                    j = -1 #This condition will Break the while loop during next comparison\n",
        "\n",
        "                                elif (result_of_dominance_check[2]==True): #CP_and_FP_are_nondominating\n",
        "                                    #check with next point from current front\n",
        "                                    if(j==1):\n",
        "                                        D[key].append(list(CP))\n",
        "                                        current_point_assigned_flag=True\n",
        "                                j = j-1\n",
        "\n",
        "        if(current_point_assigned_flag==False):\n",
        "            if ( Highest_key_dominated_by_CP > max(Front_keys_list)):\n",
        "                new_key = max(Front_keys_list)+1\n",
        "                #Front_keys_list.append(new_key)\n",
        "                Front_keys_list=insert(Front_keys_list, new_key)\n",
        "                D[new_key] = [list(CP)]\n",
        "                #D[new_key] = [CP]\n",
        "                current_point_assigned_flag=True\n",
        "\n",
        "                #Largest_value_in_Front_keys_list = max(Front_keys_list)\n",
        "                #Smallest_value_in_Front_keys_list = min(Front_keys_list)\n",
        "\n",
        "            elif (Highest_key_dominating_to_CP < min(Front_keys_list)):\n",
        "                new_key = min(Front_keys_list)-1\n",
        "                #Front_keys_list.append(new_key)\n",
        "                Front_keys_list=insert(Front_keys_list, new_key)\n",
        "                D[new_key] = [list(CP)]\n",
        "                #D[new_key] = [CP]\n",
        "                current_point_assigned_flag=True\n",
        "\n",
        "                #Largest_value_in_Front_keys_list = max(Front_keys_list)\n",
        "                #Smallest_value_in_Front_keys_list = min(Front_keys_list)\n",
        "\n",
        "            else:\n",
        "                new_key = (Highest_key_dominated_by_CP + Highest_key_dominating_to_CP) / 2\n",
        "                #Front_keys_list.append(new_key)\n",
        "                Front_keys_list=insert(Front_keys_list, new_key)\n",
        "                D[new_key] = [list(CP)]\n",
        "                #D[new_key] = [CP]\n",
        "                current_point_assigned_flag=True\n",
        "\n",
        "                #Largest_value_in_Front_keys_list = max(Front_keys_list)\n",
        "                #Smallest_value_in_Front_keys_list = min(Front_keys_list)\n",
        "\n",
        "    od = collections.OrderedDict(sorted(D.items()))\n",
        "    #od\n",
        "\n",
        "    smallest_key = min(Front_keys_list)\n",
        "\n",
        "    #print(D)\n",
        "    #print(od)\n",
        "    return od, smallest_key\n"
      ],
      "metadata": {
        "id": "D6OZAz-6DRG9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_up_without_target = train_up.drop('Creditability',axis='columns')\n",
        "test_up_without_target = test_up.drop('Creditability',axis='columns')"
      ],
      "metadata": {
        "id": "mJ4148iwDUv6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_up_without_target.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XPSJVDgyQsf",
        "outputId": "1df5c8eb-8195-4dee-bf88-97db2c4f76ed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Duration.of.Credit..month.', 'Credit.Amount', 'Value.Savings.Stocks',\n",
              "       'Length.of.current.employment', 'Instalment.per.cent',\n",
              "       'Duration.in.Current.address', 'Age..years.',\n",
              "       'No.of.Credits.at.this.Bank', 'No.of.dependents', 'Account.Balance_2',\n",
              "       'Account.Balance_3', 'Payment.Status.of.Previous.Credit_2',\n",
              "       'Payment.Status.of.Previous.Credit_3', 'Purpose_2', 'Purpose_3',\n",
              "       'Purpose_4', 'Sex...Marital.Status_2', 'Sex...Marital.Status_3',\n",
              "       'Guarantors_2', 'Most.valuable.available.asset_2',\n",
              "       'Most.valuable.available.asset_3', 'Most.valuable.available.asset_4',\n",
              "       'Concurrent.Credits_2', 'Type.of.apartment_2', 'Type.of.apartment_3',\n",
              "       'Foreign.Worker_2', 'Telephone_2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_up_without_target.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "NJE3WJiFyqZZ",
        "outputId": "098d7570-8232-4106-c145-cb8339eb5260"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Duration.of.Credit..month.  Credit.Amount  Value.Savings.Stocks  \\\n",
              "497                           6           2108                     1   \n",
              "756                          15            950                     1   \n",
              "580                          42           7174                     4   \n",
              "833                          36           7980                     4   \n",
              "602                          24           2028                     1   \n",
              "\n",
              "     Length.of.current.employment  Instalment.per.cent  \\\n",
              "497                             3                    2   \n",
              "756                             4                    4   \n",
              "580                             3                    4   \n",
              "833                             1                    4   \n",
              "602                             3                    2   \n",
              "\n",
              "     Duration.in.Current.address  Age..years.  No.of.Credits.at.this.Bank  \\\n",
              "497                            2           29                           1   \n",
              "756                            3           33                           2   \n",
              "580                            3           30                           1   \n",
              "833                            4           27                           2   \n",
              "602                            2           30                           2   \n",
              "\n",
              "     No.of.dependents  Account.Balance_2  Account.Balance_3  \\\n",
              "497                 1                  0                  1   \n",
              "756                 2                  0                  0   \n",
              "580                 1                  0                  0   \n",
              "833                 1                  0                  1   \n",
              "602                 1                  0                  1   \n",
              "\n",
              "     Payment.Status.of.Previous.Credit_2  Payment.Status.of.Previous.Credit_3  \\\n",
              "497                                    1                                    0   \n",
              "756                                    0                                    0   \n",
              "580                                    1                                    0   \n",
              "833                                    0                                    1   \n",
              "602                                    0                                    1   \n",
              "\n",
              "     Purpose_2  Purpose_3  Purpose_4  Sex...Marital.Status_2  \\\n",
              "497          0          1          0                       0   \n",
              "756          0          0          1                       1   \n",
              "580          0          1          0                       0   \n",
              "833          0          0          1                       1   \n",
              "602          1          0          0                       1   \n",
              "\n",
              "     Sex...Marital.Status_3  Guarantors_2  Most.valuable.available.asset_2  \\\n",
              "497                       1             0                                0   \n",
              "756                       0             0                                0   \n",
              "580                       0             0                                0   \n",
              "833                       0             0                                0   \n",
              "602                       0             0                                1   \n",
              "\n",
              "     Most.valuable.available.asset_3  Most.valuable.available.asset_4  \\\n",
              "497                                0                                0   \n",
              "756                                1                                0   \n",
              "580                                1                                0   \n",
              "833                                1                                0   \n",
              "602                                0                                0   \n",
              "\n",
              "     Concurrent.Credits_2  Type.of.apartment_2  Type.of.apartment_3  \\\n",
              "497                     1                    0                    0   \n",
              "756                     1                    0                    0   \n",
              "580                     1                    1                    0   \n",
              "833                     1                    0                    0   \n",
              "602                     1                    1                    0   \n",
              "\n",
              "     Foreign.Worker_2  Telephone_2  \n",
              "497                 0            0  \n",
              "756                 0            0  \n",
              "580                 0            1  \n",
              "833                 0            1  \n",
              "602                 0            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94b27f6f-8f03-466a-8309-ac335ed92997\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration.of.Credit..month.</th>\n",
              "      <th>Credit.Amount</th>\n",
              "      <th>Value.Savings.Stocks</th>\n",
              "      <th>Length.of.current.employment</th>\n",
              "      <th>Instalment.per.cent</th>\n",
              "      <th>Duration.in.Current.address</th>\n",
              "      <th>Age..years.</th>\n",
              "      <th>No.of.Credits.at.this.Bank</th>\n",
              "      <th>No.of.dependents</th>\n",
              "      <th>Account.Balance_2</th>\n",
              "      <th>Account.Balance_3</th>\n",
              "      <th>Payment.Status.of.Previous.Credit_2</th>\n",
              "      <th>Payment.Status.of.Previous.Credit_3</th>\n",
              "      <th>Purpose_2</th>\n",
              "      <th>Purpose_3</th>\n",
              "      <th>Purpose_4</th>\n",
              "      <th>Sex...Marital.Status_2</th>\n",
              "      <th>Sex...Marital.Status_3</th>\n",
              "      <th>Guarantors_2</th>\n",
              "      <th>Most.valuable.available.asset_2</th>\n",
              "      <th>Most.valuable.available.asset_3</th>\n",
              "      <th>Most.valuable.available.asset_4</th>\n",
              "      <th>Concurrent.Credits_2</th>\n",
              "      <th>Type.of.apartment_2</th>\n",
              "      <th>Type.of.apartment_3</th>\n",
              "      <th>Foreign.Worker_2</th>\n",
              "      <th>Telephone_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>6</td>\n",
              "      <td>2108</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>15</td>\n",
              "      <td>950</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>42</td>\n",
              "      <td>7174</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>36</td>\n",
              "      <td>7980</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>24</td>\n",
              "      <td>2028</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94b27f6f-8f03-466a-8309-ac335ed92997')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94b27f6f-8f03-466a-8309-ac335ed92997 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94b27f6f-8f03-466a-8309-ac335ed92997');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c32e15db-1103-4719-8f64-88f83a2ca40c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c32e15db-1103-4719-8f64-88f83a2ca40c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c32e15db-1103-4719-8f64-88f83a2ca40c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_up_without_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Are2Rn0-DfaM",
        "outputId": "f75524c2-8df5-4a3a-f6df-952580b3093c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_up['Creditability'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoxAO5NxJPwN",
        "outputId": "ce51bc55-6284-412c-9133-c42ba46c047d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    357\n",
              "1    143\n",
              "Name: Creditability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_up_without_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxyXGy2LD9Yc",
        "outputId": "ffd583fb-b02a-45c7-ca43-eeafb36a03ed"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_up['Creditability'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbt_mX_JJaVH",
        "outputId": "cda298c3-dc08-4f2e-fc24-4e2284e0c8a4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    343\n",
              "1    157\n",
              "Name: Creditability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Calculate_f1_for_X_rn(dataset_train,target_train,dataset_test, target_test, X_rn):\n",
        "    from sklearn.model_selection import train_test_split # train test split\n",
        "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "    #from sklearn.metrics import plot_precision_recall_curve\n",
        "    #from scikitplot.metrics import plot_precision_recall as plot_precision_recall_curve\n",
        "\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "    #print(P_0[X_r1], P_0[X_r2], P_0[X_r3])\n",
        "\n",
        "    #X=dataset\n",
        "    #y=target\n",
        "    X_r=X_rn\n",
        "    data_tr=dataset_train\n",
        "\n",
        "    feature_set=[]\n",
        "    for i in range(len(X_r)):\n",
        "        #print(i)\n",
        "        if X_r[i]==1:\n",
        "            feature_set.append(data_tr.columns[i])\n",
        "   # print(feature_set)\n",
        "    if(len(feature_set)==0):\n",
        "        num_feature = 0\n",
        "        f1_score = 0\n",
        "    else:\n",
        "        X_=dataset_train[feature_set]\n",
        "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "        #X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.8, random_state=42)\n",
        "\n",
        "        # we'll use xgbclassifier for noe\n",
        "        from xgboost import XGBClassifier\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "        X_train = dataset_train[feature_set]\n",
        "        X_test = dataset_test[feature_set]\n",
        "        y_train = target_train\n",
        "        y_test = target_test\n",
        "\n",
        "        #Decision Tree Classifier\n",
        "        #model=DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        num_feature=len(feature_set)\n",
        "        f1_score=f1_score(y_test, y_pred) * -1 #this is to make it minimization problem\n",
        "        #roc_auc_score = roc_auc_score(y, y_proba)\n",
        "\n",
        "        print(\"f1_score is \" +str(f1_score))\n",
        "        score = accuracy_score(y_test, y_pred)\n",
        "        accuracy_score = score\n",
        "        print(\"accuracy is \" + str(score))\n",
        "        print(\"error rate is \" + str(1-score))\n",
        "        error_rate = 1-score\n",
        "        print(\"roc_auc_score is \" + str(roc_auc_score(y_test, y_pred)))\n",
        "        print(\"gini is \" + str((2*roc_auc_score(y_test, y_pred))-1))\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    #print(num_feature)\n",
        "    #print(f1_score)\n",
        "\n",
        "    #return X_r, num_feature, f1_score\n",
        "    return X_r, num_feature, error_rate"
      ],
      "metadata": {
        "id": "gYKGUvN2D9dJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_r,a,b=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\n",
        "print(X_r)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1DZB3rnIsX6",
        "outputId": "35c1bdbd-c0ef-44ef-ba3e-39d9af42697d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score is -0.4982935153583618\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6406473417392435\n",
            "gini is 0.2812946834784871\n",
            "[[280  63]\n",
            " [ 84  73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.82      0.79       343\n",
            "           1       0.54      0.46      0.50       157\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.64      0.65       500\n",
            "weighted avg       0.70      0.71      0.70       500\n",
            "\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "27\n",
            "0.29400000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def OPS(S,optimal_sol):\n",
        "    #pass\n",
        "    import random\n",
        "    N=len(S)\n",
        "    ref = random.sample(range(0, N), 1)\n",
        "    ref=ref[0]\n",
        "    print(ref)\n",
        "\n",
        "    #Step 1: Randomly select a solution from S t , and set it as the reference solution, X re f = ( x re f, 1 , x re f, 2 , ..., x re f,D ) ;\n",
        "    X_ref = S[ref]\n",
        "\n",
        "    #Step 2: Randomly select two feature bits, u 1 and u 2 , from X ref , satisfying x re f, u 1 = 1 and x re f, u 2 = 0 ;\n",
        "    n=len(X_ref)\n",
        "\n",
        "    #Need to put ONE BYPASS CONDITION in case of all 1 or all zero\n",
        "\n",
        "    for i in range(n):\n",
        "      u1 = random.sample(range(0, n), 1)\n",
        "      u1=u1[0]\n",
        "      if X_ref[u1] == 1:\n",
        "        break\n",
        "      else:\n",
        "        continue\n",
        "    print(u1)\n",
        "\n",
        "    for i in range(n):\n",
        "      u2 = random.sample(range(0, n), 1)\n",
        "      u2=u2[0]\n",
        "      if X_ref[u2] == 0:\n",
        "        break\n",
        "      else:\n",
        "        continue\n",
        "    print(u2)\n",
        "\n",
        "    #Step 3: Judge the relative importance between the two feature bits u 1 and u 2 ;\n",
        "    X_ref_by_making_u1_equals_0 = X_ref.copy()\n",
        "    X_ref_by_making_u1_equals_0[u1] = 0\n",
        "    print(X_ref_by_making_u1_equals_0)\n",
        "\n",
        "    X_ref_by_making_u1_0_and_u2_equals_1 = X_ref_by_making_u1_equals_0.copy()\n",
        "    X_ref_by_making_u1_0_and_u2_equals_1[u2]=1\n",
        "    print(X_ref_by_making_u1_0_and_u2_equals_1)\n",
        "\n",
        "\n",
        "    X_ref, num_feature_ref, err_ref=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=X_ref)\n",
        "    X_u1,  num_feature_u1,  err_u1 =Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=X_ref_by_making_u1_equals_0)\n",
        "    X_u2,  num_feature_u2,  err_u2 =Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=X_ref_by_making_u1_0_and_u2_equals_1)\n",
        "\n",
        "    temp1= err_u1-err_ref\n",
        "    temp2=err_u1-err_u2\n",
        "    print(temp1)\n",
        "    print(temp2)\n",
        "    print(temp1-temp2)\n",
        "\n",
        "    X_h = optimal_sol\n",
        "    X_h_hat = X_h.copy()\n",
        "\n",
        "    if(abs(err_u1-err_ref) > abs(err_u1-err_u2)):\n",
        "      X_ref1 = X_ref.copy()\n",
        "      #This is within if condition, as this will execute only when u1 is imp than u2\n",
        "      #Step 4: For an optimal solution, X h  S t , do\n",
        "      if(X_h[u1]==1 and X_h[u2]==1):\n",
        "        X_h_hat[u2]=0\n",
        "      elif(X_h[u1]==0 and X_h[u2]==0):\n",
        "        X_h_hat[u1]=1\n",
        "      elif(X_h[u1]==1 and X_h[u2]==0):\n",
        "        X_h_hat[u1]=0\n",
        "      else:\n",
        "        X_h_hat[u1]=1\n",
        "        X_h_hat[u2]=0\n",
        "\n",
        "    X_h, num_feature_h, err_h=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=X_h)\n",
        "    X_h_hat, num_feature_h_hat, err_h_hat=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=X_h_hat)\n",
        "\n",
        "    hhat_dominates_h, h_dominates_hhat, h_and_hhat_are_nondominating = dominance_check_between_two_points(point1=[num_feature_h, err_h], point2=[num_feature_h_hat, err_h_hat])\n",
        "    print(err_h)\n",
        "    print(err_h_hat)\n",
        "    print(hhat_dominates_h, h_dominates_hhat, h_and_hhat_are_nondominating)\n",
        "\n",
        "    if(hhat_dominates_h): #Focusses on both objective\n",
        "    #if(err_h_hat < err_h): #Instead of 2 objective, here we focusses just on error rate\n",
        "      print(\"population Pt saves Xhhat to replace Xh\")\n",
        "    elif (h_dominates_hhat): #Focusses on both objective\n",
        "    #elif(err_h < err_h_hat): #Instead of 2 objective, here we focusses just on error rate\n",
        "      print(\"opulation keeps X h unchanged\")\n",
        "    else:\n",
        "      print(\"it saves both Xh and Xhhat into Pt\")\n",
        "\n",
        "    print(\"X_h is: \")\n",
        "    print(X_h)\n",
        "\n",
        "    print(\"X_h_hat is: \")\n",
        "    print(X_h_hat)\n",
        "  #Step 5: If the size of P t is larger than N, remove | P t |  Nindividuals with high ranks, and reduce the crowding distances from P t using the method in Section 5.3 ;\n",
        "  #Step 6: Output population P t"
      ],
      "metadata": {
        "id": "xSFr3VdlEAvP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPS(S=[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],[1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]], optimal_sol=[1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVj0l-XJEA0o",
        "outputId": "7afd2474-5636-4337-a553-f7a4505df387"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "16\n",
            "[1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "[1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.3383458646616541\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.5500176412694285\n",
            "gini is 0.10003528253885707\n",
            "[[279  64]\n",
            " [112  45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76       343\n",
            "           1       0.41      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.56      0.55      0.55       500\n",
            "weighted avg       0.62      0.65      0.63       500\n",
            "\n",
            "f1_score is -0.2713178294573643\n",
            "accuracy is 0.624\n",
            "error rate is 0.376\n",
            "roc_auc_score is 0.515255055616423\n",
            "gini is 0.030510111232846082\n",
            "[[277  66]\n",
            " [122  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.81      0.75       343\n",
            "           1       0.35      0.22      0.27       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.52      0.52      0.51       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "f1_score is -0.26459143968871596\n",
            "accuracy is 0.622\n",
            "error rate is 0.378\n",
            "roc_auc_score is 0.5120703422406269\n",
            "gini is 0.024140684481253727\n",
            "[[277  66]\n",
            " [123  34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.81      0.75       343\n",
            "           1       0.34      0.22      0.26       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.52      0.51      0.51       500\n",
            "weighted avg       0.58      0.62      0.59       500\n",
            "\n",
            "0.02400000000000002\n",
            "-0.0020000000000000018\n",
            "0.026000000000000023\n",
            "f1_score is -0.3383458646616541\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.5500176412694285\n",
            "gini is 0.10003528253885707\n",
            "[[279  64]\n",
            " [112  45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76       343\n",
            "           1       0.41      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.56      0.55      0.55       500\n",
            "weighted avg       0.62      0.65      0.63       500\n",
            "\n",
            "f1_score is -0.2713178294573643\n",
            "accuracy is 0.624\n",
            "error rate is 0.376\n",
            "roc_auc_score is 0.515255055616423\n",
            "gini is 0.030510111232846082\n",
            "[[277  66]\n",
            " [122  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.81      0.75       343\n",
            "           1       0.35      0.22      0.27       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.52      0.52      0.51       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "0.352\n",
            "0.376\n",
            "False False True\n",
            "it saves both Xh and Xhhat into Pt\n",
            "X_h is: \n",
            "[1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "X_h_hat is: \n",
            "[1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MOFS(dataset_train,target_train,dataset_test, target_test ,initial_population):\n",
        "    #Step 1: Initialize a number of individuals, P0 = {X1, X2, ..., XN}T\n",
        "    #P_0=[[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
        "    #P_0=[[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
        "    #P_0 = [[0,0,1,0,1,0,0,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1],\n",
        "    #           [0,0,1,0,0,0,0,1,1,0,0,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,1,1],\n",
        "    #           [1,0,1,0,1,0,1,1,1,1,0,0,0,0,1,1,1,0,0,1,1,1,0,1,1,0,0,1,1,1],\n",
        "    #           [0,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,0,0,1,1,0,1,0,1,0,1,0,1,1,1],\n",
        "    #           [0,0,1,0,1,0,0,0,1,1,0,0,1,0,1,1,0,0,0,1,1,0,0,1,0,1,0,1,1,1],\n",
        "    #          ]\n",
        "    P_0 = initial_population\n",
        "\n",
        "\n",
        "\n",
        "    #Step 2: Let t = 0. //Iteration steps\n",
        "    t=0\n",
        "\n",
        "    #Step 3: Iteration\n",
        "    P_t_plus_1 = []\n",
        "    #P_t_plus_1_fitness = []\n",
        "    P_t_plus_1_vector_fitness = []\n",
        "    P_t_plus_1_vector = []\n",
        "    P_t_plus_1_fitness = []\n",
        "    round_robin_flag = 0\n",
        "\n",
        "    N=len(P_0)\n",
        "\n",
        "    for i in range(1,N+1):\n",
        "        #Step 3.1: Randomly select three vectors from the population Pt, denoted as\n",
        "        # Xr1(t),Xr2(t), and Xr3(t), r1 \u0005= r2 \u0005= r3 \u0005= i;\n",
        "        #print(random.randint(0,9))\n",
        "        r1, r2, r3 = random.sample(range(0, N), 3)\n",
        "        print(r1, r2, r3)\n",
        "        print(P_0[r1], P_0[r2], P_0[r3])\n",
        "\n",
        "        #Step 3.2: Select the best one from the three vectors as the base vector,Xbest(t);\n",
        "        X_r1, num_feature_r1, f1_score_r1=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=P_0[r1])\n",
        "        X_r2, num_feature_r2, f1_score_r2=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=P_0[r2])\n",
        "        X_r3, num_feature_r3, f1_score_r3=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=P_0[r3])\n",
        "\n",
        "        #Dict_vector_cardinality_accuracy = {X_r1:[num_feature_r1, f1_score_r1], X_r2:[num_feature_r2, f1_score_r2], X_r3:[num_feature_r3, f1_score_r3]}\n",
        "        Dict_vector_cardinality_accuracy = {(num_feature_r1, f1_score_r1):X_r1, (num_feature_r2, f1_score_r2):X_r2, (num_feature_r3, f1_score_r3):X_r3}\n",
        "\n",
        "        #num_feature_and_accuracy_for_3_candidate_sol = [[num_feature_r1, f1_score_r1],[num_feature_r2, f1_score_r2],[num_feature_r3, f1_score_r3]]\n",
        "        num_feature_and_accuracy_for_3_candidate_sol = [[num_feature_r1, f1_score_r1],[num_feature_r2, f1_score_r2],[num_feature_r3, f1_score_r3]]\n",
        "\n",
        "        print(num_feature_r1)\n",
        "        print(num_feature_r1)\n",
        "        print(num_feature_and_accuracy_for_3_candidate_sol)\n",
        "        print(type(num_feature_and_accuracy_for_3_candidate_sol))\n",
        "        res, smallest_key=non_dominated_sorting(num_feature_and_accuracy_for_3_candidate_sol)\n",
        "        #print(res[smallest_key][0].tolist())\n",
        "        print(\"res and smallest key\")\n",
        "        print(res)\n",
        "        print(res[smallest_key][0])\n",
        "        print(\"round_robin_flag\")\n",
        "        print(round_robin_flag)\n",
        "\n",
        "        res_smallest_key = res[smallest_key]\n",
        "\n",
        "        #Once accuracy is prioritized and once feature count, one by one in turn they get priority\n",
        "        #if(round_robin_flag %2 == 0):\n",
        "        #  res_smallest_key = sorted(res_smallest_key, key=lambda x: x[1], reverse=False)\n",
        "        #  round_robin_flag = round_robin_flag + 1\n",
        "        #else:\n",
        "        #  res_smallest_key = sorted(res_smallest_key, key=lambda x: x[0], reverse=False)\n",
        "        #  round_robin_flag = round_robin_flag + 1\n",
        "\n",
        "        #In case of Tie always prioritizing F1 Score\n",
        "        res_smallest_key = sorted(res_smallest_key, key=lambda x: x[1], reverse=False)\n",
        "        round_robin_flag = round_robin_flag + 1\n",
        "\n",
        "        #IMP WAY: select non zero vector from first front; another way may be select best f1 score from top front\n",
        "        if(sum(res_smallest_key[0]) != 0):\n",
        "            X_best_t = res_smallest_key[0]\n",
        "        else:\n",
        "            X_best_t = res_smallest_key[1]\n",
        "        print(\"X_best_t\")\n",
        "        print(X_best_t)\n",
        "        print(\"vecetor from Dict_vector_cardinality_accuracy\")\n",
        "        print(Dict_vector_cardinality_accuracy[tuple(X_best_t)])\n",
        "        removed_ = Dict_vector_cardinality_accuracy[tuple(X_best_t)]\n",
        "\n",
        "        #Step 3.3: Generate a new mutation vector Vi(t) for the ith\n",
        "        #..individual according to Eq. (5);\n",
        "        base_vector = Dict_vector_cardinality_accuracy[tuple(X_best_t)]\n",
        "        X_i = P_0[i-1]\n",
        "\n",
        "        X_ri, num_feature_ri, f1_score_ri=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=X_i)\n",
        "        X_rbase, num_feature_rbase, f1_score_rbase=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=base_vector)\n",
        "\n",
        "        xi_dominates_base, base_dominates_xi, base_and_xi_are_nondominating = dominance_check_between_two_points(point1=[num_feature_rbase, f1_score_rbase], point2=[num_feature_ri, f1_score_ri])\n",
        "        #num_feature_and_accuracy_for_2_sol = [[num_feature_ri, f1_score_ri],[num_feature_rbase, f1_score_rbase]]\n",
        "\n",
        "        best_and_then_other_2 = [0,0,0]\n",
        "        if (X_best_t == r1):\n",
        "            best_and_then_other_2[0]=r1\n",
        "            best_and_then_other_2[1]=r2\n",
        "            best_and_then_other_2[2]=r3\n",
        "        elif (X_best_t == r2):\n",
        "            best_and_then_other_2[0]=r2\n",
        "            best_and_then_other_2[1]=r1\n",
        "            best_and_then_other_2[2]=r3\n",
        "        elif (X_best_t == r3):\n",
        "            best_and_then_other_2[0]=r3\n",
        "            best_and_then_other_2[1]=r1\n",
        "            best_and_then_other_2[2]=r2\n",
        "\n",
        "        i1=best_and_then_other_2[1]\n",
        "        i2=best_and_then_other_2[1]\n",
        "        X_r1_for_xor = P_0[i1]\n",
        "        X_r2_for_xor = P_0[i2]\n",
        "        print(\"X_r1_for_xor[1]\")\n",
        "        print(X_r1_for_xor[1])\n",
        "\n",
        "\n",
        "\n",
        "        sigma=1/100\n",
        "        c_i = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        v_i = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        F=0.05\n",
        "        random_val = random.sample(range(0, 100), 1)\n",
        "        random_value = random_val[0]/100\n",
        "\n",
        "        if (base_dominates_xi == True):\n",
        "            c_i[0] = sigma\n",
        "            c_i[1] = sigma\n",
        "            c_i[2] = sigma\n",
        "            c_i[3] = sigma\n",
        "            c_i[4] = sigma\n",
        "            c_i[5] = sigma\n",
        "            c_i[6] = sigma\n",
        "            c_i[7] = sigma\n",
        "            c_i[8] = sigma\n",
        "            c_i[9] = sigma\n",
        "            c_i[10] = sigma\n",
        "            c_i[11] = sigma\n",
        "            c_i[12] = sigma\n",
        "            c_i[13] = sigma\n",
        "            c_i[14] = sigma\n",
        "            c_i[15] = sigma\n",
        "            c_i[16] = sigma\n",
        "            c_i[17] = sigma\n",
        "            c_i[18] = sigma\n",
        "            c_i[19] = sigma\n",
        "            c_i[20] = sigma\n",
        "            c_i[21] = sigma\n",
        "            c_i[22] = sigma\n",
        "            c_i[23] = sigma\n",
        "            c_i[24] = sigma\n",
        "            c_i[25] = sigma\n",
        "            c_i[26] = sigma\n",
        "        else:\n",
        "\n",
        "            c_i[0] = min(1,F*(P_0[X_r1_for_xor[1]][0] ^ P_0[X_r2_for_xor[2]][0])+sigma)\n",
        "            c_i[1] = min(1,F*(P_0[X_r1_for_xor[1]][1] ^ P_0[X_r2_for_xor[2]][1])+sigma)\n",
        "            c_i[2] = min(1,F*(P_0[X_r1_for_xor[1]][2] ^ P_0[X_r2_for_xor[2]][2])+sigma)\n",
        "            c_i[3] = min(1,F*(P_0[X_r1_for_xor[1]][3] ^ P_0[X_r2_for_xor[2]][3])+sigma)\n",
        "            c_i[4] = min(1,F*(P_0[X_r1_for_xor[1]][4] ^ P_0[X_r2_for_xor[2]][4])+sigma)\n",
        "            c_i[5] = min(1,F*(P_0[X_r1_for_xor[1]][5] ^ P_0[X_r2_for_xor[2]][5])+sigma)\n",
        "            c_i[6] = min(1,F*(P_0[X_r1_for_xor[1]][6] ^ P_0[X_r2_for_xor[2]][6])+sigma)\n",
        "            c_i[7] = min(1,F*(P_0[X_r1_for_xor[1]][7] ^ P_0[X_r2_for_xor[2]][7])+sigma)\n",
        "            c_i[8] = min(1,F*(P_0[X_r1_for_xor[1]][8] ^ P_0[X_r2_for_xor[2]][8])+sigma)\n",
        "            c_i[9] = min(1,F*(P_0[X_r1_for_xor[1]][9] ^ P_0[X_r2_for_xor[2]][9])+sigma)\n",
        "            c_i[10] = min(1,F*(P_0[X_r1_for_xor[1]][10] ^ P_0[X_r2_for_xor[2]][10])+sigma)\n",
        "            c_i[11] = min(1,F*(P_0[X_r1_for_xor[1]][11] ^ P_0[X_r2_for_xor[2]][11])+sigma)\n",
        "            c_i[12] = min(1,F*(P_0[X_r1_for_xor[1]][12] ^ P_0[X_r2_for_xor[2]][12])+sigma)\n",
        "            c_i[13] = min(1,F*(P_0[X_r1_for_xor[1]][13] ^ P_0[X_r2_for_xor[2]][13])+sigma)\n",
        "            c_i[14] = min(1,F*(P_0[X_r1_for_xor[1]][14] ^ P_0[X_r2_for_xor[2]][14])+sigma)\n",
        "            c_i[15] = min(1,F*(P_0[X_r1_for_xor[1]][15] ^ P_0[X_r2_for_xor[2]][15])+sigma)\n",
        "            c_i[16] = min(1,F*(P_0[X_r1_for_xor[1]][16] ^ P_0[X_r2_for_xor[2]][16])+sigma)\n",
        "            c_i[17] = min(1,F*(P_0[X_r1_for_xor[1]][17] ^ P_0[X_r2_for_xor[2]][17])+sigma)\n",
        "            c_i[18] = min(1,F*(P_0[X_r1_for_xor[1]][18] ^ P_0[X_r2_for_xor[2]][18])+sigma)\n",
        "            c_i[19] = min(1,F*(P_0[X_r1_for_xor[1]][19] ^ P_0[X_r2_for_xor[2]][19])+sigma)\n",
        "            c_i[20] = min(1,F*(P_0[X_r1_for_xor[1]][20] ^ P_0[X_r2_for_xor[2]][20])+sigma)\n",
        "            c_i[21] = min(1,F*(P_0[X_r1_for_xor[1]][21] ^ P_0[X_r2_for_xor[2]][21])+sigma)\n",
        "            c_i[22] = min(1,F*(P_0[X_r1_for_xor[1]][22] ^ P_0[X_r2_for_xor[2]][22])+sigma)\n",
        "            c_i[23] = min(1,F*(P_0[X_r1_for_xor[1]][23] ^ P_0[X_r2_for_xor[2]][23])+sigma)\n",
        "            c_i[24] = min(1,F*(P_0[X_r1_for_xor[1]][24] ^ P_0[X_r2_for_xor[2]][24])+sigma)\n",
        "            c_i[25] = min(1,F*(P_0[X_r1_for_xor[1]][25] ^ P_0[X_r2_for_xor[2]][25])+sigma)\n",
        "            c_i[26] = min(1,F*(P_0[X_r1_for_xor[1]][26] ^ P_0[X_r2_for_xor[2]][26])+sigma)\n",
        "\n",
        "        if c_i[0] < random_value:\n",
        "            v_i[0] = base_vector[0]\n",
        "        else:\n",
        "            v_i[0] = 1-base_vector[0]\n",
        "\n",
        "        if c_i[1] < random_value:\n",
        "            v_i[1] = base_vector[1]\n",
        "        else:\n",
        "            v_i[1] = 1-base_vector[1]\n",
        "\n",
        "        if c_i[2] < random_value:\n",
        "            v_i[2] = base_vector[2]\n",
        "        else:\n",
        "            v_i[2] = 1-base_vector[2]\n",
        "\n",
        "        if c_i[3] < random_value:\n",
        "            v_i[3] = base_vector[3]\n",
        "        else:\n",
        "            v_i[3] = 1-base_vector[3]\n",
        "\n",
        "        if c_i[4] < random_value:\n",
        "            v_i[4] = base_vector[4]\n",
        "        else:\n",
        "            v_i[4] = 1-base_vector[4]\n",
        "\n",
        "        if c_i[5] < random_value:\n",
        "            v_i[5] = base_vector[5]\n",
        "        else:\n",
        "            v_i[5] = 1-base_vector[5]\n",
        "\n",
        "        if c_i[6] < random_value:\n",
        "            v_i[6] = base_vector[6]\n",
        "        else:\n",
        "            v_i[6] = 1-base_vector[6]\n",
        "\n",
        "        if c_i[7] < random_value:\n",
        "            v_i[7] = base_vector[7]\n",
        "        else:\n",
        "            v_i[7] = 1-base_vector[7]\n",
        "\n",
        "        if c_i[8] < random_value:\n",
        "            v_i[8] = base_vector[8]\n",
        "        else:\n",
        "            v_i[8] = 1-base_vector[8]\n",
        "\n",
        "        if c_i[9] < random_value:\n",
        "            v_i[9] = base_vector[9]\n",
        "        else:\n",
        "            v_i[9] = 1-base_vector[9]\n",
        "\n",
        "        if c_i[10] < random_value:\n",
        "            v_i[10] = base_vector[10]\n",
        "        else:\n",
        "            v_i[10] = 1-base_vector[10]\n",
        "\n",
        "        if c_i[11] < random_value:\n",
        "            v_i[11] = base_vector[11]\n",
        "        else:\n",
        "            v_i[11] = 1-base_vector[11]\n",
        "\n",
        "        if c_i[12] < random_value:\n",
        "            v_i[12] = base_vector[12]\n",
        "        else:\n",
        "            v_i[12] = 1-base_vector[12]\n",
        "\n",
        "        if c_i[13] < random_value:\n",
        "            v_i[13] = base_vector[13]\n",
        "        else:\n",
        "            v_i[13] = 1-base_vector[13]\n",
        "\n",
        "        if c_i[14] < random_value:\n",
        "            v_i[14] = base_vector[14]\n",
        "        else:\n",
        "            v_i[14] = 1-base_vector[14]\n",
        "\n",
        "        if c_i[15] < random_value:\n",
        "            v_i[15] = base_vector[15]\n",
        "        else:\n",
        "            v_i[15] = 1-base_vector[15]\n",
        "\n",
        "        if c_i[16] < random_value:\n",
        "            v_i[16] = base_vector[16]\n",
        "        else:\n",
        "            v_i[16] = 1-base_vector[16]\n",
        "\n",
        "        if c_i[17] < random_value:\n",
        "            v_i[17] = base_vector[17]\n",
        "        else:\n",
        "            v_i[17] = 1-base_vector[17]\n",
        "\n",
        "        if c_i[18] < random_value:\n",
        "            v_i[18] = base_vector[18]\n",
        "        else:\n",
        "            v_i[18] = 1-base_vector[18]\n",
        "\n",
        "        if c_i[19] < random_value:\n",
        "            v_i[19] = base_vector[19]\n",
        "        else:\n",
        "            v_i[19] = 1-base_vector[19]\n",
        "\n",
        "        if c_i[20] < random_value:\n",
        "            v_i[20] = base_vector[20]\n",
        "        else:\n",
        "            v_i[20] = 1-base_vector[20]\n",
        "\n",
        "        if c_i[21] < random_value:\n",
        "            v_i[21] = base_vector[21]\n",
        "        else:\n",
        "            v_i[21] = 1-base_vector[21]\n",
        "\n",
        "        if c_i[22] < random_value:\n",
        "            v_i[22] = base_vector[22]\n",
        "        else:\n",
        "            v_i[22] = 1-base_vector[22]\n",
        "\n",
        "        if c_i[23] < random_value:\n",
        "            v_i[23] = base_vector[23]\n",
        "        else:\n",
        "            v_i[23] = 1-base_vector[23]\n",
        "\n",
        "        if c_i[24] < random_value:\n",
        "            v_i[24] = base_vector[24]\n",
        "        else:\n",
        "            v_i[24] = 1-base_vector[24]\n",
        "\n",
        "        if c_i[25] < random_value:\n",
        "            v_i[25] = base_vector[25]\n",
        "        else:\n",
        "            v_i[25] = 1-base_vector[25]\n",
        "\n",
        "        if c_i[26] < random_value:\n",
        "            v_i[26] = base_vector[26]\n",
        "        else:\n",
        "            v_i[26] = 1-base_vector[26]\n",
        "\n",
        "\n",
        "\n",
        "        #Step 3.4: Generate a trial vector Ui(t) for the ith individual according to Eq. (4);\n",
        "        u_0_1 = random.sample(range(0, 100), 1)[0]\n",
        "        u_0_1 = u_0_1/100\n",
        "        #u_0_1_val = u_0_1\n",
        "        h= random.sample(range(0, N), 1)[0]\n",
        "        cr= 0.2 #random.sample(range(0, 1), 1)[0]\n",
        "        u_i = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "        if (u_0_1 < cr or 0==h ):\n",
        "            u_i[0]=v_i[0]\n",
        "        else:\n",
        "            u_i[0]=X_i[0]\n",
        "\n",
        "        if (u_0_1 < cr or 1==h ):\n",
        "            u_i[1]=v_i[1]\n",
        "        else:\n",
        "            u_i[1]=X_i[1]\n",
        "\n",
        "        if (u_0_1 < cr or 2==h ):\n",
        "            u_i[2]=v_i[2]\n",
        "        else:\n",
        "            u_i[2]=X_i[2]\n",
        "\n",
        "        if (u_0_1 < cr or 3==h ):\n",
        "            u_i[3]=v_i[3]\n",
        "        else:\n",
        "            u_i[3]=X_i[3]\n",
        "\n",
        "        if (u_0_1 < cr or 4==h ):\n",
        "            u_i[4]=v_i[4]\n",
        "        else:\n",
        "            u_i[4]=X_i[4]\n",
        "\n",
        "        if (u_0_1 < cr or 5==h ):\n",
        "            u_i[5]=v_i[5]\n",
        "        else:\n",
        "            u_i[5]=X_i[5]\n",
        "\n",
        "        if (u_0_1 < cr or 6==h ):\n",
        "            u_i[6]=v_i[6]\n",
        "        else:\n",
        "            u_i[6]=X_i[6]\n",
        "\n",
        "        if (u_0_1 < cr or 7==h ):\n",
        "            u_i[7]=v_i[7]\n",
        "        else:\n",
        "            u_i[7]=X_i[7]\n",
        "\n",
        "        if (u_0_1 < cr or 8==h ):\n",
        "            u_i[8]=v_i[8]\n",
        "        else:\n",
        "            u_i[8]=X_i[8]\n",
        "\n",
        "        if (u_0_1 < cr or 9==h ):\n",
        "            u_i[9]=v_i[9]\n",
        "        else:\n",
        "            u_i[9]=X_i[9]\n",
        "\n",
        "        if (u_0_1 < cr or 10==h ):\n",
        "            u_i[10]=v_i[10]\n",
        "        else:\n",
        "            u_i[10]=X_i[10]\n",
        "\n",
        "        if (u_0_1 < cr or 11==h ):\n",
        "            u_i[11]=v_i[11]\n",
        "        else:\n",
        "            u_i[11]=X_i[11]\n",
        "\n",
        "        if (u_0_1 < cr or 12==h ):\n",
        "            u_i[12]=v_i[12]\n",
        "        else:\n",
        "            u_i[12]=X_i[12]\n",
        "\n",
        "        if (u_0_1 < cr or 13==h ):\n",
        "            u_i[13]=v_i[13]\n",
        "        else:\n",
        "            u_i[13]=X_i[13]\n",
        "\n",
        "        if (u_0_1 < cr or 14==h ):\n",
        "            u_i[14]=v_i[14]\n",
        "        else:\n",
        "            u_i[14]=X_i[14]\n",
        "\n",
        "        if (u_0_1 < cr or 15==h ):\n",
        "            u_i[15]=v_i[15]\n",
        "        else:\n",
        "            u_i[15]=X_i[15]\n",
        "\n",
        "        if (u_0_1 < cr or 16==h ):\n",
        "            u_i[16]=v_i[16]\n",
        "        else:\n",
        "            u_i[16]=X_i[16]\n",
        "\n",
        "        if (u_0_1 < cr or 17==h ):\n",
        "            u_i[17]=v_i[17]\n",
        "        else:\n",
        "            u_i[17]=X_i[17]\n",
        "\n",
        "        if (u_0_1 < cr or 18==h ):\n",
        "            u_i[18]=v_i[18]\n",
        "        else:\n",
        "            u_i[18]=X_i[18]\n",
        "\n",
        "        if (u_0_1 < cr or 19==h ):\n",
        "            u_i[19]=v_i[19]\n",
        "        else:\n",
        "            u_i[19]=X_i[19]\n",
        "\n",
        "        if (u_0_1 < cr or 20==h ):\n",
        "            u_i[20]=v_i[20]\n",
        "        else:\n",
        "            u_i[20]=X_i[20]\n",
        "\n",
        "        if (u_0_1 < cr or 21==h ):\n",
        "            u_i[21]=v_i[21]\n",
        "        else:\n",
        "            u_i[21]=X_i[21]\n",
        "\n",
        "        if (u_0_1 < cr or 22==h ):\n",
        "            u_i[22]=v_i[22]\n",
        "        else:\n",
        "            u_i[22]=X_i[22]\n",
        "\n",
        "        if (u_0_1 < cr or 23==h ):\n",
        "            u_i[23]=v_i[23]\n",
        "        else:\n",
        "            u_i[23]=X_i[23]\n",
        "\n",
        "        if (u_0_1 < cr or 24==h ):\n",
        "            u_i[24]=v_i[24]\n",
        "        else:\n",
        "            u_i[24]=X_i[24]\n",
        "\n",
        "        if (u_0_1 < cr or 25==h ):\n",
        "            u_i[25]=v_i[25]\n",
        "        else:\n",
        "            u_i[25]=X_i[25]\n",
        "\n",
        "        if (u_0_1 < cr or 26==h ):\n",
        "            u_i[26]=v_i[26]\n",
        "        else:\n",
        "            u_i[26]=X_i[26]\n",
        "\n",
        "\n",
        "        #Step 3.5: Evaluate the fitness of the trial vector Ui(t)\n",
        "        X_ui, num_feature_ui, f1_score_ui=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'],X_rn=u_i)\n",
        "        #Step 3.6: Compare the ith individual Xi(t) with Ui(t).\n",
        "        #If Xi(t) dominates Ui(t), save Xi(t) into Pt+1;\n",
        "        #if Ui(t) dominatesXi(t), save Ui(t) into Pt+1;\n",
        "        #otherwise, save both Ui(t) and Xi(t) into Pt+1.\n",
        "\n",
        "        xi_dominates_ui, ui_dominates_xi, ui_and_xi_are_nondominating = dominance_check_between_two_points(point1=[num_feature_ui, f1_score_ui], point2=[num_feature_ri, f1_score_ri])\n",
        "        if(xi_dominates_ui==1):\n",
        "            P_t_plus_1.append(X_i)\n",
        "            P_t_plus_1_vector_fitness.append([X_ri, num_feature_ri, f1_score_ri])\n",
        "            P_t_plus_1_vector.append([X_ri])\n",
        "            P_t_plus_1_fitness.append([num_feature_ri, f1_score_ri])\n",
        "        elif(ui_dominates_xi==1):\n",
        "            P_t_plus_1.append(u_i)\n",
        "            P_t_plus_1_vector_fitness.append([X_ui, num_feature_ui, f1_score_ui])\n",
        "            P_t_plus_1_vector.append([X_ui])\n",
        "            P_t_plus_1_fitness.append([num_feature_ui, f1_score_ui])\n",
        "        else:\n",
        "            P_t_plus_1.append(X_i)\n",
        "            P_t_plus_1.append(u_i)\n",
        "            P_t_plus_1_vector_fitness.append([X_ri, num_feature_ri, f1_score_ri])\n",
        "            P_t_plus_1_vector.append([X_ri])\n",
        "            P_t_plus_1_fitness.append([num_feature_ri, f1_score_ri])\n",
        "            P_t_plus_1_vector_fitness.append([X_ui, num_feature_ui, f1_score_ui])\n",
        "            P_t_plus_1_vector.append([X_ui])\n",
        "            P_t_plus_1_fitness.append([num_feature_ui, f1_score_ui])\n",
        "    #EndFor\n",
        "    if len(P_t_plus_1) > N:\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(P_0)\n",
        "    print(P_t_plus_1)\n",
        "    print(P_t_plus_1_vector_fitness)\n",
        "    print(P_t_plus_1_vector)\n",
        "    print(P_t_plus_1_fitness)"
      ],
      "metadata": {
        "id": "wC_Npk7HNc96"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "Feature_population = []\n",
        "for i in range(27):\n",
        "  #zeros = list(np.zeros(15).astype(int))\n",
        "  #ones = list(np.ones(15).astype(int))\n",
        "  #list_of_0_1 = zeros + ones\n",
        "\n",
        "  array_of_0_1=np.random.rand(27)\n",
        "  array_of_0_1[array_of_0_1 >= 0.5] = 1\n",
        "  array_of_0_1[array_of_0_1 < 0.5] = 0\n",
        "  array_of_0_1 = array_of_0_1.astype(int)\n",
        "  list_of_0_1 = list(array_of_0_1)\n",
        "\n",
        "  random.shuffle(list_of_0_1)\n",
        "  Feature_population.append(list_of_0_1)"
      ],
      "metadata": {
        "id": "jUt9Sb94D5EJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Feature_population[0])\n",
        "print(Feature_population[1])\n",
        "print(Feature_population[2])\n",
        "print(Feature_population[3])\n",
        "print(Feature_population[4])\n",
        "print(Feature_population[5])\n",
        "print(Feature_population[6])\n",
        "print(Feature_population[7])\n",
        "print(Feature_population[8])\n",
        "print(Feature_population[9])\n",
        "print(Feature_population[10])\n",
        "print(Feature_population[11])\n",
        "print(Feature_population[12])\n",
        "print(Feature_population[13])\n",
        "print(Feature_population[14])\n",
        "print(Feature_population[15])\n",
        "print(Feature_population[16])\n",
        "print(Feature_population[17])\n",
        "print(Feature_population[18])\n",
        "print(Feature_population[19])\n",
        "print(Feature_population[20])\n",
        "print(Feature_population[21])\n",
        "print(Feature_population[22])\n",
        "print(Feature_population[23])\n",
        "print(Feature_population[24])\n",
        "print(Feature_population[25])\n",
        "print(Feature_population[26])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThvxJqgkTwps",
        "outputId": "b707708a-1423-43c5-d5fb-c5bd2e688c62"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1]\n",
            "[1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1]\n",
            "[0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
            "[0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n",
            "[1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n",
            "[1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "[1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
            "[1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
            "[1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
            "[0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
            "[1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0]\n",
            "[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "[1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
            "[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
            "[1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "[1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_r,a,b=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target ,\\\n",
        "                              target_test = test_up['Creditability'],X_rn=[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1])\n",
        "print(X_r)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHcMYYtC4P2R",
        "outputId": "7b4c6cea-ff15-46d0-f0ba-1e5b7ac15349"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "14\n",
            "0.30600000000000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Feature_population)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I3KU2yDUASj",
        "outputId": "db12fd49-e740-40ec-d44c-64c9cf56bd0c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Round"
      ],
      "metadata": {
        "id": "nbaZYY5FUc6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_population = [\n",
        "[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0],\n",
        "[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1],\n",
        "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
        "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
        "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
        "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
        "[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1],\n",
        "[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1],\n",
        "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
        "[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0],\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
        "[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
        "[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1],\n",
        "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
        "[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
        "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1],\n",
        "[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
        "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
        "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
        "[0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1],\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
        "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
        "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
        "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
        "]"
      ],
      "metadata": {
        "id": "26pabE8hUQF8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Feature_population)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKOu35bJMyUZ",
        "outputId": "dc0b42be-0a8f-43f0-a5d7-a46ee27860a5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MOFS(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'] ,initial_population= Feature_population)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvqAZXG1U76H",
        "outputId": "160a1b4d-5825-48cb-c4ba-61be3952b6e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 18 24\n",
            "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.3357664233576642\n",
            "accuracy is 0.636\n",
            "error rate is 0.364\n",
            "roc_auc_score is 0.5429982730125716\n",
            "gini is 0.08599654602514328\n",
            "[[272  71]\n",
            " [111  46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.39      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.54       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.41605839416058393\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5940651055690702\n",
            "gini is 0.18813021113814044\n",
            "[[283  60]\n",
            " [100  57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78       343\n",
            "           1       0.49      0.36      0.42       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.61      0.59      0.60       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.364], [15, 0.31999999999999995], [12, 0.29800000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.364], [15.0, 0.31999999999999995], [12.0, 0.29800000000000004]])])\n",
            "[10.0, 0.364]\n",
            "round_robin_flag\n",
            "0\n",
            "X_best_t\n",
            "[12.0, 0.29800000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "0 21 10\n",
            "[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.47887323943661975\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.63055467865035\n",
            "gini is 0.26110935730069995\n",
            "[[284  59]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.54      0.43      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.2962962962962963\n",
            "accuracy is 0.62\n",
            "error rate is 0.38\n",
            "roc_auc_score is 0.520974540862751\n",
            "gini is 0.041949081725501935\n",
            "[[270  73]\n",
            " [117  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       343\n",
            "           1       0.35      0.25      0.30       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.53      0.52      0.52       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.32199999999999995], [11, 0.29600000000000004], [9, 0.38]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[11.0, 0.29600000000000004], [9.0, 0.38]]), (1, [[15.0, 0.32199999999999995]])])\n",
            "[11.0, 0.29600000000000004]\n",
            "round_robin_flag\n",
            "1\n",
            "X_best_t\n",
            "[11.0, 0.29600000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.34782608695652173\n",
            "accuracy is 0.64\n",
            "error rate is 0.36\n",
            "roc_auc_score is 0.5493676997641641\n",
            "gini is 0.09873539952832822\n",
            "[[272  71]\n",
            " [109  48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.40      0.31      0.35       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.56      0.55      0.55       500\n",
            "weighted avg       0.62      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.47887323943661975\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.63055467865035\n",
            "gini is 0.26110935730069995\n",
            "[[284  59]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.54      0.43      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.34782608695652173\n",
            "accuracy is 0.64\n",
            "error rate is 0.36\n",
            "roc_auc_score is 0.5493676997641641\n",
            "gini is 0.09873539952832822\n",
            "[[272  71]\n",
            " [109  48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.40      0.31      0.35       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.56      0.55      0.55       500\n",
            "weighted avg       0.62      0.64      0.62       500\n",
            "\n",
            "7 20 4\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "f1_score is -0.4636678200692042\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.6186236095894228\n",
            "gini is 0.2372472191788455\n",
            "[[278  65]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.51      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.26415094339622636\n",
            "accuracy is 0.61\n",
            "error rate is 0.39\n",
            "roc_auc_score is 0.5050509739837701\n",
            "gini is 0.010101947967540159\n",
            "[[270  73]\n",
            " [122  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.79      0.73       343\n",
            "           1       0.32      0.22      0.26       157\n",
            "\n",
            "    accuracy                           0.61       500\n",
            "   macro avg       0.51      0.51      0.50       500\n",
            "weighted avg       0.57      0.61      0.59       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.33799999999999997], [14, 0.31000000000000005], [11, 0.39]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.33799999999999997], [14.0, 0.31000000000000005], [11.0, 0.39]])])\n",
            "[12.0, 0.33799999999999997]\n",
            "round_robin_flag\n",
            "2\n",
            "X_best_t\n",
            "[14.0, 0.31000000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.4015444015444016\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.5927187981653079\n",
            "gini is 0.18543759633061585\n",
            "[[293  50]\n",
            " [105  52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.79       343\n",
            "           1       0.51      0.33      0.40       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.59      0.60       500\n",
            "weighted avg       0.67      0.69      0.67       500\n",
            "\n",
            "f1_score is -0.4636678200692042\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.6186236095894228\n",
            "gini is 0.2372472191788455\n",
            "[[278  65]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.51      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4015444015444016\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.5927187981653079\n",
            "gini is 0.18543759633061585\n",
            "[[293  50]\n",
            " [105  52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.79       343\n",
            "           1       0.51      0.33      0.40       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.59      0.60       500\n",
            "weighted avg       0.67      0.69      0.67       500\n",
            "\n",
            "10 6 17\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.2962962962962963\n",
            "accuracy is 0.62\n",
            "error rate is 0.38\n",
            "roc_auc_score is 0.520974540862751\n",
            "gini is 0.041949081725501935\n",
            "[[270  73]\n",
            " [117  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       343\n",
            "           1       0.35      0.25      0.30       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.53      0.52      0.52       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "f1_score is -0.31178707224334606\n",
            "accuracy is 0.638\n",
            "error rate is 0.362\n",
            "roc_auc_score is 0.535821061818722\n",
            "gini is 0.07164212363744404\n",
            "[[278  65]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.75       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.40410958904109595\n",
            "accuracy is 0.652\n",
            "error rate is 0.348\n",
            "roc_auc_score is 0.5771109171603128\n",
            "gini is 0.15422183432062564\n",
            "[[267  76]\n",
            " [ 98  59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.44      0.38      0.40       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.58      0.58       500\n",
            "weighted avg       0.64      0.65      0.64       500\n",
            "\n",
            "9\n",
            "9\n",
            "[[9, 0.38], [12, 0.362], [15, 0.348]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[9.0, 0.38], [12.0, 0.362], [15.0, 0.348]])])\n",
            "[9.0, 0.38]\n",
            "round_robin_flag\n",
            "3\n",
            "X_best_t\n",
            "[15.0, 0.348]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.40410958904109595\n",
            "accuracy is 0.652\n",
            "error rate is 0.348\n",
            "roc_auc_score is 0.5771109171603128\n",
            "gini is 0.15422183432062564\n",
            "[[267  76]\n",
            " [ 98  59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.44      0.38      0.40       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.58      0.58       500\n",
            "weighted avg       0.64      0.65      0.64       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "4 15 3\n",
            "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.26415094339622636\n",
            "accuracy is 0.61\n",
            "error rate is 0.39\n",
            "roc_auc_score is 0.5050509739837701\n",
            "gini is 0.010101947967540159\n",
            "[[270  73]\n",
            " [122  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.79      0.73       343\n",
            "           1       0.32      0.22      0.26       157\n",
            "\n",
            "    accuracy                           0.61       500\n",
            "   macro avg       0.51      0.51      0.50       500\n",
            "weighted avg       0.57      0.61      0.59       500\n",
            "\n",
            "f1_score is -0.4366197183098592\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.6027000427104418\n",
            "gini is 0.2054000854208835\n",
            "[[278  65]\n",
            " [ 95  62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.49      0.39      0.44       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.60      0.61       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.39], [14, 0.31999999999999995], [15, 0.29800000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.39], [14.0, 0.31999999999999995], [15.0, 0.29800000000000004]])])\n",
            "[11.0, 0.39]\n",
            "round_robin_flag\n",
            "4\n",
            "X_best_t\n",
            "[15.0, 0.29800000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.26415094339622636\n",
            "accuracy is 0.61\n",
            "error rate is 0.39\n",
            "roc_auc_score is 0.5050509739837701\n",
            "gini is 0.010101947967540159\n",
            "[[270  73]\n",
            " [122  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.79      0.73       343\n",
            "           1       0.32      0.22      0.26       157\n",
            "\n",
            "    accuracy                           0.61       500\n",
            "   macro avg       0.51      0.51      0.50       500\n",
            "weighted avg       0.57      0.61      0.59       500\n",
            "\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "0 17 9\n",
            "[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0] [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1] [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.40410958904109595\n",
            "accuracy is 0.652\n",
            "error rate is 0.348\n",
            "roc_auc_score is 0.5771109171603128\n",
            "gini is 0.15422183432062564\n",
            "[[267  76]\n",
            " [ 98  59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.44      0.38      0.40       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.58      0.58       500\n",
            "weighted avg       0.64      0.65      0.64       500\n",
            "\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.32199999999999995], [15, 0.348], [13, 0.32799999999999996]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[15.0, 0.32199999999999995], [13.0, 0.32799999999999996]]), (2, [[15.0, 0.348]])])\n",
            "[15.0, 0.32199999999999995]\n",
            "round_robin_flag\n",
            "5\n",
            "X_best_t\n",
            "[15.0, 0.32199999999999995]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n",
            "f1_score is -0.3357664233576642\n",
            "accuracy is 0.636\n",
            "error rate is 0.364\n",
            "roc_auc_score is 0.5429982730125716\n",
            "gini is 0.08599654602514328\n",
            "[[272  71]\n",
            " [111  46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.39      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.54       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.34532374100719426\n",
            "accuracy is 0.636\n",
            "error rate is 0.364\n",
            "roc_auc_score is 0.5464522478691203\n",
            "gini is 0.09290449573824056\n",
            "[[270  73]\n",
            " [109  48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.40      0.31      0.35       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.55      0.55       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "16 13 9\n",
            "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0] [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0] [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.5\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.6397281387532265\n",
            "gini is 0.2794562775064531\n",
            "[[275  68]\n",
            " [ 82  75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.80      0.79       343\n",
            "           1       0.52      0.48      0.50       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.64      0.64       500\n",
            "weighted avg       0.69      0.70      0.70       500\n",
            "\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.31200000000000006], [13, 0.30000000000000004], [13, 0.32799999999999996]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.31200000000000006], [13.0, 0.30000000000000004]]), (2, [[13.0, 0.32799999999999996]])])\n",
            "[12.0, 0.31200000000000006]\n",
            "round_robin_flag\n",
            "6\n",
            "X_best_t\n",
            "[13.0, 0.30000000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.31178707224334606\n",
            "accuracy is 0.638\n",
            "error rate is 0.362\n",
            "roc_auc_score is 0.535821061818722\n",
            "gini is 0.07164212363744404\n",
            "[[278  65]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.75       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.5\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.6397281387532265\n",
            "gini is 0.2794562775064531\n",
            "[[275  68]\n",
            " [ 82  75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.80      0.79       343\n",
            "           1       0.52      0.48      0.50       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.64      0.64       500\n",
            "weighted avg       0.69      0.70      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.31178707224334606\n",
            "accuracy is 0.638\n",
            "error rate is 0.362\n",
            "roc_auc_score is 0.535821061818722\n",
            "gini is 0.07164212363744404\n",
            "[[278  65]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.75       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "6 10 25\n",
            "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.31178707224334606\n",
            "accuracy is 0.638\n",
            "error rate is 0.362\n",
            "roc_auc_score is 0.535821061818722\n",
            "gini is 0.07164212363744404\n",
            "[[278  65]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.75       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.2962962962962963\n",
            "accuracy is 0.62\n",
            "error rate is 0.38\n",
            "roc_auc_score is 0.520974540862751\n",
            "gini is 0.041949081725501935\n",
            "[[270  73]\n",
            " [117  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       343\n",
            "           1       0.35      0.25      0.30       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.53      0.52      0.52       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "f1_score is -0.47750865051903113\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.6279084882360588\n",
            "gini is 0.25581697647211765\n",
            "[[280  63]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.52      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.63      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.362], [9, 0.38], [10, 0.30200000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.30200000000000005]]), (1, [[12.0, 0.362], [9.0, 0.38]])])\n",
            "[10.0, 0.30200000000000005]\n",
            "round_robin_flag\n",
            "7\n",
            "X_best_t\n",
            "[10.0, 0.30200000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "f1_score is -0.47750865051903113\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.6279084882360588\n",
            "gini is 0.25581697647211765\n",
            "[[280  63]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.52      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.63      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.580676310560621\n",
            "gini is 0.16135262112124193\n",
            "[[276  67]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.77       343\n",
            "           1       0.46      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.65      0.66      0.65       500\n",
            "\n",
            "19 25 17\n",
            "[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.3942652329749104\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.5774915971848248\n",
            "gini is 0.15498319436964958\n",
            "[[276  67]\n",
            " [102  55]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.77       343\n",
            "           1       0.45      0.35      0.39       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "f1_score is -0.47750865051903113\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.6279084882360588\n",
            "gini is 0.25581697647211765\n",
            "[[280  63]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.52      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.63      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.40410958904109595\n",
            "accuracy is 0.652\n",
            "error rate is 0.348\n",
            "roc_auc_score is 0.5771109171603128\n",
            "gini is 0.15422183432062564\n",
            "[[267  76]\n",
            " [ 98  59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.44      0.38      0.40       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.58      0.58       500\n",
            "weighted avg       0.64      0.65      0.64       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.33799999999999997], [10, 0.30200000000000005], [15, 0.348]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.30200000000000005]]), (1, [[13.0, 0.33799999999999997]]), (2, [[15.0, 0.348]])])\n",
            "[10.0, 0.30200000000000005]\n",
            "round_robin_flag\n",
            "8\n",
            "X_best_t\n",
            "[10.0, 0.30200000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.35294117647058826\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.5551986035542515\n",
            "gini is 0.11039720710850309\n",
            "[[276  67]\n",
            " [109  48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.80      0.76       343\n",
            "           1       0.42      0.31      0.35       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.57      0.56      0.56       500\n",
            "weighted avg       0.62      0.65      0.63       500\n",
            "\n",
            "f1_score is -0.47750865051903113\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.6279084882360588\n",
            "gini is 0.25581697647211765\n",
            "[[280  63]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.52      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.63      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.36162361623616235\n",
            "accuracy is 0.654\n",
            "error rate is 0.346\n",
            "roc_auc_score is 0.5612987688250914\n",
            "gini is 0.12259753765018289\n",
            "[[278  65]\n",
            " [108  49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.81      0.76       343\n",
            "           1       0.43      0.31      0.36       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.56      0.56       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "12 20 10\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.3888888888888889\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.569014502980446\n",
            "gini is 0.13802900596089196\n",
            "[[268  75]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.43      0.36      0.39       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.57      0.57       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "f1_score is -0.4636678200692042\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.6186236095894228\n",
            "gini is 0.2372472191788455\n",
            "[[278  65]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.51      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.2962962962962963\n",
            "accuracy is 0.62\n",
            "error rate is 0.38\n",
            "roc_auc_score is 0.520974540862751\n",
            "gini is 0.041949081725501935\n",
            "[[270  73]\n",
            " [117  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       343\n",
            "           1       0.35      0.25      0.30       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.53      0.52      0.52       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "7\n",
            "7\n",
            "[[7, 0.352], [14, 0.31000000000000005], [9, 0.38]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[7.0, 0.352], [14.0, 0.31000000000000005]]), (2, [[9.0, 0.38]])])\n",
            "[7.0, 0.352]\n",
            "round_robin_flag\n",
            "9\n",
            "X_best_t\n",
            "[14.0, 0.31000000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "f1_score is -0.4636678200692042\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.6186236095894228\n",
            "gini is 0.2372472191788455\n",
            "[[278  65]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.51      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4542372881355932\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6098772539042916\n",
            "gini is 0.2197545078085832\n",
            "[[272  71]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "10 7 16\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.2962962962962963\n",
            "accuracy is 0.62\n",
            "error rate is 0.38\n",
            "roc_auc_score is 0.520974540862751\n",
            "gini is 0.041949081725501935\n",
            "[[270  73]\n",
            " [117  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       343\n",
            "           1       0.35      0.25      0.30       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.53      0.52      0.52       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "9\n",
            "9\n",
            "[[9, 0.38], [12, 0.33799999999999997], [12, 0.31200000000000006]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[9.0, 0.38], [12.0, 0.33799999999999997], [12.0, 0.31200000000000006]])])\n",
            "[9.0, 0.38]\n",
            "round_robin_flag\n",
            "10\n",
            "X_best_t\n",
            "[12.0, 0.31200000000000006]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.2962962962962963\n",
            "accuracy is 0.62\n",
            "error rate is 0.38\n",
            "roc_auc_score is 0.520974540862751\n",
            "gini is 0.041949081725501935\n",
            "[[270  73]\n",
            " [117  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       343\n",
            "           1       0.35      0.25      0.30       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.53      0.52      0.52       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.34456928838951306\n",
            "accuracy is 0.65\n",
            "error rate is 0.35\n",
            "roc_auc_score is 0.5532023546452247\n",
            "gini is 0.10640470929044943\n",
            "[[279  64]\n",
            " [111  46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.81      0.76       343\n",
            "           1       0.42      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.57      0.55      0.55       500\n",
            "weighted avg       0.62      0.65      0.63       500\n",
            "\n",
            "3 21 12\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.47887323943661975\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.63055467865035\n",
            "gini is 0.26110935730069995\n",
            "[[284  59]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.54      0.43      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.3888888888888889\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.569014502980446\n",
            "gini is 0.13802900596089196\n",
            "[[268  75]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.43      0.36      0.39       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.57      0.57       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.29800000000000004], [11, 0.29600000000000004], [7, 0.352]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[11.0, 0.29600000000000004], [7.0, 0.352]]), (1, [[15.0, 0.29800000000000004]])])\n",
            "[11.0, 0.29600000000000004]\n",
            "round_robin_flag\n",
            "11\n",
            "X_best_t\n",
            "[11.0, 0.29600000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.4225352112676057\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5934151640638057\n",
            "gini is 0.18683032812761136\n",
            "[[276  67]\n",
            " [ 97  60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.80      0.77       343\n",
            "           1       0.47      0.38      0.42       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.59      0.60       500\n",
            "weighted avg       0.66      0.67      0.66       500\n",
            "\n",
            "f1_score is -0.47887323943661975\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.63055467865035\n",
            "gini is 0.26110935730069995\n",
            "[[284  59]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.54      0.43      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4225352112676057\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5934151640638057\n",
            "gini is 0.18683032812761136\n",
            "[[276  67]\n",
            " [ 97  60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.80      0.77       343\n",
            "           1       0.47      0.38      0.42       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.59      0.60       500\n",
            "weighted avg       0.66      0.67      0.66       500\n",
            "\n",
            "4 1 7\n",
            "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.26415094339622636\n",
            "accuracy is 0.61\n",
            "error rate is 0.39\n",
            "roc_auc_score is 0.5050509739837701\n",
            "gini is 0.010101947967540159\n",
            "[[270  73]\n",
            " [122  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.79      0.73       343\n",
            "           1       0.32      0.22      0.26       157\n",
            "\n",
            "    accuracy                           0.61       500\n",
            "   macro avg       0.51      0.51      0.50       500\n",
            "weighted avg       0.57      0.61      0.59       500\n",
            "\n",
            "f1_score is -0.34782608695652173\n",
            "accuracy is 0.64\n",
            "error rate is 0.36\n",
            "roc_auc_score is 0.5493676997641641\n",
            "gini is 0.09873539952832822\n",
            "[[272  71]\n",
            " [109  48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.40      0.31      0.35       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.56      0.55      0.55       500\n",
            "weighted avg       0.62      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.39], [13, 0.36], [12, 0.33799999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.39], [13.0, 0.36], [12.0, 0.33799999999999997]])])\n",
            "[11.0, 0.39]\n",
            "round_robin_flag\n",
            "12\n",
            "X_best_t\n",
            "[12.0, 0.33799999999999997]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.3888888888888889\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.569014502980446\n",
            "gini is 0.13802900596089196\n",
            "[[268  75]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.43      0.36      0.39       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.57      0.57       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.3888888888888889\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.569014502980446\n",
            "gini is 0.13802900596089196\n",
            "[[268  75]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.43      0.36      0.39       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.57      0.57       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "9 14 12\n",
            "[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1] [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "f1_score is -0.31297709923664124\n",
            "accuracy is 0.64\n",
            "error rate is 0.36\n",
            "roc_auc_score is 0.5372787877662438\n",
            "gini is 0.07455757553248765\n",
            "[[279  64]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.3888888888888889\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.569014502980446\n",
            "gini is 0.13802900596089196\n",
            "[[268  75]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.43      0.36      0.39       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.57      0.57       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.32799999999999996], [13, 0.36], [7, 0.352]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[13.0, 0.32799999999999996], [7.0, 0.352]]), (2, [[13.0, 0.36]])])\n",
            "[13.0, 0.32799999999999996]\n",
            "round_robin_flag\n",
            "13\n",
            "X_best_t\n",
            "[13.0, 0.32799999999999996]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.5\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.6397281387532265\n",
            "gini is 0.2794562775064531\n",
            "[[275  68]\n",
            " [ 82  75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.80      0.79       343\n",
            "           1       0.52      0.48      0.50       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.64      0.64       500\n",
            "weighted avg       0.69      0.70      0.70       500\n",
            "\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "5 23 26\n",
            "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.3357664233576642\n",
            "accuracy is 0.636\n",
            "error rate is 0.364\n",
            "roc_auc_score is 0.5429982730125716\n",
            "gini is 0.08599654602514328\n",
            "[[272  71]\n",
            " [111  46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.39      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.54       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.364], [11, 0.32199999999999995], [14, 0.30600000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.364], [11.0, 0.32199999999999995], [14.0, 0.30600000000000005]])])\n",
            "[10.0, 0.364]\n",
            "round_robin_flag\n",
            "14\n",
            "X_best_t\n",
            "[14.0, 0.30600000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.31297709923664124\n",
            "accuracy is 0.64\n",
            "error rate is 0.36\n",
            "roc_auc_score is 0.5372787877662438\n",
            "gini is 0.07455757553248765\n",
            "[[279  64]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.35521235521235517\n",
            "accuracy is 0.666\n",
            "error rate is 0.33399999999999996\n",
            "roc_auc_score is 0.5648641622253997\n",
            "gini is 0.1297283244507994\n",
            "[[287  56]\n",
            " [111  46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.84      0.77       343\n",
            "           1       0.45      0.29      0.36       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.59      0.56      0.56       500\n",
            "weighted avg       0.64      0.67      0.64       500\n",
            "\n",
            "14 24 9\n",
            "[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.31297709923664124\n",
            "accuracy is 0.64\n",
            "error rate is 0.36\n",
            "roc_auc_score is 0.5372787877662438\n",
            "gini is 0.07455757553248765\n",
            "[[279  64]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.36], [12, 0.29800000000000004], [13, 0.32799999999999996]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[12.0, 0.29800000000000004]]), (0.5, [[13.0, 0.32799999999999996]]), (1, [[13.0, 0.36]])])\n",
            "[12.0, 0.29800000000000004]\n",
            "round_robin_flag\n",
            "15\n",
            "X_best_t\n",
            "[12.0, 0.29800000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.4366197183098592\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.6027000427104418\n",
            "gini is 0.2054000854208835\n",
            "[[278  65]\n",
            " [ 95  62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.49      0.39      0.44       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.60      0.61       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4366197183098592\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.6027000427104418\n",
            "gini is 0.2054000854208835\n",
            "[[278  65]\n",
            " [ 95  62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.49      0.39      0.44       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.60      0.61       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "12 16 7\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.3888888888888889\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.569014502980446\n",
            "gini is 0.13802900596089196\n",
            "[[268  75]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.43      0.36      0.39       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.57      0.57       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "7\n",
            "7\n",
            "[[7, 0.352], [12, 0.31200000000000006], [12, 0.33799999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[7.0, 0.352], [12.0, 0.31200000000000006], [12.0, 0.33799999999999997]])])\n",
            "[7.0, 0.352]\n",
            "round_robin_flag\n",
            "16\n",
            "X_best_t\n",
            "[12.0, 0.31200000000000006]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.36501901140684406\n",
            "accuracy is 0.666\n",
            "error rate is 0.33399999999999996\n",
            "roc_auc_score is 0.5683181370819483\n",
            "gini is 0.13663627416389668\n",
            "[[285  58]\n",
            " [109  48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.83      0.77       343\n",
            "           1       0.45      0.31      0.37       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.59      0.57      0.57       500\n",
            "weighted avg       0.64      0.67      0.65       500\n",
            "\n",
            "26 18 10\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "f1_score is -0.41605839416058393\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5940651055690702\n",
            "gini is 0.18813021113814044\n",
            "[[283  60]\n",
            " [100  57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78       343\n",
            "           1       0.49      0.36      0.42       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.61      0.59      0.60       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.2962962962962963\n",
            "accuracy is 0.62\n",
            "error rate is 0.38\n",
            "roc_auc_score is 0.520974540862751\n",
            "gini is 0.041949081725501935\n",
            "[[270  73]\n",
            " [117  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       343\n",
            "           1       0.35      0.25      0.30       157\n",
            "\n",
            "    accuracy                           0.62       500\n",
            "   macro avg       0.53      0.52      0.52       500\n",
            "weighted avg       0.59      0.62      0.60       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.30600000000000005], [15, 0.31999999999999995], [9, 0.38]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.30600000000000005], [9.0, 0.38]]), (2, [[15.0, 0.31999999999999995]])])\n",
            "[14.0, 0.30600000000000005]\n",
            "round_robin_flag\n",
            "17\n",
            "X_best_t\n",
            "[14.0, 0.30600000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.40410958904109595\n",
            "accuracy is 0.652\n",
            "error rate is 0.348\n",
            "roc_auc_score is 0.5771109171603128\n",
            "gini is 0.15422183432062564\n",
            "[[267  76]\n",
            " [ 98  59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.44      0.38      0.40       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.58      0.58       500\n",
            "weighted avg       0.64      0.65      0.64       500\n",
            "\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.40410958904109595\n",
            "accuracy is 0.652\n",
            "error rate is 0.348\n",
            "roc_auc_score is 0.5771109171603128\n",
            "gini is 0.15422183432062564\n",
            "[[267  76]\n",
            " [ 98  59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.44      0.38      0.40       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.58      0.58       500\n",
            "weighted avg       0.64      0.65      0.64       500\n",
            "\n",
            "2 18 23\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1] [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.4015444015444016\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.5927187981653079\n",
            "gini is 0.18543759633061585\n",
            "[[293  50]\n",
            " [105  52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.79       343\n",
            "           1       0.51      0.33      0.40       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.59      0.60       500\n",
            "weighted avg       0.67      0.69      0.67       500\n",
            "\n",
            "f1_score is -0.41605839416058393\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5940651055690702\n",
            "gini is 0.18813021113814044\n",
            "[[283  60]\n",
            " [100  57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78       343\n",
            "           1       0.49      0.36      0.42       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.61      0.59      0.60       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.31000000000000005], [15, 0.31999999999999995], [11, 0.32199999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.31000000000000005], [11.0, 0.32199999999999995]]), (2, [[15.0, 0.31999999999999995]])])\n",
            "[12.0, 0.31000000000000005]\n",
            "round_robin_flag\n",
            "18\n",
            "X_best_t\n",
            "[12.0, 0.31000000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.41605839416058393\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5940651055690702\n",
            "gini is 0.18813021113814044\n",
            "[[283  60]\n",
            " [100  57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78       343\n",
            "           1       0.49      0.36      0.42       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.61      0.59      0.60       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.4015444015444016\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.5927187981653079\n",
            "gini is 0.18543759633061585\n",
            "[[293  50]\n",
            " [105  52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.79       343\n",
            "           1       0.51      0.33      0.40       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.59      0.60       500\n",
            "weighted avg       0.67      0.69      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.41605839416058393\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5940651055690702\n",
            "gini is 0.18813021113814044\n",
            "[[283  60]\n",
            " [100  57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78       343\n",
            "           1       0.49      0.36      0.42       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.61      0.59      0.60       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "9 7 6\n",
            "[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "f1_score is -0.31178707224334606\n",
            "accuracy is 0.638\n",
            "error rate is 0.362\n",
            "roc_auc_score is 0.535821061818722\n",
            "gini is 0.07164212363744404\n",
            "[[278  65]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.75       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.32799999999999996], [12, 0.33799999999999997], [12, 0.362]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[13.0, 0.32799999999999996], [12.0, 0.33799999999999997], [12.0, 0.362]])])\n",
            "[13.0, 0.32799999999999996]\n",
            "round_robin_flag\n",
            "19\n",
            "X_best_t\n",
            "[13.0, 0.32799999999999996]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.3942652329749104\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.5774915971848248\n",
            "gini is 0.15498319436964958\n",
            "[[276  67]\n",
            " [102  55]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.77       343\n",
            "           1       0.45      0.35      0.39       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "f1_score is -0.44966442953020136\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.605504076061726\n",
            "gini is 0.21100815212345192\n",
            "[[269  74]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       343\n",
            "           1       0.48      0.43      0.45       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.61      0.61      0.61       500\n",
            "weighted avg       0.66      0.67      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.3957597173144876\n",
            "accuracy is 0.658\n",
            "error rate is 0.34199999999999997\n",
            "roc_auc_score is 0.5763031327180553\n",
            "gini is 0.15260626543611067\n",
            "[[273  70]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.44      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "22 0 7\n",
            "[0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1] [0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.3927272727272727\n",
            "accuracy is 0.666\n",
            "error rate is 0.33399999999999996\n",
            "roc_auc_score is 0.5786800616515942\n",
            "gini is 0.1573601233031885\n",
            "[[279  64]\n",
            " [103  54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.81      0.77       343\n",
            "           1       0.46      0.34      0.39       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.67      0.65       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.33399999999999996], [15, 0.32199999999999995], [12, 0.33799999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.33399999999999996], [15.0, 0.32199999999999995], [12.0, 0.33799999999999997]])])\n",
            "[14.0, 0.33399999999999996]\n",
            "round_robin_flag\n",
            "20\n",
            "X_best_t\n",
            "[15.0, 0.32199999999999995]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n",
            "f1_score is -0.4636678200692042\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.6186236095894228\n",
            "gini is 0.2372472191788455\n",
            "[[278  65]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.51      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4636678200692042\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.6186236095894228\n",
            "gini is 0.2372472191788455\n",
            "[[278  65]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.51      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "20 26 15\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.4636678200692042\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.6186236095894228\n",
            "gini is 0.2372472191788455\n",
            "[[278  65]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.51      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "f1_score is -0.4366197183098592\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.6027000427104418\n",
            "gini is 0.2054000854208835\n",
            "[[278  65]\n",
            " [ 95  62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.49      0.39      0.44       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.60      0.61       500\n",
            "weighted avg       0.66      0.68      0.67       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.31000000000000005], [14, 0.30600000000000005], [14, 0.31999999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[14.0, 0.30600000000000005]]), (1, [[14.0, 0.31000000000000005]]), (2, [[14.0, 0.31999999999999995]])])\n",
            "[14.0, 0.30600000000000005]\n",
            "round_robin_flag\n",
            "21\n",
            "X_best_t\n",
            "[14.0, 0.30600000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.47887323943661975\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.63055467865035\n",
            "gini is 0.26110935730069995\n",
            "[[284  59]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.54      0.43      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.46099290780141844\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.6195428125754396\n",
            "gini is 0.23908562515087928\n",
            "[[283  60]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.83      0.79       343\n",
            "           1       0.52      0.41      0.46       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.62       500\n",
            "weighted avg       0.68      0.70      0.69       500\n",
            "\n",
            "6 17 24\n",
            "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.31178707224334606\n",
            "accuracy is 0.638\n",
            "error rate is 0.362\n",
            "roc_auc_score is 0.535821061818722\n",
            "gini is 0.07164212363744404\n",
            "[[278  65]\n",
            " [116  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.75       343\n",
            "           1       0.39      0.26      0.31       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.40410958904109595\n",
            "accuracy is 0.652\n",
            "error rate is 0.348\n",
            "roc_auc_score is 0.5771109171603128\n",
            "gini is 0.15422183432062564\n",
            "[[267  76]\n",
            " [ 98  59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.44      0.38      0.40       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.58      0.58       500\n",
            "weighted avg       0.64      0.65      0.64       500\n",
            "\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.362], [15, 0.348], [12, 0.29800000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[12.0, 0.29800000000000004]]), (1, [[12.0, 0.362], [15.0, 0.348]])])\n",
            "[12.0, 0.29800000000000004]\n",
            "round_robin_flag\n",
            "22\n",
            "X_best_t\n",
            "[12.0, 0.29800000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.3927272727272727\n",
            "accuracy is 0.666\n",
            "error rate is 0.33399999999999996\n",
            "roc_auc_score is 0.5786800616515942\n",
            "gini is 0.1573601233031885\n",
            "[[279  64]\n",
            " [103  54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.81      0.77       343\n",
            "           1       0.46      0.34      0.39       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.67      0.65       500\n",
            "\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "7 0 21\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.39857651245551595\n",
            "accuracy is 0.662\n",
            "error rate is 0.33799999999999997\n",
            "roc_auc_score is 0.579218584613099\n",
            "gini is 0.1584371692261981\n",
            "[[275  68]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       343\n",
            "           1       0.45      0.36      0.40       157\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.66      0.65       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.47887323943661975\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.63055467865035\n",
            "gini is 0.26110935730069995\n",
            "[[284  59]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.54      0.43      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.33799999999999997], [15, 0.32199999999999995], [11, 0.29600000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[11.0, 0.29600000000000004]]), (1, [[12.0, 0.33799999999999997], [15.0, 0.32199999999999995]])])\n",
            "[11.0, 0.29600000000000004]\n",
            "round_robin_flag\n",
            "23\n",
            "X_best_t\n",
            "[11.0, 0.29600000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "f1_score is -0.47887323943661975\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.63055467865035\n",
            "gini is 0.26110935730069995\n",
            "[[284  59]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.54      0.43      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "12 5 23\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.3888888888888889\n",
            "accuracy is 0.648\n",
            "error rate is 0.352\n",
            "roc_auc_score is 0.569014502980446\n",
            "gini is 0.13802900596089196\n",
            "[[268  75]\n",
            " [101  56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.75       343\n",
            "           1       0.43      0.36      0.39       157\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.58      0.57      0.57       500\n",
            "weighted avg       0.63      0.65      0.64       500\n",
            "\n",
            "f1_score is -0.3357664233576642\n",
            "accuracy is 0.636\n",
            "error rate is 0.364\n",
            "roc_auc_score is 0.5429982730125716\n",
            "gini is 0.08599654602514328\n",
            "[[272  71]\n",
            " [111  46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.39      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.54       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "7\n",
            "7\n",
            "[[7, 0.352], [10, 0.364], [11, 0.32199999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[7.0, 0.352], [11.0, 0.32199999999999995]]), (2, [[10.0, 0.364]])])\n",
            "[7.0, 0.352]\n",
            "round_robin_flag\n",
            "24\n",
            "X_best_t\n",
            "[11.0, 0.32199999999999995]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.45791245791245794\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.6116042413325657\n",
            "gini is 0.2232084826651315\n",
            "[[271  72]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       343\n",
            "           1       0.49      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.62      0.61      0.61       500\n",
            "weighted avg       0.67      0.68      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.4808362369337979\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6308239401311025\n",
            "gini is 0.2616478802622051\n",
            "[[282  61]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.53      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.65      0.63      0.64       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "16 5 22\n",
            "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1]\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "f1_score is -0.3357664233576642\n",
            "accuracy is 0.636\n",
            "error rate is 0.364\n",
            "roc_auc_score is 0.5429982730125716\n",
            "gini is 0.08599654602514328\n",
            "[[272  71]\n",
            " [111  46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75       343\n",
            "           1       0.39      0.29      0.34       157\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.55      0.54      0.54       500\n",
            "weighted avg       0.61      0.64      0.62       500\n",
            "\n",
            "f1_score is -0.3927272727272727\n",
            "accuracy is 0.666\n",
            "error rate is 0.33399999999999996\n",
            "roc_auc_score is 0.5786800616515942\n",
            "gini is 0.1573601233031885\n",
            "[[279  64]\n",
            " [103  54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.81      0.77       343\n",
            "           1       0.46      0.34      0.39       157\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.59      0.58      0.58       500\n",
            "weighted avg       0.64      0.67      0.65       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.31200000000000006], [10, 0.364], [14, 0.33399999999999996]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.31200000000000006], [10.0, 0.364]]), (2, [[14.0, 0.33399999999999996]])])\n",
            "[12.0, 0.31200000000000006]\n",
            "round_robin_flag\n",
            "25\n",
            "X_best_t\n",
            "[12.0, 0.31200000000000006]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.47750865051903113\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.6279084882360588\n",
            "gini is 0.25581697647211765\n",
            "[[280  63]\n",
            " [ 88  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       343\n",
            "           1       0.52      0.44      0.48       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.63      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "4 3 16\n",
            "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.26415094339622636\n",
            "accuracy is 0.61\n",
            "error rate is 0.39\n",
            "roc_auc_score is 0.5050509739837701\n",
            "gini is 0.010101947967540159\n",
            "[[270  73]\n",
            " [122  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.79      0.73       343\n",
            "           1       0.32      0.22      0.26       157\n",
            "\n",
            "    accuracy                           0.61       500\n",
            "   macro avg       0.51      0.51      0.50       500\n",
            "weighted avg       0.57      0.61      0.59       500\n",
            "\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "f1_score is -0.46206896551724136\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.6171658836419007\n",
            "gini is 0.23433176728380145\n",
            "[[277  66]\n",
            " [ 90  67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       343\n",
            "           1       0.50      0.43      0.46       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.62      0.62       500\n",
            "weighted avg       0.68      0.69      0.68       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.39], [15, 0.29800000000000004], [12, 0.31200000000000006]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.39], [15.0, 0.29800000000000004], [12.0, 0.31200000000000006]])])\n",
            "[11.0, 0.39]\n",
            "round_robin_flag\n",
            "26\n",
            "X_best_t\n",
            "[15.0, 0.29800000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "f1_score is -0.46594982078853053\n",
            "accuracy is 0.702\n",
            "error rate is 0.29800000000000004\n",
            "roc_auc_score is 0.6239159904180053\n",
            "gini is 0.24783198083601055\n",
            "[[286  57]\n",
            " [ 92  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       343\n",
            "           1       0.53      0.41      0.47       157\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.69      0.70      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.47058823529411764\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.6232660489127407\n",
            "gini is 0.24653209782548147\n",
            "[[279  64]\n",
            " [ 89  68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       343\n",
            "           1       0.52      0.43      0.47       157\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.64      0.62      0.63       500\n",
            "weighted avg       0.68      0.69      0.69       500\n",
            "\n",
            "[[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]\n",
            "[[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1], [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1], [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]\n",
            "[[[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 15, 0.32199999999999995], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 15, 0.32199999999999995], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], 13, 0.36], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], 13, 0.36], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.31000000000000005], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.31000000000000005], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 15, 0.29800000000000004], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 15, 0.29800000000000004], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.39], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 15, 0.29800000000000004], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1], 9, 0.364], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.362], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.362], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 12, 0.33799999999999997], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1], 13, 0.33599999999999997], [[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], 10, 0.346], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 13, 0.32799999999999996], [[0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 14, 0.32199999999999995], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.38], [[0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 10, 0.35], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 16, 0.32799999999999996], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 16, 0.32799999999999996], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.352], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.352], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.30000000000000004], [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], 13, 0.36], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], 14, 0.33399999999999996], [[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], 14, 0.31999999999999995], [[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], 14, 0.31999999999999995], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 12, 0.31200000000000006], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1], 15, 0.348], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1], 15, 0.348], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], 15, 0.31999999999999995], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], 15, 0.31999999999999995], [[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], 13, 0.33799999999999997], [[0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], 12, 0.34199999999999997], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.31000000000000005], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.31000000000000005], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29600000000000004], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.29800000000000004], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.32199999999999995], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.32199999999999995], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.29800000000000004], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.29800000000000004], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.30200000000000005], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.30600000000000005], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.30600000000000005]]\n",
            "[[[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1]], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1]], [[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]], [[0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]], [[0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]], [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]], [[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]], [[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]], [[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]], [[0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]]\n",
            "[[15, 0.32199999999999995], [15, 0.32199999999999995], [13, 0.36], [13, 0.36], [12, 0.31000000000000005], [12, 0.31000000000000005], [15, 0.29800000000000004], [15, 0.29800000000000004], [11, 0.39], [15, 0.29800000000000004], [9, 0.364], [12, 0.362], [12, 0.362], [12, 0.33799999999999997], [13, 0.33599999999999997], [10, 0.346], [13, 0.32799999999999996], [14, 0.32199999999999995], [9, 0.38], [10, 0.35], [16, 0.32799999999999996], [16, 0.32799999999999996], [7, 0.352], [7, 0.352], [13, 0.30000000000000004], [13, 0.36], [14, 0.33399999999999996], [14, 0.31999999999999995], [14, 0.31999999999999995], [12, 0.31200000000000006], [15, 0.348], [15, 0.348], [15, 0.31999999999999995], [15, 0.31999999999999995], [13, 0.33799999999999997], [12, 0.34199999999999997], [14, 0.31000000000000005], [14, 0.31000000000000005], [11, 0.29600000000000004], [12, 0.29800000000000004], [11, 0.32199999999999995], [11, 0.32199999999999995], [12, 0.29800000000000004], [12, 0.29800000000000004], [10, 0.30200000000000005], [14, 0.30600000000000005], [14, 0.30600000000000005]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DcLGlAGrnAKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.DataFrame([[[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 15, 0.32999999999999996], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 15, 0.32999999999999996], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], 13, 0.30400000000000005], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 15, 0.262], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.264], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.31599999999999995], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.31599999999999995], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 15, 0.262], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 12, 0.30000000000000004], [[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], 11, 0.31999999999999995], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 13, 0.30400000000000005], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 13, 0.30400000000000005], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.31599999999999995], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 16, 0.30400000000000005], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 16, 0.30400000000000005], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 16, 0.30400000000000005], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], 13, 0.30800000000000005], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 12, 0.30200000000000005], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 12, 0.30200000000000005], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 12, 0.30200000000000005], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1], 14, 0.31200000000000006], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], 15, 0.30000000000000004], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], 14, 0.31799999999999995], [[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], 12, 0.31200000000000006], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 13, 0.29000000000000004]])"
      ],
      "metadata": {
        "id": "bTI4pUOWiVOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display.max_colwidth\n",
        "pd.set_option(\"max_colwidth\", 100)\n",
        "#pd.set_option(\"display.precision\", 7)\n",
        "pd.options.display.float_format = '{:,.3f}'.format"
      ],
      "metadata": {
        "id": "srW6jWK8iytj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "um8CMIb9ic8F",
        "outputId": "c9b6a639-5d31-45bd-bafd-8990a7054c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                    0  \\\n",
              "0   [0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]   \n",
              "1   [0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]   \n",
              "2   [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]   \n",
              "3   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
              "4   [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "5   [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "6   [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "7   [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "8   [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "9   [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "10  [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]   \n",
              "11  [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]   \n",
              "12  [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
              "13  [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]   \n",
              "14  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]   \n",
              "15  [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]   \n",
              "16  [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]   \n",
              "17  [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
              "18  [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]   \n",
              "19  [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]   \n",
              "20  [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]   \n",
              "21  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "22  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "23  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "24  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "25  [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]   \n",
              "26  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]   \n",
              "27  [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "28  [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "29  [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "30  [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1]   \n",
              "31  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]   \n",
              "32  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]   \n",
              "33  [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]   \n",
              "34  [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]   \n",
              "35  [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]   \n",
              "36  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "37  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "38  [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]   \n",
              "39  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "40  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "41  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]   \n",
              "42  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]   \n",
              "43  [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]   \n",
              "44  [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]   \n",
              "45  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]   \n",
              "\n",
              "     1     2  \n",
              "0   15 0.330  \n",
              "1   15 0.330  \n",
              "2   13 0.304  \n",
              "3   12 0.288  \n",
              "4   15 0.262  \n",
              "5   14 0.264  \n",
              "6   11 0.316  \n",
              "7   11 0.316  \n",
              "8   10 0.336  \n",
              "9   15 0.262  \n",
              "10  12 0.302  \n",
              "11  12 0.302  \n",
              "12  12 0.300  \n",
              "13  11 0.320  \n",
              "14  14 0.296  \n",
              "15  13 0.304  \n",
              "16  13 0.304  \n",
              "17   9 0.316  \n",
              "18  16 0.304  \n",
              "19  16 0.304  \n",
              "20  16 0.304  \n",
              "21   7 0.292  \n",
              "22   7 0.292  \n",
              "23  13 0.294  \n",
              "24  13 0.294  \n",
              "25  13 0.308  \n",
              "26  14 0.296  \n",
              "27  12 0.302  \n",
              "28  12 0.302  \n",
              "29  12 0.302  \n",
              "30  14 0.312  \n",
              "31  15 0.300  \n",
              "32  14 0.318  \n",
              "33  12 0.312  \n",
              "34  14 0.284  \n",
              "35  14 0.284  \n",
              "36  11 0.292  \n",
              "37  11 0.292  \n",
              "38  12 0.302  \n",
              "39  11 0.282  \n",
              "40  11 0.282  \n",
              "41  12 0.272  \n",
              "42  12 0.272  \n",
              "43  10 0.274  \n",
              "44  10 0.274  \n",
              "45  13 0.290  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cc159ad-501b-4afc-a141-e4248328c066\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>9</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>7</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>7</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cc159ad-501b-4afc-a141-e4248328c066')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cc159ad-501b-4afc-a141-e4248328c066 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cc159ad-501b-4afc-a141-e4248328c066');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_t_plus_1_fitness_1 = [[15, 0.32999999999999996], [15, 0.32999999999999996], [13, 0.30400000000000005], [12, 0.28800000000000003], [15, 0.262], [14, 0.264], [11, 0.31599999999999995], [11, 0.31599999999999995], [10, 0.33599999999999997], [15, 0.262], [12, 0.30200000000000005], [12, 0.30200000000000005], [12, 0.30000000000000004], [11, 0.31999999999999995], [14, 0.29600000000000004], [13, 0.30400000000000005], [13, 0.30400000000000005], [9, 0.31599999999999995], [16, 0.30400000000000005], [16, 0.30400000000000005], [16, 0.30400000000000005], [7, 0.29200000000000004], [7, 0.29200000000000004], [13, 0.29400000000000004], [13, 0.29400000000000004], [13, 0.30800000000000005], [14, 0.29600000000000004], [12, 0.30200000000000005], [12, 0.30200000000000005], [12, 0.30200000000000005], [14, 0.31200000000000006], [15, 0.30000000000000004], [14, 0.31799999999999995], [12, 0.31200000000000006], [14, 0.28400000000000003], [14, 0.28400000000000003], [11, 0.29200000000000004], [11, 0.29200000000000004], [12, 0.30200000000000005], [11, 0.28200000000000003], [11, 0.28200000000000003], [12, 0.272], [12, 0.272], [10, 0.274], [10, 0.274], [13, 0.29000000000000004]]\n",
        "\n",
        "#import operator\n",
        "#list1 = sorted(P_t_plus_1_fitness_1, key=operator.itemgetter(0, 1))\n",
        "#res, smallest_key=non_dominated_sorting(list1)\n",
        "#res, smallest_key=non_dominated_sorting(P_t_plus_1_fitness_1)\n",
        "#res"
      ],
      "metadata": {
        "id": "65u8EzZHVuyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=P_t_plus_1_fitness_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RecLa2KLVu2B",
        "outputId": "5f068a9a-2917-40db-a38f-10cc24921878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[4, 5, 21, 41, 43],\n",
              "  [9, 22, 42, 44],\n",
              "  [17, 39],\n",
              "  [8, 40],\n",
              "  [3, 34, 36],\n",
              "  [45, 35, 37],\n",
              "  [6, 12, 23],\n",
              "  [7, 10, 24],\n",
              "  [13, 11, 14],\n",
              "  [27, 26],\n",
              "  [28, 31],\n",
              "  [29],\n",
              "  [38],\n",
              "  [2, 33],\n",
              "  [15],\n",
              "  [16],\n",
              "  [18, 25],\n",
              "  [19, 30],\n",
              "  [20, 32],\n",
              "  [0],\n",
              "  [1],\n",
              "  []],\n",
              " [[[15, 0.262],\n",
              "   [14, 0.264],\n",
              "   [7, 0.29200000000000004],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274]],\n",
              "  [[15, 0.262], [7, 0.29200000000000004], [12, 0.272], [10, 0.274]],\n",
              "  [[9, 0.31599999999999995], [11, 0.28200000000000003]],\n",
              "  [[10, 0.33599999999999997], [11, 0.28200000000000003]],\n",
              "  [[12, 0.28800000000000003],\n",
              "   [14, 0.28400000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[13, 0.29000000000000004],\n",
              "   [14, 0.28400000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[11, 0.31599999999999995],\n",
              "   [12, 0.30000000000000004],\n",
              "   [13, 0.29400000000000004]],\n",
              "  [[11, 0.31599999999999995],\n",
              "   [12, 0.30200000000000005],\n",
              "   [13, 0.29400000000000004]],\n",
              "  [[11, 0.31999999999999995],\n",
              "   [12, 0.30200000000000005],\n",
              "   [14, 0.29600000000000004]],\n",
              "  [[12, 0.30200000000000005], [14, 0.29600000000000004]],\n",
              "  [[12, 0.30200000000000005], [15, 0.30000000000000004]],\n",
              "  [[12, 0.30200000000000005]],\n",
              "  [[12, 0.30200000000000005]],\n",
              "  [[13, 0.30400000000000005], [12, 0.31200000000000006]],\n",
              "  [[13, 0.30400000000000005]],\n",
              "  [[13, 0.30400000000000005]],\n",
              "  [[16, 0.30400000000000005], [13, 0.30800000000000005]],\n",
              "  [[16, 0.30400000000000005], [14, 0.31200000000000006]],\n",
              "  [[16, 0.30400000000000005], [14, 0.31799999999999995]],\n",
              "  [[15, 0.32999999999999996]],\n",
              "  [[15, 0.32999999999999996]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now applying One bit purifying search"
      ],
      "metadata": {
        "id": "e1YxN_LXV_y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Optimal_front = [\n",
        "   [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "   [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "   [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "   [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
        "   [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
        "]"
      ],
      "metadata": {
        "id": "owrylNOEWAMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPS(S=Optimal_front, optimal_sol=[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggkAHwSyWAPu",
        "outputId": "215f2442-e622-43e1-b105-96d56dea5d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "18\n",
            "13\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.817320703653586\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6408701788267628\n",
            "gini is 0.28174035765352556\n",
            "[[ 63  94]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.40      0.48       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.64      0.65       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8185538881309685\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6506935804349037\n",
            "gini is 0.3013871608698073\n",
            "[[ 67  90]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.87      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "0.008000000000000007\n",
            "0.0040000000000000036\n",
            "0.0040000000000000036\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8167115902964959\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6359584780226922\n",
            "gini is 0.27191695604538446\n",
            "[[ 61  96]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "0.274\n",
            "0.272\n",
            "True False False\n",
            "population Pt saves Xhhat to replace Xh\n",
            "X_h is: \n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "X_h_hat is: \n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8J4PvskWWMQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXdfrvM-WMT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wm_5U8Hf6qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=P_t_plus_1_fitness_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqFhpscZWUqA",
        "outputId": "64edc28c-4318-481c-eb6a-5aafb4bcf024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[4, 5, 21, 41, 43],\n",
              "  [9, 22, 42, 44],\n",
              "  [17, 39],\n",
              "  [8, 40],\n",
              "  [3, 34, 36],\n",
              "  [45, 35, 37],\n",
              "  [6, 12, 23],\n",
              "  [7, 10, 24],\n",
              "  [13, 11, 14],\n",
              "  [27, 26],\n",
              "  [28, 31],\n",
              "  [29],\n",
              "  [38],\n",
              "  [2, 33],\n",
              "  [15],\n",
              "  [16],\n",
              "  [18, 25],\n",
              "  [19, 30],\n",
              "  [20, 32],\n",
              "  [0],\n",
              "  [1],\n",
              "  []],\n",
              " [[[15, 0.262],\n",
              "   [14, 0.264],\n",
              "   [7, 0.29200000000000004],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274]],\n",
              "  [[15, 0.262], [7, 0.29200000000000004], [12, 0.272], [10, 0.274]],\n",
              "  [[9, 0.31599999999999995], [11, 0.28200000000000003]],\n",
              "  [[10, 0.33599999999999997], [11, 0.28200000000000003]],\n",
              "  [[12, 0.28800000000000003],\n",
              "   [14, 0.28400000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[13, 0.29000000000000004],\n",
              "   [14, 0.28400000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[11, 0.31599999999999995],\n",
              "   [12, 0.30000000000000004],\n",
              "   [13, 0.29400000000000004]],\n",
              "  [[11, 0.31599999999999995],\n",
              "   [12, 0.30200000000000005],\n",
              "   [13, 0.29400000000000004]],\n",
              "  [[11, 0.31999999999999995],\n",
              "   [12, 0.30200000000000005],\n",
              "   [14, 0.29600000000000004]],\n",
              "  [[12, 0.30200000000000005], [14, 0.29600000000000004]],\n",
              "  [[12, 0.30200000000000005], [15, 0.30000000000000004]],\n",
              "  [[12, 0.30200000000000005]],\n",
              "  [[12, 0.30200000000000005]],\n",
              "  [[13, 0.30400000000000005], [12, 0.31200000000000006]],\n",
              "  [[13, 0.30400000000000005]],\n",
              "  [[13, 0.30400000000000005]],\n",
              "  [[16, 0.30400000000000005], [13, 0.30800000000000005]],\n",
              "  [[16, 0.30400000000000005], [14, 0.31200000000000006]],\n",
              "  [[16, 0.30400000000000005], [14, 0.31799999999999995]],\n",
              "  [[15, 0.32999999999999996]],\n",
              "  [[15, 0.32999999999999996]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "list1 = sorted(P_t_plus_1_fitness_1, key=operator.itemgetter(0, 1))\n",
        "res=fast_non_dominated_sort(list1)"
      ],
      "metadata": {
        "id": "k9K00IC_gIjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhO1FKcJWVOr",
        "outputId": "1fac6d6e-6bc1-4422-dfc4-ef2b45124625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[7, 0.29200000000000004],\n",
              "  [10, 0.274],\n",
              "  [12, 0.272],\n",
              "  [14, 0.264],\n",
              "  [15, 0.262]],\n",
              " [[7, 0.29200000000000004], [10, 0.274], [12, 0.272], [15, 0.262]],\n",
              " [[9, 0.31599999999999995], [11, 0.28200000000000003]],\n",
              " [[10, 0.33599999999999997], [11, 0.28200000000000003]],\n",
              " [[11, 0.29200000000000004],\n",
              "  [12, 0.28800000000000003],\n",
              "  [14, 0.28400000000000003]],\n",
              " [[11, 0.29200000000000004],\n",
              "  [13, 0.29000000000000004],\n",
              "  [14, 0.28400000000000003]],\n",
              " [[11, 0.31599999999999995],\n",
              "  [12, 0.30000000000000004],\n",
              "  [13, 0.29400000000000004]],\n",
              " [[11, 0.31599999999999995],\n",
              "  [12, 0.30200000000000005],\n",
              "  [13, 0.29400000000000004]],\n",
              " [[11, 0.31999999999999995],\n",
              "  [12, 0.30200000000000005],\n",
              "  [14, 0.29600000000000004]],\n",
              " [[12, 0.30200000000000005], [14, 0.29600000000000004]],\n",
              " [[12, 0.30200000000000005], [15, 0.30000000000000004]],\n",
              " [[12, 0.30200000000000005]],\n",
              " [[12, 0.30200000000000005]],\n",
              " [[12, 0.31200000000000006], [13, 0.30400000000000005]],\n",
              " [[13, 0.30400000000000005]],\n",
              " [[13, 0.30400000000000005]],\n",
              " [[13, 0.30800000000000005], [16, 0.30400000000000005]],\n",
              " [[14, 0.31200000000000006], [16, 0.30400000000000005]],\n",
              " [[14, 0.31799999999999995], [16, 0.30400000000000005]],\n",
              " [[15, 0.32999999999999996]],\n",
              " [[15, 0.32999999999999996]],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round 2"
      ],
      "metadata": {
        "id": "HnfI-2wT1G5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_population = [\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
        "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
        "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
        "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
        "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
        "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
        "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
        "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1],\n",
        "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
        "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
        "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
        "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
        "[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1],\n",
        "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1],\n",
        "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
        "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1],\n",
        "[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1],\n",
        "[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
        "[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1],\n",
        "[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0],\n",
        "[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
        "]"
      ],
      "metadata": {
        "id": "Bst1PVUmgOx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Feature_population)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9H7S3XD1jpi",
        "outputId": "f4e38437-a6d8-490f-fd44-ffe50f8a6a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zv4AV5eFU2Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOFS(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'] ,initial_population= Feature_population)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zXCR_v31jtE",
        "outputId": "6486b6a8-e9d0-430a-f1ee-72cdb91f276b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 21 27\n",
            "[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1] [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.7963446475195823\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.56881023565022\n",
            "gini is 0.13762047130044008\n",
            "[[ 39 118]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.25      0.33       157\n",
            "           1       0.72      0.89      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.57      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.30400000000000005], [12, 0.31200000000000006], [10, 0.262]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.262]]), (1, [[13.0, 0.30400000000000005], [12.0, 0.31200000000000006]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "0\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "17 5 6\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.29600000000000004], [9, 0.31599999999999995], [11, 0.28200000000000003]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[11.0, 0.28200000000000003]]), (1, [[14.0, 0.29600000000000004], [9.0, 0.31599999999999995]])])\n",
            "[11.0, 0.28200000000000003]\n",
            "round_robin_flag\n",
            "1\n",
            "X_best_t\n",
            "[11.0, 0.28200000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "20 10 5\n",
            "[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.30400000000000005], [11, 0.29200000000000004], [9, 0.31599999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[11.0, 0.29200000000000004], [9.0, 0.31599999999999995]]), (1, [[13.0, 0.30400000000000005]])])\n",
            "[11.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "2\n",
            "X_best_t\n",
            "[11.0, 0.29200000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8052631578947368\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.5925609552283152\n",
            "gini is 0.1851219104566304\n",
            "[[ 46 111]\n",
            " [ 37 306]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.29      0.38       157\n",
            "           1       0.73      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.59      0.59       500\n",
            "weighted avg       0.68      0.70      0.67       500\n",
            "\n",
            "19 20 17\n",
            "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1] [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8036649214659686\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5844645410484486\n",
            "gini is 0.16892908209689717\n",
            "[[ 43 114]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.27      0.36       157\n",
            "           1       0.73      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.58      0.58       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.30000000000000004], [13, 0.30400000000000005], [14, 0.29600000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[14.0, 0.29600000000000004]]), (1, [[15.0, 0.30000000000000004], [13.0, 0.30400000000000005]])])\n",
            "[14.0, 0.29600000000000004]\n",
            "round_robin_flag\n",
            "3\n",
            "X_best_t\n",
            "[14.0, 0.29600000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "6 2 7\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.28200000000000003], [7, 0.29200000000000004], [10, 0.33599999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.28200000000000003], [7.0, 0.29200000000000004], [10.0, 0.33599999999999997]])])\n",
            "[11.0, 0.28200000000000003]\n",
            "round_robin_flag\n",
            "4\n",
            "X_best_t\n",
            "[11.0, 0.28200000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.7946308724832215\n",
            "accuracy is 0.694\n",
            "error rate is 0.30600000000000005\n",
            "roc_auc_score is 0.5939072626320774\n",
            "gini is 0.18781452526415476\n",
            "[[ 51 106]\n",
            " [ 47 296]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.32      0.40       157\n",
            "           1       0.74      0.86      0.79       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.63      0.59      0.60       500\n",
            "weighted avg       0.67      0.69      0.67       500\n",
            "\n",
            "21 13 18\n",
            "[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.7963446475195823\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.56881023565022\n",
            "gini is 0.13762047130044008\n",
            "[[ 39 118]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.25      0.33       157\n",
            "           1       0.72      0.89      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.57      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.7973154362416107\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5985497019553955\n",
            "gini is 0.19709940391079095\n",
            "[[ 52 105]\n",
            " [ 46 297]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.60      0.60       500\n",
            "weighted avg       0.67      0.70      0.68       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.31200000000000006], [12, 0.30000000000000004], [12, 0.30200000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[12.0, 0.30000000000000004]]), (0.5, [[12.0, 0.30200000000000005]]), (1, [[12.0, 0.31200000000000006]])])\n",
            "[12.0, 0.30000000000000004]\n",
            "round_robin_flag\n",
            "5\n",
            "X_best_t\n",
            "[12.0, 0.30000000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.791293213828425\n",
            "accuracy is 0.674\n",
            "error rate is 0.32599999999999996\n",
            "roc_auc_score is 0.5396092923065495\n",
            "gini is 0.07921858461309905\n",
            "[[ 28 129]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.18      0.26       157\n",
            "           1       0.71      0.90      0.79       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.58      0.54      0.52       500\n",
            "weighted avg       0.63      0.67      0.62       500\n",
            "\n",
            "7 4 17\n",
            "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.33599999999999997], [10, 0.274], [14, 0.29600000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.274]]), (1, [[10.0, 0.33599999999999997], [14.0, 0.29600000000000004]])])\n",
            "[10.0, 0.274]\n",
            "round_robin_flag\n",
            "6\n",
            "X_best_t\n",
            "[10.0, 0.274]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "24 3 20\n",
            "[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.80306905370844\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5596367755473436\n",
            "gini is 0.11927355109468718\n",
            "[[ 32 125]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.20      0.29       157\n",
            "           1       0.72      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.56      0.55       500\n",
            "weighted avg       0.66      0.69      0.64       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.30800000000000005], [12, 0.272], [13, 0.30400000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[12.0, 0.272]]), (0.5, [[13.0, 0.30400000000000005]]), (1, [[13.0, 0.30800000000000005]])])\n",
            "[12.0, 0.272]\n",
            "round_robin_flag\n",
            "7\n",
            "X_best_t\n",
            "[12.0, 0.272]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "7 12 20\n",
            "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.802992518703242\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5330820226179643\n",
            "gini is 0.06616404523592867\n",
            "[[ 20 137]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.13      0.20       157\n",
            "           1       0.70      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.53      0.50       500\n",
            "weighted avg       0.63      0.68      0.61       500\n",
            "\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.33599999999999997], [11, 0.31599999999999995], [13, 0.30400000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.33599999999999997], [11.0, 0.31599999999999995], [13.0, 0.30400000000000005]])])\n",
            "[10.0, 0.33599999999999997]\n",
            "round_robin_flag\n",
            "8\n",
            "X_best_t\n",
            "[13.0, 0.30400000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.7963683527885863\n",
            "accuracy is 0.686\n",
            "error rate is 0.31399999999999995\n",
            "roc_auc_score is 0.5621715474178752\n",
            "gini is 0.12434309483575046\n",
            "[[ 36 121]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.23      0.31       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.56      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "1 9 23\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.7994722955145118\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5850030640099534\n",
            "gini is 0.17000612801990678\n",
            "[[ 45 112]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.29      0.37       157\n",
            "           1       0.73      0.88      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.59      0.59       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.264], [14, 0.28400000000000003], [16, 0.30400000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.264]]), (2, [[14.0, 0.28400000000000003]]), (3, [[16.0, 0.30400000000000005]])])\n",
            "[14.0, 0.264]\n",
            "round_robin_flag\n",
            "9\n",
            "X_best_t\n",
            "[14.0, 0.264]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8074866310160428\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6122077584445971\n",
            "gini is 0.22441551688919414\n",
            "[[ 54 103]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.43       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "24 8 4\n",
            "[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.80306905370844\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5596367755473436\n",
            "gini is 0.11927355109468718\n",
            "[[ 32 125]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.20      0.29       157\n",
            "           1       0.72      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.56      0.55       500\n",
            "weighted avg       0.66      0.69      0.64       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.30800000000000005], [12, 0.28800000000000003], [10, 0.274]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(-1, [[10.0, 0.274]]), (0, [[12.0, 0.28800000000000003]]), (1, [[13.0, 0.30800000000000005]])])\n",
            "[10.0, 0.274]\n",
            "round_robin_flag\n",
            "10\n",
            "X_best_t\n",
            "[10.0, 0.274]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "10 11 27\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8048452220726783\n",
            "accuracy is 0.71\n",
            "error rate is 0.29000000000000004\n",
            "roc_auc_score is 0.6142040073536239\n",
            "gini is 0.2284080147072478\n",
            "[[ 56 101]\n",
            " [ 44 299]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.36      0.44       157\n",
            "           1       0.75      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.29200000000000004], [13, 0.29000000000000004], [10, 0.262]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.262]]), (1, [[11.0, 0.29200000000000004], [13.0, 0.29000000000000004]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "11\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8048452220726783\n",
            "accuracy is 0.71\n",
            "error rate is 0.29000000000000004\n",
            "roc_auc_score is 0.6142040073536239\n",
            "gini is 0.2284080147072478\n",
            "[[ 56 101]\n",
            " [ 44 299]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.36      0.44       157\n",
            "           1       0.75      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "18 11 19\n",
            "[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.7973154362416107\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5985497019553955\n",
            "gini is 0.19709940391079095\n",
            "[[ 52 105]\n",
            " [ 46 297]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.60      0.60       500\n",
            "weighted avg       0.67      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.8048452220726783\n",
            "accuracy is 0.71\n",
            "error rate is 0.29000000000000004\n",
            "roc_auc_score is 0.6142040073536239\n",
            "gini is 0.2284080147072478\n",
            "[[ 56 101]\n",
            " [ 44 299]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.36      0.44       157\n",
            "           1       0.75      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8036649214659686\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5844645410484486\n",
            "gini is 0.16892908209689717\n",
            "[[ 43 114]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.27      0.36       157\n",
            "           1       0.73      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.58      0.58       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.30200000000000005], [13, 0.29000000000000004], [15, 0.30000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.30200000000000005], [13.0, 0.29000000000000004], [15.0, 0.30000000000000004]])])\n",
            "[12.0, 0.30200000000000005]\n",
            "round_robin_flag\n",
            "12\n",
            "X_best_t\n",
            "[13.0, 0.29000000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.802992518703242\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5330820226179643\n",
            "gini is 0.06616404523592867\n",
            "[[ 20 137]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.13      0.20       157\n",
            "           1       0.70      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.53      0.50       500\n",
            "weighted avg       0.63      0.68      0.61       500\n",
            "\n",
            "f1_score is -0.8048452220726783\n",
            "accuracy is 0.71\n",
            "error rate is 0.29000000000000004\n",
            "roc_auc_score is 0.6142040073536239\n",
            "gini is 0.2284080147072478\n",
            "[[ 56 101]\n",
            " [ 44 299]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.36      0.44       157\n",
            "           1       0.75      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8085642317380353\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5539172903010157\n",
            "gini is 0.10783458060203133\n",
            "[[ 27 130]\n",
            " [ 22 321]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.17      0.26       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.55      0.54       500\n",
            "weighted avg       0.66      0.70      0.64       500\n",
            "\n",
            "25 27 24\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.80306905370844\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5596367755473436\n",
            "gini is 0.11927355109468718\n",
            "[[ 32 125]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.20      0.29       157\n",
            "           1       0.72      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.56      0.55       500\n",
            "weighted avg       0.66      0.69      0.64       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.248], [10, 0.262], [13, 0.30800000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[16.0, 0.248], [10.0, 0.262], [13.0, 0.30800000000000005]])])\n",
            "[16.0, 0.248]\n",
            "round_robin_flag\n",
            "13\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "0 2 27\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.262], [7, 0.29200000000000004], [10, 0.262]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.262]]), (1, [[15.0, 0.262], [7.0, 0.29200000000000004]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "14\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "15 21 25\n",
            "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "f1_score is -0.7963446475195823\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.56881023565022\n",
            "gini is 0.13762047130044008\n",
            "[[ 39 118]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.25      0.33       157\n",
            "           1       0.72      0.89      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.57      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.30200000000000005], [12, 0.31200000000000006], [16, 0.248]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.30200000000000005], [16.0, 0.248]]), (2, [[12.0, 0.31200000000000006]])])\n",
            "[12.0, 0.30200000000000005]\n",
            "round_robin_flag\n",
            "15\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "15 20 17\n",
            "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.30200000000000005], [13, 0.30400000000000005], [14, 0.29600000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.30200000000000005], [14.0, 0.29600000000000004]]), (2, [[13.0, 0.30400000000000005]])])\n",
            "[12.0, 0.30200000000000005]\n",
            "round_robin_flag\n",
            "16\n",
            "X_best_t\n",
            "[14.0, 0.29600000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.7953964194373402\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5457094575773894\n",
            "gini is 0.09141891515477885\n",
            "[[ 29 128]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.18      0.27       157\n",
            "           1       0.71      0.91      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.7953964194373402\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5457094575773894\n",
            "gini is 0.09141891515477885\n",
            "[[ 29 128]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.18      0.27       157\n",
            "           1       0.71      0.91      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "10 3 2\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.29200000000000004], [12, 0.272], [7, 0.29200000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[7.0, 0.29200000000000004]]), (1, [[11.0, 0.29200000000000004], [12.0, 0.272]])])\n",
            "[7.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "17\n",
            "X_best_t\n",
            "[7.0, 0.29200000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "27 8 11\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.8048452220726783\n",
            "accuracy is 0.71\n",
            "error rate is 0.29000000000000004\n",
            "roc_auc_score is 0.6142040073536239\n",
            "gini is 0.2284080147072478\n",
            "[[ 56 101]\n",
            " [ 44 299]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.36      0.44       157\n",
            "           1       0.75      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.262], [12, 0.28800000000000003], [13, 0.29000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.262]]), (2, [[12.0, 0.28800000000000003]]), (3, [[13.0, 0.29000000000000004]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "18\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.7973154362416107\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5985497019553955\n",
            "gini is 0.19709940391079095\n",
            "[[ 52 105]\n",
            " [ 46 297]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.60      0.60       500\n",
            "weighted avg       0.67      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "21 8 15\n",
            "[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n",
            "f1_score is -0.7963446475195823\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.56881023565022\n",
            "gini is 0.13762047130044008\n",
            "[[ 39 118]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.25      0.33       157\n",
            "           1       0.72      0.89      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.57      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.31200000000000006], [12, 0.28800000000000003], [12, 0.30200000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[12.0, 0.28800000000000003]]), (0.5, [[12.0, 0.30200000000000005]]), (1, [[12.0, 0.31200000000000006]])])\n",
            "[12.0, 0.28800000000000003]\n",
            "round_robin_flag\n",
            "19\n",
            "X_best_t\n",
            "[12.0, 0.28800000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8036649214659686\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5844645410484486\n",
            "gini is 0.16892908209689717\n",
            "[[ 43 114]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.27      0.36       157\n",
            "           1       0.73      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.58      0.58       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8068331143232588\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.594018681175837\n",
            "gini is 0.188037362351674\n",
            "[[ 46 111]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.29      0.38       157\n",
            "           1       0.73      0.90      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.59      0.60       500\n",
            "weighted avg       0.68      0.71      0.67       500\n",
            "\n",
            "26 10 27\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.256], [11, 0.29200000000000004], [10, 0.262]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[15.0, 0.256], [11.0, 0.29200000000000004], [10.0, 0.262]])])\n",
            "[15.0, 0.256]\n",
            "round_robin_flag\n",
            "20\n",
            "X_best_t\n",
            "[15.0, 0.256]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8025974025974026\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5746411394403075\n",
            "gini is 0.14928227888061496\n",
            "[[ 39 118]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.25      0.34       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.57       500\n",
            "weighted avg       0.66      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.7890624999999999\n",
            "accuracy is 0.676\n",
            "error rate is 0.32399999999999995\n",
            "roc_auc_score is 0.5531559302519915\n",
            "gini is 0.106311860503983\n",
            "[[ 35 122]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.22      0.30       157\n",
            "           1       0.71      0.88      0.79       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.55      0.55       500\n",
            "weighted avg       0.64      0.68      0.64       500\n",
            "\n",
            "23 27 7\n",
            "[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.7994722955145118\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5850030640099534\n",
            "gini is 0.17000612801990678\n",
            "[[ 45 112]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.29      0.37       157\n",
            "           1       0.73      0.88      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.59      0.59       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.30400000000000005], [10, 0.262], [10, 0.33599999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.262]]), (1, [[16.0, 0.30400000000000005], [10.0, 0.33599999999999997]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "21\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.7963446475195823\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.56881023565022\n",
            "gini is 0.13762047130044008\n",
            "[[ 39 118]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.25      0.33       157\n",
            "           1       0.72      0.89      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.57      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8056628056628057\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5709179031030065\n",
            "gini is 0.141835806206013\n",
            "[[ 36 121]\n",
            " [ 30 313]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.91      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.57      0.56       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "24 7 12\n",
            "[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.80306905370844\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5596367755473436\n",
            "gini is 0.11927355109468718\n",
            "[[ 32 125]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.20      0.29       157\n",
            "           1       0.72      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.56      0.55       500\n",
            "weighted avg       0.66      0.69      0.64       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.802992518703242\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5330820226179643\n",
            "gini is 0.06616404523592867\n",
            "[[ 20 137]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.13      0.20       157\n",
            "           1       0.70      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.53      0.50       500\n",
            "weighted avg       0.63      0.68      0.61       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.30800000000000005], [10, 0.33599999999999997], [11, 0.31599999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[13.0, 0.30800000000000005], [10.0, 0.33599999999999997], [11.0, 0.31599999999999995]])])\n",
            "[13.0, 0.30800000000000005]\n",
            "round_robin_flag\n",
            "22\n",
            "X_best_t\n",
            "[13.0, 0.30800000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]\n",
            "f1_score is -0.7912087912087913\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.610907875434068\n",
            "gini is 0.22181575086813599\n",
            "[[ 60  97]\n",
            " [ 55 288]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.38      0.44       157\n",
            "           1       0.75      0.84      0.79       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.61      0.62       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.80306905370844\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5596367755473436\n",
            "gini is 0.11927355109468718\n",
            "[[ 32 125]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.20      0.29       157\n",
            "           1       0.72      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.56      0.55       500\n",
            "weighted avg       0.66      0.69      0.64       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.80306905370844\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5596367755473436\n",
            "gini is 0.11927355109468718\n",
            "[[ 32 125]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.20      0.29       157\n",
            "           1       0.72      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.56      0.55       500\n",
            "weighted avg       0.66      0.69      0.64       500\n",
            "\n",
            "1 15 13\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.264], [12, 0.30200000000000005], [12, 0.30000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.264], [12.0, 0.30200000000000005], [12.0, 0.30000000000000004]])])\n",
            "[14.0, 0.264]\n",
            "round_robin_flag\n",
            "23\n",
            "X_best_t\n",
            "[14.0, 0.264]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.7994722955145118\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5850030640099534\n",
            "gini is 0.17000612801990678\n",
            "[[ 45 112]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.29      0.37       157\n",
            "           1       0.73      0.88      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.59      0.59       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.794701986754967\n",
            "accuracy is 0.69\n",
            "error rate is 0.31000000000000005\n",
            "roc_auc_score is 0.5806298861673878\n",
            "gini is 0.1612597723347755\n",
            "[[ 45 112]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.29      0.37       157\n",
            "           1       0.73      0.87      0.79       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.58      0.58       500\n",
            "weighted avg       0.66      0.69      0.66       500\n",
            "\n",
            "27 14 3\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.262], [13, 0.29400000000000004], [12, 0.272]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.262]]), (1.5, [[12.0, 0.272]]), (2, [[13.0, 0.29400000000000004]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "24\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.80306905370844\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5596367755473436\n",
            "gini is 0.11927355109468718\n",
            "[[ 32 125]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.20      0.29       157\n",
            "           1       0.72      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.56      0.55       500\n",
            "weighted avg       0.66      0.69      0.64       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8005082592121981\n",
            "accuracy is 0.686\n",
            "error rate is 0.31399999999999995\n",
            "roc_auc_score is 0.5483556479916807\n",
            "gini is 0.09671129598336137\n",
            "[[ 28 129]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.69      0.63       500\n",
            "\n",
            "16 0 27\n",
            "[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1] [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.7953964194373402\n",
            "accuracy is 0.68\n",
            "error rate is 0.31999999999999995\n",
            "roc_auc_score is 0.5457094575773894\n",
            "gini is 0.09141891515477885\n",
            "[[ 29 128]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.18      0.27       157\n",
            "           1       0.71      0.91      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.31999999999999995], [15, 0.262], [10, 0.262]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.262]]), (1, [[11.0, 0.31999999999999995], [15.0, 0.262]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "25\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8322147651006712\n",
            "accuracy is 0.75\n",
            "error rate is 0.25\n",
            "roc_auc_score is 0.65890141315853\n",
            "gini is 0.31780282631706\n",
            "[[ 65  92]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.41      0.51       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.67       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "10 22 7\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.7912087912087913\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.610907875434068\n",
            "gini is 0.22181575086813599\n",
            "[[ 60  97]\n",
            " [ 55 288]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.38      0.44       157\n",
            "           1       0.75      0.84      0.79       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.61      0.62       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.29200000000000004], [13, 0.30400000000000005], [10, 0.33599999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.29200000000000004], [10.0, 0.33599999999999997]]), (2, [[13.0, 0.30400000000000005]])])\n",
            "[11.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "26\n",
            "X_best_t\n",
            "[11.0, 0.29200000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "23 7 12\n",
            "[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.7994722955145118\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5850030640099534\n",
            "gini is 0.17000612801990678\n",
            "[[ 45 112]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.29      0.37       157\n",
            "           1       0.73      0.88      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.59      0.59       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.802992518703242\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5330820226179643\n",
            "gini is 0.06616404523592867\n",
            "[[ 20 137]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.13      0.20       157\n",
            "           1       0.70      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.53      0.50       500\n",
            "weighted avg       0.63      0.68      0.61       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.30400000000000005], [10, 0.33599999999999997], [11, 0.31599999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[16.0, 0.30400000000000005], [10.0, 0.33599999999999997], [11.0, 0.31599999999999995]])])\n",
            "[16.0, 0.30400000000000005]\n",
            "round_robin_flag\n",
            "27\n",
            "X_best_t\n",
            "[16.0, 0.30400000000000005]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.7994722955145118\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5850030640099534\n",
            "gini is 0.17000612801990678\n",
            "[[ 45 112]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.29      0.37       157\n",
            "           1       0.73      0.88      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.59      0.59       500\n",
            "weighted avg       0.67      0.70      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "1\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "[[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]]\n",
            "[[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], [1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]]\n",
            "[[[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.264], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.31599999999999995], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 11, 0.31399999999999995], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.31599999999999995], [[0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 12, 0.30400000000000005], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 12, 0.30000000000000004], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 11, 0.31200000000000006], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], 11, 0.31999999999999995], [[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], 11, 0.31999999999999995], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 12, 0.30200000000000005], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], 14, 0.29400000000000004], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], 13, 0.30400000000000005], [[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], 12, 0.31200000000000006], [[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], 13, 0.30200000000000005], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 13, 0.30400000000000005], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 16, 0.30400000000000005], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 15, 0.31000000000000005], [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], 13, 0.30800000000000005], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262]]\n",
            "[[[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]], [[0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]], [[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]], [[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]], [[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]], [[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]], [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]]]\n",
            "[[14, 0.262], [14, 0.264], [13, 0.266], [7, 0.29200000000000004], [12, 0.272], [13, 0.27], [10, 0.274], [9, 0.31599999999999995], [11, 0.28200000000000003], [11, 0.28200000000000003], [10, 0.33599999999999997], [11, 0.30000000000000004], [12, 0.28800000000000003], [11, 0.31399999999999995], [14, 0.28400000000000003], [11, 0.29200000000000004], [11, 0.29200000000000004], [10, 0.262], [11, 0.31599999999999995], [12, 0.30400000000000005], [12, 0.30000000000000004], [11, 0.31200000000000006], [13, 0.29400000000000004], [13, 0.29400000000000004], [12, 0.30200000000000005], [12, 0.30200000000000005], [11, 0.31999999999999995], [11, 0.31999999999999995], [14, 0.29600000000000004], [14, 0.29600000000000004], [12, 0.30200000000000005], [13, 0.274], [14, 0.29400000000000004], [13, 0.30400000000000005], [12, 0.31200000000000006], [13, 0.30200000000000005], [13, 0.30400000000000005], [16, 0.30400000000000005], [15, 0.31000000000000005], [13, 0.30800000000000005], [16, 0.248], [15, 0.256], [12, 0.28800000000000003], [10, 0.262], [10, 0.262]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame([[[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.264], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.31599999999999995], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 11, 0.31399999999999995], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.31599999999999995], [[0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 12, 0.30400000000000005], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 12, 0.30000000000000004], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 11, 0.31200000000000006], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], 11, 0.31999999999999995], [[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1], 11, 0.31999999999999995], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004], [[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 12, 0.30200000000000005], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], 14, 0.29400000000000004], [[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], 13, 0.30400000000000005], [[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], 12, 0.31200000000000006], [[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], 13, 0.30200000000000005], [[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 13, 0.30400000000000005], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 16, 0.30400000000000005], [[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0], 15, 0.31000000000000005], [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0], 13, 0.30800000000000005], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262]])\n",
        "pd.set_option(\"max_colwidth\", 100)\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s1ptTVhZK39h",
        "outputId": "8c6255e3-cce0-4d7f-ea71-cd3339843753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                    0  \\\n",
              "0   [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "1   [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "2   [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "3   [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "4   [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]   \n",
              "5   [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
              "6   [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]   \n",
              "7   [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
              "8   [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "9   [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "10  [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "11  [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "12  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
              "13  [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
              "14  [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]   \n",
              "15  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "16  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "17  [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
              "18  [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "19  [0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "20  [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
              "21  [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
              "22  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "23  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "24  [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]   \n",
              "25  [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]   \n",
              "26  [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]   \n",
              "27  [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]   \n",
              "28  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]   \n",
              "29  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]   \n",
              "30  [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "31  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "32  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]   \n",
              "33  [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]   \n",
              "34  [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]   \n",
              "35  [1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]   \n",
              "36  [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]   \n",
              "37  [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]   \n",
              "38  [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]   \n",
              "39  [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]   \n",
              "40  [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "41  [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "42  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]   \n",
              "43  [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
              "44  [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
              "\n",
              "     1     2  \n",
              "0   14 0.262  \n",
              "1   14 0.264  \n",
              "2   13 0.266  \n",
              "3    7 0.292  \n",
              "4   12 0.272  \n",
              "5   13 0.270  \n",
              "6   10 0.274  \n",
              "7    9 0.316  \n",
              "8   11 0.282  \n",
              "9   11 0.282  \n",
              "10  10 0.336  \n",
              "11  11 0.300  \n",
              "12  12 0.288  \n",
              "13  11 0.314  \n",
              "14  14 0.284  \n",
              "15  11 0.292  \n",
              "16  11 0.292  \n",
              "17  10 0.262  \n",
              "18  11 0.316  \n",
              "19  12 0.304  \n",
              "20  12 0.300  \n",
              "21  11 0.312  \n",
              "22  13 0.294  \n",
              "23  13 0.294  \n",
              "24  12 0.302  \n",
              "25  12 0.302  \n",
              "26  11 0.320  \n",
              "27  11 0.320  \n",
              "28  14 0.296  \n",
              "29  14 0.296  \n",
              "30  12 0.302  \n",
              "31  13 0.274  \n",
              "32  14 0.294  \n",
              "33  13 0.304  \n",
              "34  12 0.312  \n",
              "35  13 0.302  \n",
              "36  13 0.304  \n",
              "37  16 0.304  \n",
              "38  15 0.310  \n",
              "39  13 0.308  \n",
              "40  16 0.248  \n",
              "41  15 0.256  \n",
              "42  12 0.288  \n",
              "43  10 0.262  \n",
              "44  10 0.262  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-259063b2-9e17-4bde-bc68-17424bf6b24f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>7</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>9</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-259063b2-9e17-4bde-bc68-17424bf6b24f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-259063b2-9e17-4bde-bc68-17424bf6b24f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-259063b2-9e17-4bde-bc68-17424bf6b24f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_t_plus_1_fitness_1 = [[14, 0.262], [14, 0.264], [13, 0.266], [7, 0.29200000000000004], [12, 0.272], [13, 0.27], [10, 0.274], [9, 0.31599999999999995], [11, 0.28200000000000003], [11, 0.28200000000000003], [10, 0.33599999999999997], [11, 0.30000000000000004], [12, 0.28800000000000003], [11, 0.31399999999999995], [14, 0.28400000000000003], [11, 0.29200000000000004], [11, 0.29200000000000004], [10, 0.262], [11, 0.31599999999999995], [12, 0.30400000000000005], [12, 0.30000000000000004], [11, 0.31200000000000006], [13, 0.29400000000000004], [13, 0.29400000000000004], [12, 0.30200000000000005], [12, 0.30200000000000005], [11, 0.31999999999999995], [11, 0.31999999999999995], [14, 0.29600000000000004], [14, 0.29600000000000004], [12, 0.30200000000000005], [13, 0.274], [14, 0.29400000000000004], [13, 0.30400000000000005], [12, 0.31200000000000006], [13, 0.30200000000000005], [13, 0.30400000000000005], [16, 0.30400000000000005], [15, 0.31000000000000005], [13, 0.30800000000000005], [16, 0.248], [15, 0.256], [12, 0.28800000000000003], [10, 0.262], [10, 0.262]]\n",
        "#import operator\n",
        "#list1 = sorted(P_t_plus_1_fitness_1, key=operator.itemgetter(0, 1))\n",
        "#res, smallest_key=non_dominated_sorting(list1)\n",
        "#res, smallest_key=non_dominated_sorting(P_t_plus_1_fitness_1)\n",
        "#res"
      ],
      "metadata": {
        "id": "9UqS-lH71zBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=P_t_plus_1_fitness_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-CfPHvU2KDw",
        "outputId": "01d5bb0a-eda3-40c2-8c61-54091d0e9408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[3, 17, 40, 41],\n",
              "  [7, 43],\n",
              "  [44],\n",
              "  [0, 2, 4, 6],\n",
              "  [1, 5, 8, 10],\n",
              "  [31, 9],\n",
              "  [12, 14, 15],\n",
              "  [42, 16],\n",
              "  [11, 22],\n",
              "  [20, 21, 23],\n",
              "  [24, 13, 32],\n",
              "  [25, 18, 28],\n",
              "  [30, 26, 29],\n",
              "  [19, 35, 27],\n",
              "  [34, 33],\n",
              "  [36],\n",
              "  [37, 39],\n",
              "  [38],\n",
              "  []],\n",
              " [[[7, 0.29200000000000004], [10, 0.262], [16, 0.248], [15, 0.256]],\n",
              "  [[9, 0.31599999999999995], [10, 0.262]],\n",
              "  [[10, 0.262]],\n",
              "  [[14, 0.262], [13, 0.266], [12, 0.272], [10, 0.274]],\n",
              "  [[14, 0.264],\n",
              "   [13, 0.27],\n",
              "   [11, 0.28200000000000003],\n",
              "   [10, 0.33599999999999997]],\n",
              "  [[13, 0.274], [11, 0.28200000000000003]],\n",
              "  [[12, 0.28800000000000003],\n",
              "   [14, 0.28400000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[12, 0.28800000000000003], [11, 0.29200000000000004]],\n",
              "  [[11, 0.30000000000000004], [13, 0.29400000000000004]],\n",
              "  [[12, 0.30000000000000004],\n",
              "   [11, 0.31200000000000006],\n",
              "   [13, 0.29400000000000004]],\n",
              "  [[12, 0.30200000000000005],\n",
              "   [11, 0.31399999999999995],\n",
              "   [14, 0.29400000000000004]],\n",
              "  [[12, 0.30200000000000005],\n",
              "   [11, 0.31599999999999995],\n",
              "   [14, 0.29600000000000004]],\n",
              "  [[12, 0.30200000000000005],\n",
              "   [11, 0.31999999999999995],\n",
              "   [14, 0.29600000000000004]],\n",
              "  [[12, 0.30400000000000005],\n",
              "   [13, 0.30200000000000005],\n",
              "   [11, 0.31999999999999995]],\n",
              "  [[12, 0.31200000000000006], [13, 0.30400000000000005]],\n",
              "  [[13, 0.30400000000000005]],\n",
              "  [[16, 0.30400000000000005], [13, 0.30800000000000005]],\n",
              "  [[15, 0.31000000000000005]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Optimal_front = [\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
        "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
        "]"
      ],
      "metadata": {
        "id": "aBf0SogW2Ro7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPS(S=Optimal_front, optimal_sol=[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ5HH0pTUVRv",
        "outputId": "da8025cd-e0f4-4035-de0d-204bb8ef403d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "9\n",
            "13\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8236877523553162\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6467010826168502\n",
            "gini is 0.29340216523370044\n",
            "[[ 63  94]\n",
            " [ 37 306]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.40      0.49       157\n",
            "           1       0.77      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8268456375838926\n",
            "accuracy is 0.742\n",
            "error rate is 0.258\n",
            "roc_auc_score is 0.6496165345118939\n",
            "gini is 0.2992330690237879\n",
            "[[ 63  94]\n",
            " [ 35 308]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.40      0.49       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.73      0.74      0.72       500\n",
            "\n",
            "0.014000000000000012\n",
            "0.0040000000000000036\n",
            "0.010000000000000009\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8057742782152232\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.5908339678000409\n",
            "gini is 0.18166793560008188\n",
            "[[ 45 112]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.29      0.38       157\n",
            "           1       0.73      0.90      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.59      0.59       500\n",
            "weighted avg       0.68      0.70      0.67       500\n",
            "\n",
            "0.29200000000000004\n",
            "0.29600000000000004\n",
            "False True False\n",
            "opulation keeps X h unchanged\n",
            "X_h is: \n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "X_h_hat is: \n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round 3"
      ],
      "metadata": {
        "id": "vu-oAn-Vca51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_population = [\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
        "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
        "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
        "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
        "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
        "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
        "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
        "[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
        "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
        "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
        "[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
        "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
        "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
        "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1],\n",
        "\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
        "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
        "\n",
        "\n",
        "#[1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "#[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "#[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
        "]"
      ],
      "metadata": {
        "id": "e2paJ-_TU6Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Feature_population)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX5xc_G7cjzj",
        "outputId": "bc6b16b8-4670-4bfe-c36d-a75d75006bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MOFS(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'] ,initial_population= Feature_population)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLr-BcpPcj3N",
        "outputId": "38688731-3219-4c82-b730-d136d4fff21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 19 12\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.248], [12, 0.30000000000000004], [13, 0.274]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[16.0, 0.248], [12.0, 0.30000000000000004], [13.0, 0.274]])])\n",
            "[16.0, 0.248]\n",
            "round_robin_flag\n",
            "0\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "17 0 7\n",
            "[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.30000000000000004], [7, 0.29200000000000004], [10, 0.274]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[7.0, 0.29200000000000004], [10.0, 0.274]]), (1, [[11.0, 0.30000000000000004]])])\n",
            "[7.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "1\n",
            "X_best_t\n",
            "[10.0, 0.274]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "9 7 21\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.27], [10, 0.274], [12, 0.30200000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[13.0, 0.27], [10.0, 0.274], [12.0, 0.30200000000000005]])])\n",
            "[13.0, 0.27]\n",
            "round_robin_flag\n",
            "2\n",
            "X_best_t\n",
            "[13.0, 0.27]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "2 10 11\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.248], [11, 0.28200000000000003], [10, 0.33599999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[16.0, 0.248], [11.0, 0.28200000000000003], [10.0, 0.33599999999999997]])])\n",
            "[16.0, 0.248]\n",
            "round_robin_flag\n",
            "3\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "10 15 5\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.28200000000000003], [11, 0.29200000000000004], [13, 0.266]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.28200000000000003], [13.0, 0.266]]), (2, [[11.0, 0.29200000000000004]])])\n",
            "[11.0, 0.28200000000000003]\n",
            "round_robin_flag\n",
            "4\n",
            "X_best_t\n",
            "[13.0, 0.266]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "1 20 24\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.262], [11, 0.31200000000000006], [15, 0.256]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.262], [15.0, 0.256]]), (2, [[11.0, 0.31200000000000006]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "5\n",
            "X_best_t\n",
            "[15.0, 0.256]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "19 4 22\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.7963683527885863\n",
            "accuracy is 0.686\n",
            "error rate is 0.31399999999999995\n",
            "roc_auc_score is 0.5621715474178752\n",
            "gini is 0.12434309483575046\n",
            "[[ 36 121]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.23      0.31       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.56      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.30000000000000004], [14, 0.262], [11, 0.31399999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.30000000000000004], [14.0, 0.262], [11.0, 0.31399999999999995]])])\n",
            "[12.0, 0.30000000000000004]\n",
            "round_robin_flag\n",
            "6\n",
            "X_best_t\n",
            "[14.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8133333333333334\n",
            "accuracy is 0.72\n",
            "error rate is 0.28\n",
            "roc_auc_score is 0.6197656496629589\n",
            "gini is 0.23953129932591777\n",
            "[[ 55 102]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.35      0.44       157\n",
            "           1       0.75      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "11 20 2\n",
            "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.33599999999999997], [11, 0.31200000000000006], [16, 0.248]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.33599999999999997], [11.0, 0.31200000000000006], [16.0, 0.248]])])\n",
            "[10.0, 0.33599999999999997]\n",
            "round_robin_flag\n",
            "7\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8144192256341789\n",
            "accuracy is 0.722\n",
            "error rate is 0.278\n",
            "roc_auc_score is 0.6229503630387552\n",
            "gini is 0.24590072607751035\n",
            "[[ 56 101]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.36      0.45       157\n",
            "           1       0.75      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "19 4 6\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.30000000000000004], [14, 0.262], [12, 0.272]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[12.0, 0.272]]), (1, [[12.0, 0.30000000000000004], [14.0, 0.262]])])\n",
            "[12.0, 0.272]\n",
            "round_robin_flag\n",
            "8\n",
            "X_best_t\n",
            "[12.0, 0.272]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "6 2 26\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.272], [16, 0.248], [14, 0.29600000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.272], [16.0, 0.248]]), (2, [[14.0, 0.29600000000000004]])])\n",
            "[12.0, 0.272]\n",
            "round_robin_flag\n",
            "9\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8172043010752688\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.634231490594418\n",
            "gini is 0.26846298118883594\n",
            "[[ 60  97]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "24 20 17\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.256], [11, 0.31200000000000006], [11, 0.30000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[15.0, 0.256], [11.0, 0.31200000000000006], [11.0, 0.30000000000000004]])])\n",
            "[15.0, 0.256]\n",
            "round_robin_flag\n",
            "10\n",
            "X_best_t\n",
            "[15.0, 0.256]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "7 16 9\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.274], [12, 0.28800000000000003], [13, 0.27]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.274], [13.0, 0.27]]), (2, [[12.0, 0.28800000000000003]])])\n",
            "[10.0, 0.274]\n",
            "round_robin_flag\n",
            "11\n",
            "X_best_t\n",
            "[13.0, 0.27]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "2 7 19\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.248], [10, 0.274], [12, 0.30000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[16.0, 0.248], [10.0, 0.274], [12.0, 0.30000000000000004]])])\n",
            "[16.0, 0.248]\n",
            "round_robin_flag\n",
            "12\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "16 0 19\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.28800000000000003], [7, 0.29200000000000004], [12, 0.30000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.28800000000000003], [7.0, 0.29200000000000004]]), (2, [[12.0, 0.30000000000000004]])])\n",
            "[12.0, 0.28800000000000003]\n",
            "round_robin_flag\n",
            "13\n",
            "X_best_t\n",
            "[12.0, 0.28800000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "6 15 14\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.272], [11, 0.29200000000000004], [14, 0.28400000000000003]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.272], [11.0, 0.29200000000000004]]), (2, [[14.0, 0.28400000000000003]])])\n",
            "[12.0, 0.272]\n",
            "round_robin_flag\n",
            "14\n",
            "X_best_t\n",
            "[12.0, 0.272]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "8 26 13\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.264], [14, 0.29600000000000004], [12, 0.28800000000000003]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.264], [12.0, 0.28800000000000003]]), (2, [[14.0, 0.29600000000000004]])])\n",
            "[14.0, 0.264]\n",
            "round_robin_flag\n",
            "15\n",
            "X_best_t\n",
            "[14.0, 0.264]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "7 2 19\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.274], [16, 0.248], [12, 0.30000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.274], [16.0, 0.248]]), (2, [[12.0, 0.30000000000000004]])])\n",
            "[10.0, 0.274]\n",
            "round_robin_flag\n",
            "16\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "14 21 0\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.28400000000000003], [12, 0.30200000000000005], [7, 0.29200000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.28400000000000003], [12.0, 0.30200000000000005], [7.0, 0.29200000000000004]])])\n",
            "[14.0, 0.28400000000000003]\n",
            "round_robin_flag\n",
            "17\n",
            "X_best_t\n",
            "[14.0, 0.28400000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "13 26 18\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.28800000000000003], [14, 0.29600000000000004], [13, 0.29400000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.28800000000000003]]), (1.5, [[13.0, 0.29400000000000004]]), (2, [[14.0, 0.29600000000000004]])])\n",
            "[12.0, 0.28800000000000003]\n",
            "round_robin_flag\n",
            "18\n",
            "X_best_t\n",
            "[12.0, 0.28800000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "2 0 5\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.248], [7, 0.29200000000000004], [13, 0.266]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[16.0, 0.248], [7.0, 0.29200000000000004], [13.0, 0.266]])])\n",
            "[16.0, 0.248]\n",
            "round_robin_flag\n",
            "19\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8071979434447302\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5723756290505283\n",
            "gini is 0.1447512581010566\n",
            "[[ 36 121]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.23      0.32       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.57      0.57       500\n",
            "weighted avg       0.67      0.70      0.66       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8010335917312662\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5665447252604408\n",
            "gini is 0.1330894505208815\n",
            "[[ 36 121]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.23      0.32       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.57      0.56       500\n",
            "weighted avg       0.66      0.69      0.65       500\n",
            "\n",
            "2 7 3\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "16\n",
            "16\n",
            "[[16, 0.248], [10, 0.274], [9, 0.31599999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[16.0, 0.248], [10.0, 0.274], [9.0, 0.31599999999999995]])])\n",
            "[16.0, 0.248]\n",
            "round_robin_flag\n",
            "20\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "8 0 3\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.264], [7, 0.29200000000000004], [9, 0.31599999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.264], [7.0, 0.29200000000000004], [9.0, 0.31599999999999995]])])\n",
            "[14.0, 0.264]\n",
            "round_robin_flag\n",
            "21\n",
            "X_best_t\n",
            "[14.0, 0.264]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "10 9 7\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.28200000000000003], [13, 0.27], [10, 0.274]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.274]]), (1, [[11.0, 0.28200000000000003], [13.0, 0.27]])])\n",
            "[10.0, 0.274]\n",
            "round_robin_flag\n",
            "22\n",
            "X_best_t\n",
            "[10.0, 0.274]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.7963683527885863\n",
            "accuracy is 0.686\n",
            "error rate is 0.31399999999999995\n",
            "roc_auc_score is 0.5621715474178752\n",
            "gini is 0.12434309483575046\n",
            "[[ 36 121]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.23      0.31       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.56      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "22 1 9\n",
            "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.7963683527885863\n",
            "accuracy is 0.686\n",
            "error rate is 0.31399999999999995\n",
            "roc_auc_score is 0.5621715474178752\n",
            "gini is 0.12434309483575046\n",
            "[[ 36 121]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.23      0.31       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.56      0.56       500\n",
            "weighted avg       0.65      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.31399999999999995], [10, 0.262], [13, 0.27]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.262]]), (1, [[11.0, 0.31399999999999995], [13.0, 0.27]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "23\n",
            "X_best_t\n",
            "[10.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8068331143232588\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.594018681175837\n",
            "gini is 0.188037362351674\n",
            "[[ 46 111]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.29      0.38       157\n",
            "           1       0.73      0.90      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.59      0.60       500\n",
            "weighted avg       0.68      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "21 26 10\n",
            "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.8076433121019109\n",
            "accuracy is 0.698\n",
            "error rate is 0.30200000000000005\n",
            "roc_auc_score is 0.5640099533899092\n",
            "gini is 0.12801990677981845\n",
            "[[ 32 125]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.20      0.30       157\n",
            "           1       0.72      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.67      0.70      0.65       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.30200000000000005], [14, 0.29600000000000004], [11, 0.28200000000000003]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[11.0, 0.28200000000000003]]), (1, [[12.0, 0.30200000000000005], [14.0, 0.29600000000000004]])])\n",
            "[11.0, 0.28200000000000003]\n",
            "round_robin_flag\n",
            "24\n",
            "X_best_t\n",
            "[11.0, 0.28200000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "25 26 11\n",
            "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.802992518703242\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5330820226179643\n",
            "gini is 0.06616404523592867\n",
            "[[ 20 137]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.13      0.20       157\n",
            "           1       0.70      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.53      0.50       500\n",
            "weighted avg       0.63      0.68      0.61       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.31599999999999995], [14, 0.29600000000000004], [10, 0.33599999999999997]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.31599999999999995], [14.0, 0.29600000000000004], [10.0, 0.33599999999999997]])])\n",
            "[11.0, 0.31599999999999995]\n",
            "round_robin_flag\n",
            "25\n",
            "X_best_t\n",
            "[14.0, 0.29600000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "f1_score is -0.802992518703242\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5330820226179643\n",
            "gini is 0.06616404523592867\n",
            "[[ 20 137]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.13      0.20       157\n",
            "           1       0.70      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.59      0.53      0.50       500\n",
            "weighted avg       0.63      0.68      0.61       500\n",
            "\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.7970297029702971\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5139737423631874\n",
            "gini is 0.02794748472637476\n",
            "[[ 14 143]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.15       157\n",
            "           1       0.69      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.55      0.51      0.47       500\n",
            "weighted avg       0.60      0.67      0.59       500\n",
            "\n",
            "15 9 13\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.29200000000000004], [13, 0.27], [12, 0.28800000000000003]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.29200000000000004], [13.0, 0.27], [12.0, 0.28800000000000003]])])\n",
            "[11.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "26\n",
            "X_best_t\n",
            "[13.0, 0.27]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.802139037433155\n",
            "accuracy is 0.704\n",
            "error rate is 0.29600000000000004\n",
            "roc_auc_score is 0.6029228797979611\n",
            "gini is 0.20584575959592222\n",
            "[[ 52 105]\n",
            " [ 43 300]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.33      0.41       157\n",
            "           1       0.74      0.87      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.797843665768194\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.603461402759466\n",
            "gini is 0.20692280551893205\n",
            "[[ 54 103]\n",
            " [ 47 296]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.34      0.42       157\n",
            "           1       0.74      0.86      0.80       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.60      0.61       500\n",
            "weighted avg       0.68      0.70      0.68       500\n",
            "\n",
            "[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]\n",
            "[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]\n",
            "[[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.31599999999999995], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 10, 0.31200000000000006], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.264], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.28200000000000003], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], 14, 0.272], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 12, 0.30000000000000004], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], 11, 0.30800000000000005], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 11, 0.31200000000000006], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 11, 0.31200000000000006], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], 13, 0.276], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.31599999999999995], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 10, 0.32799999999999996], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004]]\n",
            "[[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]]\n",
            "[[7, 0.29200000000000004], [7, 0.29200000000000004], [10, 0.262], [10, 0.262], [16, 0.248], [13, 0.27], [9, 0.31599999999999995], [10, 0.31200000000000006], [14, 0.262], [14, 0.262], [13, 0.266], [13, 0.266], [12, 0.272], [10, 0.274], [14, 0.264], [13, 0.28200000000000003], [13, 0.27], [11, 0.28200000000000003], [15, 0.256], [10, 0.33599999999999997], [10, 0.33599999999999997], [13, 0.274], [14, 0.272], [12, 0.28800000000000003], [12, 0.28800000000000003], [14, 0.28400000000000003], [14, 0.28400000000000003], [11, 0.29200000000000004], [11, 0.29200000000000004], [12, 0.28800000000000003], [16, 0.248], [11, 0.30000000000000004], [14, 0.28400000000000003], [13, 0.29400000000000004], [13, 0.29400000000000004], [12, 0.30000000000000004], [11, 0.30800000000000005], [11, 0.31200000000000006], [11, 0.31200000000000006], [12, 0.30200000000000005], [12, 0.30200000000000005], [10, 0.274], [13, 0.276], [15, 0.256], [11, 0.28200000000000003], [11, 0.31599999999999995], [10, 0.32799999999999996], [14, 0.29600000000000004]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YIu2h-W6jwro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8BV-MiHrjyaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame([[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.31599999999999995], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 10, 0.31200000000000006], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.264], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.28200000000000003], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], 14, 0.272], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 12, 0.30000000000000004], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], 11, 0.30800000000000005], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 11, 0.31200000000000006], [[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], 11, 0.31200000000000006], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], 12, 0.30200000000000005], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], 13, 0.276], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.31599999999999995], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 10, 0.32799999999999996], [[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 14, 0.29600000000000004]])\n",
        "pd.set_option(\"max_colwidth\", 100)\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vBad5V_ZdUrW",
        "outputId": "f40db0dd-0f1a-4d0f-8a1e-9a5d2896fdc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                    0  \\\n",
              "0   [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "1   [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "2   [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
              "3   [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
              "4   [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "5   [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
              "6   [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
              "7   [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
              "8   [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "9   [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "10  [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "11  [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "12  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]   \n",
              "13  [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]   \n",
              "14  [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "15  [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "16  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
              "17  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "18  [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "19  [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "20  [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "21  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "22  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "23  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
              "24  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
              "25  [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]   \n",
              "26  [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]   \n",
              "27  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "28  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "29  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]   \n",
              "30  [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "31  [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "32  [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]   \n",
              "33  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "34  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "35  [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
              "36  [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]   \n",
              "37  [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
              "38  [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
              "39  [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]   \n",
              "40  [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]   \n",
              "41  [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]   \n",
              "42  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]   \n",
              "43  [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "44  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "45  [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "46  [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "47  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]   \n",
              "\n",
              "     1     2  \n",
              "0    7 0.292  \n",
              "1    7 0.292  \n",
              "2   10 0.262  \n",
              "3   10 0.262  \n",
              "4   16 0.248  \n",
              "5   13 0.270  \n",
              "6    9 0.316  \n",
              "7   10 0.312  \n",
              "8   14 0.262  \n",
              "9   14 0.262  \n",
              "10  13 0.266  \n",
              "11  13 0.266  \n",
              "12  12 0.272  \n",
              "13  10 0.274  \n",
              "14  14 0.264  \n",
              "15  13 0.282  \n",
              "16  13 0.270  \n",
              "17  11 0.282  \n",
              "18  15 0.256  \n",
              "19  10 0.336  \n",
              "20  10 0.336  \n",
              "21  13 0.274  \n",
              "22  14 0.272  \n",
              "23  12 0.288  \n",
              "24  12 0.288  \n",
              "25  14 0.284  \n",
              "26  14 0.284  \n",
              "27  11 0.292  \n",
              "28  11 0.292  \n",
              "29  12 0.288  \n",
              "30  16 0.248  \n",
              "31  11 0.300  \n",
              "32  14 0.284  \n",
              "33  13 0.294  \n",
              "34  13 0.294  \n",
              "35  12 0.300  \n",
              "36  11 0.308  \n",
              "37  11 0.312  \n",
              "38  11 0.312  \n",
              "39  12 0.302  \n",
              "40  12 0.302  \n",
              "41  10 0.274  \n",
              "42  13 0.276  \n",
              "43  15 0.256  \n",
              "44  11 0.282  \n",
              "45  11 0.316  \n",
              "46  10 0.328  \n",
              "47  14 0.296  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d80aaaf-49e1-4776-b9b5-a1a6bc4aa572\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>7</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>7</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>9</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d80aaaf-49e1-4776-b9b5-a1a6bc4aa572')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d80aaaf-49e1-4776-b9b5-a1a6bc4aa572 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d80aaaf-49e1-4776-b9b5-a1a6bc4aa572');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_t_plus_1_fitness_1 = [[7, 0.29200000000000004], [7, 0.29200000000000004], [10, 0.262], [10, 0.262], [16, 0.248], [13, 0.27], [9, 0.31599999999999995], [10, 0.31200000000000006], [14, 0.262], [14, 0.262], [13, 0.266], [13, 0.266], [12, 0.272], [10, 0.274], [14, 0.264], [13, 0.28200000000000003], [13, 0.27], [11, 0.28200000000000003], [15, 0.256], [10, 0.33599999999999997], [10, 0.33599999999999997], [13, 0.274], [14, 0.272], [12, 0.28800000000000003], [12, 0.28800000000000003], [14, 0.28400000000000003], [14, 0.28400000000000003], [11, 0.29200000000000004], [11, 0.29200000000000004], [12, 0.28800000000000003], [16, 0.248], [11, 0.30000000000000004], [14, 0.28400000000000003], [13, 0.29400000000000004], [13, 0.29400000000000004], [12, 0.30000000000000004], [11, 0.30800000000000005], [11, 0.31200000000000006], [11, 0.31200000000000006], [12, 0.30200000000000005], [12, 0.30200000000000005], [10, 0.274], [13, 0.276], [15, 0.256], [11, 0.28200000000000003], [11, 0.31599999999999995], [10, 0.32799999999999996], [14, 0.29600000000000004]]\n",
        "#import operator\n",
        "#list1 = sorted(P_t_plus_1_fitness_1, key=operator.itemgetter(0, 1))\n",
        "#res, smallest_key=non_dominated_sorting(list1)\n",
        "#res, smallest_key=non_dominated_sorting(P_t_plus_1_fitness_1)\n",
        "#res"
      ],
      "metadata": {
        "id": "HJJU24i-dVLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=P_t_plus_1_fitness_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Dv69DSdVO6",
        "outputId": "a74dd1b5-b69e-422d-fe9b-fc5027603e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0, 2, 4, 18],\n",
              "  [1, 3, 30, 43],\n",
              "  [6, 8, 10, 12, 13],\n",
              "  [9, 11, 41],\n",
              "  [14, 5, 7, 17],\n",
              "  [16, 46, 44],\n",
              "  [21, 22, 19, 23, 27],\n",
              "  [42, 20, 24, 28],\n",
              "  [15, 29, 31],\n",
              "  [25, 33, 35, 36],\n",
              "  [26, 34, 39, 37],\n",
              "  [32, 40, 38],\n",
              "  [47, 45],\n",
              "  []],\n",
              " [[[7, 0.29200000000000004], [10, 0.262], [16, 0.248], [15, 0.256]],\n",
              "  [[7, 0.29200000000000004], [10, 0.262], [16, 0.248], [15, 0.256]],\n",
              "  [[9, 0.31599999999999995],\n",
              "   [14, 0.262],\n",
              "   [13, 0.266],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274]],\n",
              "  [[14, 0.262], [13, 0.266], [10, 0.274]],\n",
              "  [[14, 0.264],\n",
              "   [13, 0.27],\n",
              "   [10, 0.31200000000000006],\n",
              "   [11, 0.28200000000000003]],\n",
              "  [[13, 0.27], [10, 0.32799999999999996], [11, 0.28200000000000003]],\n",
              "  [[13, 0.274],\n",
              "   [14, 0.272],\n",
              "   [10, 0.33599999999999997],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[13, 0.276],\n",
              "   [10, 0.33599999999999997],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[13, 0.28200000000000003],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.30000000000000004]],\n",
              "  [[14, 0.28400000000000003],\n",
              "   [13, 0.29400000000000004],\n",
              "   [12, 0.30000000000000004],\n",
              "   [11, 0.30800000000000005]],\n",
              "  [[14, 0.28400000000000003],\n",
              "   [13, 0.29400000000000004],\n",
              "   [12, 0.30200000000000005],\n",
              "   [11, 0.31200000000000006]],\n",
              "  [[14, 0.28400000000000003],\n",
              "   [12, 0.30200000000000005],\n",
              "   [11, 0.31200000000000006]],\n",
              "  [[14, 0.29600000000000004], [11, 0.31599999999999995]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Optimal_front = [\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "]"
      ],
      "metadata": {
        "id": "ie5rp9Gcj1rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPS(S=Optimal_front, optimal_sol=[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY-aQdz_j2Za",
        "outputId": "3cee2635-84ee-43b1-894e-bceb75d84ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "4\n",
            "3\n",
            "[1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.8266666666666668\n",
            "accuracy is 0.74\n",
            "error rate is 0.26\n",
            "roc_auc_score is 0.6429778462795491\n",
            "gini is 0.28595569255909825\n",
            "[[ 60  97]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.38      0.48       157\n",
            "           1       0.76      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.73      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8175765645805593\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6258658149337988\n",
            "gini is 0.25173162986759756\n",
            "[[ 56 101]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.45       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "0.0040000000000000036\n",
            "-0.014000000000000012\n",
            "0.018000000000000016\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "0.256\n",
            "0.256\n",
            "False False True\n",
            "it saves both Xh and Xhhat into Pt\n",
            "X_h is: \n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X_h_hat is: \n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPS(S=Optimal_front, optimal_sol=[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLIKDELkjpwu",
        "outputId": "2a1b5e76-a299-4abe-b492-df708fcceb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "10\n",
            "11\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8071065989847717\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5590982525858387\n",
            "gini is 0.11819650517167735\n",
            "[[ 30 127]\n",
            " [ 25 318]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.19      0.28       157\n",
            "           1       0.71      0.93      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.66      0.70      0.64       500\n",
            "\n",
            "f1_score is -0.8151041666666666\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.5995803234851721\n",
            "gini is 0.1991606469703442\n",
            "[[ 45 112]\n",
            " [ 30 313]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.29      0.39       157\n",
            "           1       0.74      0.91      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.60      0.60       500\n",
            "weighted avg       0.69      0.72      0.68       500\n",
            "\n",
            "0.05600000000000005\n",
            "0.020000000000000018\n",
            "0.03600000000000003\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8071065989847717\n",
            "accuracy is 0.696\n",
            "error rate is 0.30400000000000005\n",
            "roc_auc_score is 0.5590982525858387\n",
            "gini is 0.11819650517167735\n",
            "[[ 30 127]\n",
            " [ 25 318]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.19      0.28       157\n",
            "           1       0.71      0.93      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.63      0.56      0.55       500\n",
            "weighted avg       0.66      0.70      0.64       500\n",
            "\n",
            "0.248\n",
            "0.30400000000000005\n",
            "False False True\n",
            "it saves both Xh and Xhhat into Pt\n",
            "X_h is: \n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "X_h_hat is: \n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round 4"
      ],
      "metadata": {
        "id": "32RZSZ5kjiXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_population = [\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
        "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
        "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
        "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
        "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
        "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
        "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0],\n",
        "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
        "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
        "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1],\n",
        "[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
        "[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
        "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
        "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
        "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "]"
      ],
      "metadata": {
        "id": "JPsd6ds-oRtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Feature_population)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPSRqlghoR1u",
        "outputId": "78dd9b78-41c7-4fe2-b862-888cb40f6fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MOFS(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target , target_test = test_up['Creditability'] ,initial_population= Feature_population)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9WEY_ZDECw9",
        "outputId": "90f8ea8d-42ae-4ed3-99be-095ef5d31b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 7 23\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.27], [12, 0.272], [14, 0.28400000000000003]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[13.0, 0.27], [12.0, 0.272]]), (2, [[14.0, 0.28400000000000003]])])\n",
            "[13.0, 0.27]\n",
            "round_robin_flag\n",
            "0\n",
            "X_best_t\n",
            "[13.0, 0.27]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "9 20 15\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.264], [13, 0.28200000000000003], [14, 0.272]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.264], [13.0, 0.28200000000000003]]), (2, [[14.0, 0.272]])])\n",
            "[14.0, 0.264]\n",
            "round_robin_flag\n",
            "1\n",
            "X_best_t\n",
            "[14.0, 0.264]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "3 13 8\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.7970297029702971\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5139737423631874\n",
            "gini is 0.02794748472637476\n",
            "[[ 14 143]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.15       157\n",
            "           1       0.69      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.55      0.51      0.47       500\n",
            "weighted avg       0.60      0.67      0.59       500\n",
            "\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "15\n",
            "15\n",
            "[[15, 0.256], [10, 0.32799999999999996], [10, 0.274]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[15.0, 0.256], [10.0, 0.32799999999999996], [10.0, 0.274]])])\n",
            "[15.0, 0.256]\n",
            "round_robin_flag\n",
            "2\n",
            "X_best_t\n",
            "[15.0, 0.256]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "15 23 2\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0] [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.272], [14, 0.28400000000000003], [16, 0.248]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.272], [16.0, 0.248]]), (2, [[14.0, 0.28400000000000003]])])\n",
            "[14.0, 0.272]\n",
            "round_robin_flag\n",
            "3\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8274932614555256\n",
            "accuracy is 0.744\n",
            "error rate is 0.256\n",
            "roc_auc_score is 0.6545282353159645\n",
            "gini is 0.309056470631929\n",
            "[[ 65  92]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.71      0.65      0.67       500\n",
            "weighted avg       0.73      0.74      0.73       500\n",
            "\n",
            "14 15 2\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0] [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.274], [14, 0.272], [16, 0.248]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[13.0, 0.274], [14.0, 0.272], [16.0, 0.248]])])\n",
            "[13.0, 0.274]\n",
            "round_robin_flag\n",
            "4\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "7 4 19\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.272], [9, 0.31599999999999995], [13, 0.276]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.272], [9.0, 0.31599999999999995]]), (2, [[13.0, 0.276]])])\n",
            "[12.0, 0.272]\n",
            "round_robin_flag\n",
            "5\n",
            "X_best_t\n",
            "[12.0, 0.272]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8147138964577655\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6428664277357895\n",
            "gini is 0.285732855471579\n",
            "[[ 65  92]\n",
            " [ 44 299]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.41      0.49       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.64      0.65       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "5 26 24\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.262], [14, 0.246], [13, 0.29400000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[14.0, 0.246], [13.0, 0.29400000000000004]]), (1, [[14.0, 0.262]])])\n",
            "[14.0, 0.246]\n",
            "round_robin_flag\n",
            "6\n",
            "X_best_t\n",
            "[14.0, 0.246]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "22 16 10\n",
            "[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.30000000000000004], [10, 0.33599999999999997], [13, 0.27]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.30000000000000004], [10.0, 0.33599999999999997], [13.0, 0.27]])])\n",
            "[11.0, 0.30000000000000004]\n",
            "round_robin_flag\n",
            "7\n",
            "X_best_t\n",
            "[13.0, 0.27]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "24 1 2\n",
            "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0] [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.29400000000000004], [10, 0.262], [16, 0.248]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[10.0, 0.262], [16.0, 0.248]]), (1, [[13.0, 0.29400000000000004]])])\n",
            "[10.0, 0.262]\n",
            "round_robin_flag\n",
            "8\n",
            "X_best_t\n",
            "[16.0, 0.248]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.815114709851552\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6345007520751704\n",
            "gini is 0.26900150415034085\n",
            "[[ 61  96]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47       157\n",
            "           1       0.76      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8144192256341789\n",
            "accuracy is 0.722\n",
            "error rate is 0.278\n",
            "roc_auc_score is 0.6229503630387552\n",
            "gini is 0.24590072607751035\n",
            "[[ 56 101]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.36      0.45       157\n",
            "           1       0.75      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "21 16 18\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.28800000000000003], [10, 0.33599999999999997], [11, 0.29200000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.28800000000000003], [10.0, 0.33599999999999997], [11.0, 0.29200000000000004]])])\n",
            "[12.0, 0.28800000000000003]\n",
            "round_robin_flag\n",
            "9\n",
            "X_best_t\n",
            "[12.0, 0.28800000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8201634877384196\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6521513063824256\n",
            "gini is 0.30430261276485115\n",
            "[[ 67  90]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.43      0.50       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8179347826086957\n",
            "accuracy is 0.732\n",
            "error rate is 0.268\n",
            "roc_auc_score is 0.6457818796308332\n",
            "gini is 0.29156375926166644\n",
            "[[ 65  92]\n",
            " [ 42 301]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.41      0.49       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.65      0.66       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "25 6 18\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1] [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8010335917312662\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5665447252604408\n",
            "gini is 0.1330894505208815\n",
            "[[ 36 121]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.23      0.32       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.57      0.56       500\n",
            "weighted avg       0.66      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.30800000000000005], [13, 0.266], [11, 0.29200000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[11.0, 0.29200000000000004]]), (1, [[11.0, 0.30800000000000005], [13.0, 0.266]])])\n",
            "[11.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "10\n",
            "X_best_t\n",
            "[11.0, 0.29200000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "11 20 24\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.31200000000000006], [13, 0.28200000000000003], [13, 0.29400000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.31200000000000006], [13.0, 0.28200000000000003], [13.0, 0.29400000000000004]])])\n",
            "[10.0, 0.31200000000000006]\n",
            "round_robin_flag\n",
            "11\n",
            "X_best_t\n",
            "[13.0, 0.28200000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.7887323943661971\n",
            "accuracy is 0.67\n",
            "error rate is 0.32999999999999996\n",
            "roc_auc_score is 0.5349668529832315\n",
            "gini is 0.06993370596646309\n",
            "[[ 27 130]\n",
            " [ 35 308]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.17      0.25       157\n",
            "           1       0.70      0.90      0.79       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.57      0.53      0.52       500\n",
            "weighted avg       0.62      0.67      0.62       500\n",
            "\n",
            "25 11 0\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "f1_score is -0.8010335917312662\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5665447252604408\n",
            "gini is 0.1330894505208815\n",
            "[[ 36 121]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.23      0.32       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.57      0.56       500\n",
            "weighted avg       0.66      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.30800000000000005], [10, 0.31200000000000006], [7, 0.29200000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[7.0, 0.29200000000000004]]), (1, [[11.0, 0.30800000000000005], [10.0, 0.31200000000000006]])])\n",
            "[7.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "12\n",
            "X_best_t\n",
            "[7.0, 0.29200000000000004]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "13 16 26\n",
            "[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.7970297029702971\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5139737423631874\n",
            "gini is 0.02794748472637476\n",
            "[[ 14 143]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.15       157\n",
            "           1       0.69      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.55      0.51      0.47       500\n",
            "weighted avg       0.60      0.67      0.59       500\n",
            "\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.32799999999999996], [10, 0.33599999999999997], [14, 0.246]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.32799999999999996], [14.0, 0.246]]), (2, [[10.0, 0.33599999999999997]])])\n",
            "[10.0, 0.32799999999999996]\n",
            "round_robin_flag\n",
            "13\n",
            "X_best_t\n",
            "[14.0, 0.246]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.7970297029702971\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5139737423631874\n",
            "gini is 0.02794748472637476\n",
            "[[ 14 143]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.15       157\n",
            "           1       0.69      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.55      0.51      0.47       500\n",
            "weighted avg       0.60      0.67      0.59       500\n",
            "\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.7990012484394508\n",
            "accuracy is 0.678\n",
            "error rate is 0.32199999999999995\n",
            "roc_auc_score is 0.5269818573471244\n",
            "gini is 0.05396371469424888\n",
            "[[ 19 138]\n",
            " [ 23 320]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.12      0.19       157\n",
            "           1       0.70      0.93      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.58      0.53      0.49       500\n",
            "weighted avg       0.62      0.68      0.61       500\n",
            "\n",
            "0 10 13\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.806878306878307\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6006573694081818\n",
            "gini is 0.20131473881636364\n",
            "[[ 49 108]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.31      0.40       157\n",
            "           1       0.74      0.89      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.60      0.60       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.7970297029702971\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5139737423631874\n",
            "gini is 0.02794748472637476\n",
            "[[ 14 143]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.15       157\n",
            "           1       0.69      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.55      0.51      0.47       500\n",
            "weighted avg       0.60      0.67      0.59       500\n",
            "\n",
            "7\n",
            "7\n",
            "[[7, 0.29200000000000004], [13, 0.27], [10, 0.32799999999999996]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[7.0, 0.29200000000000004], [13.0, 0.27]]), (2, [[10.0, 0.32799999999999996]])])\n",
            "[7.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "14\n",
            "X_best_t\n",
            "[13.0, 0.27]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "12 21 24\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0] [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.28200000000000003], [12, 0.28800000000000003], [13, 0.29400000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.28200000000000003]]), (2, [[12.0, 0.28800000000000003]]), (3, [[13.0, 0.29400000000000004]])])\n",
            "[11.0, 0.28200000000000003]\n",
            "round_robin_flag\n",
            "15\n",
            "X_best_t\n",
            "[11.0, 0.28200000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8112449799196786\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.6200349111437113\n",
            "gini is 0.24006982228742269\n",
            "[[ 56 101]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.44       157\n",
            "           1       0.75      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "26 22 11\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "f1_score is -0.8015267175572519\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.551540361367477\n",
            "gini is 0.10308072273495394\n",
            "[[ 29 128]\n",
            " [ 28 315]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.18      0.27       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.61      0.55      0.54       500\n",
            "weighted avg       0.65      0.69      0.63       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.246], [11, 0.30000000000000004], [10, 0.31200000000000006]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.246], [11.0, 0.30000000000000004], [10.0, 0.31200000000000006]])])\n",
            "[14.0, 0.246]\n",
            "round_robin_flag\n",
            "16\n",
            "X_best_t\n",
            "[14.0, 0.246]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "21 19 17\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.28800000000000003], [13, 0.276], [12, 0.28800000000000003]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.28800000000000003], [13.0, 0.276], [12.0, 0.28800000000000003]])])\n",
            "[12.0, 0.28800000000000003]\n",
            "round_robin_flag\n",
            "17\n",
            "X_best_t\n",
            "[13.0, 0.276]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "16 5 19\n",
            "[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
            "f1_score is -0.7873417721518987\n",
            "accuracy is 0.664\n",
            "error rate is 0.33599999999999997\n",
            "roc_auc_score is 0.52023175057102\n",
            "gini is 0.040463501142040004\n",
            "[[ 21 136]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.13      0.20       157\n",
            "           1       0.70      0.91      0.79       343\n",
            "\n",
            "    accuracy                           0.66       500\n",
            "   macro avg       0.55      0.52      0.49       500\n",
            "weighted avg       0.60      0.66      0.60       500\n",
            "\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "10\n",
            "10\n",
            "[[10, 0.33599999999999997], [14, 0.262], [13, 0.276]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[10.0, 0.33599999999999997], [14.0, 0.262], [13.0, 0.276]])])\n",
            "[10.0, 0.33599999999999997]\n",
            "round_robin_flag\n",
            "18\n",
            "X_best_t\n",
            "[14.0, 0.262]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8217687074829932\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6536090323299475\n",
            "gini is 0.307218064659895\n",
            "[[ 67  90]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.43      0.51       157\n",
            "           1       0.77      0.88      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.72      0.74      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "22 20 25\n",
            "[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1] [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8010335917312662\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5665447252604408\n",
            "gini is 0.1330894505208815\n",
            "[[ 36 121]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.23      0.32       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.57      0.56       500\n",
            "weighted avg       0.66      0.69      0.65       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.30000000000000004], [13, 0.28200000000000003], [11, 0.30800000000000005]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.30000000000000004], [13.0, 0.28200000000000003]]), (2, [[11.0, 0.30800000000000005]])])\n",
            "[11.0, 0.30000000000000004]\n",
            "round_robin_flag\n",
            "19\n",
            "X_best_t\n",
            "[13.0, 0.28200000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "25 13 14\n",
            "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0] [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.8010335917312662\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5665447252604408\n",
            "gini is 0.1330894505208815\n",
            "[[ 36 121]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.23      0.32       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.57      0.56       500\n",
            "weighted avg       0.66      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.7970297029702971\n",
            "accuracy is 0.672\n",
            "error rate is 0.32799999999999996\n",
            "roc_auc_score is 0.5139737423631874\n",
            "gini is 0.02794748472637476\n",
            "[[ 14 143]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.15       157\n",
            "           1       0.69      0.94      0.80       343\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.55      0.51      0.47       500\n",
            "weighted avg       0.60      0.67      0.59       500\n",
            "\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.30800000000000005], [10, 0.32799999999999996], [13, 0.274]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.30800000000000005], [10.0, 0.32799999999999996], [13.0, 0.274]])])\n",
            "[11.0, 0.30800000000000005]\n",
            "round_robin_flag\n",
            "20\n",
            "X_best_t\n",
            "[13.0, 0.274]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8086838534599728\n",
            "accuracy is 0.718\n",
            "error rate is 0.28200000000000003\n",
            "roc_auc_score is 0.628669848285083\n",
            "gini is 0.257339696570166\n",
            "[[ 61  96]\n",
            " [ 45 298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.46       157\n",
            "           1       0.76      0.87      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.67      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "23 6 15\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.28400000000000003], [13, 0.266], [14, 0.272]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(0, [[13.0, 0.266]]), (0.5, [[14.0, 0.272]]), (1, [[14.0, 0.28400000000000003]])])\n",
            "[13.0, 0.266]\n",
            "round_robin_flag\n",
            "21\n",
            "X_best_t\n",
            "[13.0, 0.266]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "10 26 7\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1] [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "f1_score is -0.818791946308725\n",
            "accuracy is 0.73\n",
            "error rate is 0.27\n",
            "roc_auc_score is 0.6356892165419399\n",
            "gini is 0.27137843308387977\n",
            "[[ 60  97]\n",
            " [ 38 305]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "13\n",
            "13\n",
            "[[13, 0.27], [14, 0.246], [12, 0.272]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[13.0, 0.27], [14.0, 0.246], [12.0, 0.272]])])\n",
            "[13.0, 0.27]\n",
            "round_robin_flag\n",
            "22\n",
            "X_best_t\n",
            "[14.0, 0.246]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "4 21 22\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0] [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8110831234256927\n",
            "accuracy is 0.7\n",
            "error rate is 0.30000000000000004\n",
            "roc_auc_score is 0.5585597296243339\n",
            "gini is 0.11711945924866773\n",
            "[[ 28 129]\n",
            " [ 21 322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.18      0.27       157\n",
            "           1       0.71      0.94      0.81       343\n",
            "\n",
            "    accuracy                           0.70       500\n",
            "   macro avg       0.64      0.56      0.54       500\n",
            "weighted avg       0.67      0.70      0.64       500\n",
            "\n",
            "9\n",
            "9\n",
            "[[9, 0.31599999999999995], [12, 0.28800000000000003], [11, 0.30000000000000004]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[9.0, 0.31599999999999995], [12.0, 0.28800000000000003], [11.0, 0.30000000000000004]])])\n",
            "[9.0, 0.31599999999999995]\n",
            "round_robin_flag\n",
            "23\n",
            "X_best_t\n",
            "[12.0, 0.28800000000000003]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
            "f1_score is -0.8054794520547944\n",
            "accuracy is 0.716\n",
            "error rate is 0.28400000000000003\n",
            "roc_auc_score is 0.632393084622384\n",
            "gini is 0.26478616924476794\n",
            "[[ 64  93]\n",
            " [ 49 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47       157\n",
            "           1       0.76      0.86      0.81       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.66      0.63      0.64       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8079999999999999\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.6104807710163229\n",
            "gini is 0.22096154203264584\n",
            "[[ 53 104]\n",
            " [ 40 303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.34      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.61      0.62       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "15 19 14\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0] [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1] [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.8174603174603174\n",
            "accuracy is 0.724\n",
            "error rate is 0.276\n",
            "roc_auc_score is 0.619227126701454\n",
            "gini is 0.23845425340290793\n",
            "[[ 53 104]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.43       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.70      0.72      0.70       500\n",
            "\n",
            "f1_score is -0.8185430463576158\n",
            "accuracy is 0.726\n",
            "error rate is 0.274\n",
            "roc_auc_score is 0.6224118400772503\n",
            "gini is 0.2448236801545005\n",
            "[[ 54 103]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.62      0.63       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "14\n",
            "14\n",
            "[[14, 0.272], [13, 0.276], [13, 0.274]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[14.0, 0.272], [13.0, 0.276], [13.0, 0.274]])])\n",
            "[14.0, 0.272]\n",
            "round_robin_flag\n",
            "24\n",
            "X_best_t\n",
            "[14.0, 0.272]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.796116504854369\n",
            "accuracy is 0.706\n",
            "error rate is 0.29400000000000004\n",
            "roc_auc_score is 0.6285584297413234\n",
            "gini is 0.25711685948264673\n",
            "[[ 66  91]\n",
            " [ 56 287]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.42      0.47       157\n",
            "           1       0.76      0.84      0.80       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.63      0.63       500\n",
            "weighted avg       0.69      0.71      0.69       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.7874659400544959\n",
            "accuracy is 0.688\n",
            "error rate is 0.31200000000000006\n",
            "roc_auc_score is 0.5964420345026091\n",
            "gini is 0.19288406900521826\n",
            "[[ 55 102]\n",
            " [ 54 289]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.35      0.41       157\n",
            "           1       0.74      0.84      0.79       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.60      0.60       500\n",
            "weighted avg       0.67      0.69      0.67       500\n",
            "\n",
            "17 6 4\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8149100257069408\n",
            "accuracy is 0.712\n",
            "error rate is 0.28800000000000003\n",
            "roc_auc_score is 0.5863029470204825\n",
            "gini is 0.17260589404096494\n",
            "[[ 39 118]\n",
            " [ 26 317]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.25      0.35       157\n",
            "           1       0.73      0.92      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.66      0.59      0.58       500\n",
            "weighted avg       0.69      0.71      0.67       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "12\n",
            "12\n",
            "[[12, 0.28800000000000003], [13, 0.266], [9, 0.31599999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[12.0, 0.28800000000000003], [13.0, 0.266], [9.0, 0.31599999999999995]])])\n",
            "[12.0, 0.28800000000000003]\n",
            "round_robin_flag\n",
            "25\n",
            "X_best_t\n",
            "[13.0, 0.266]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "f1_score is -0.8010335917312662\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5665447252604408\n",
            "gini is 0.1330894505208815\n",
            "[[ 36 121]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.23      0.32       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.57      0.56       500\n",
            "weighted avg       0.66      0.69      0.65       500\n",
            "\n",
            "f1_score is -0.8205128205128206\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6437856307218065\n",
            "gini is 0.287571261443613\n",
            "[[ 63  94]\n",
            " [ 39 304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.40      0.49       157\n",
            "           1       0.76      0.89      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.64      0.65       500\n",
            "weighted avg       0.72      0.73      0.72       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.8010335917312662\n",
            "accuracy is 0.692\n",
            "error rate is 0.30800000000000005\n",
            "roc_auc_score is 0.5665447252604408\n",
            "gini is 0.1330894505208815\n",
            "[[ 36 121]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.23      0.32       157\n",
            "           1       0.72      0.90      0.80       343\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.62      0.57      0.56       500\n",
            "weighted avg       0.66      0.69      0.65       500\n",
            "\n",
            "18 15 4\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8053333333333333\n",
            "accuracy is 0.708\n",
            "error rate is 0.29200000000000004\n",
            "roc_auc_score is 0.6058383316930047\n",
            "gini is 0.21167666338600943\n",
            "[[ 52 105]\n",
            " [ 41 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.33      0.42       157\n",
            "           1       0.74      0.88      0.81       343\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.65      0.61      0.61       500\n",
            "weighted avg       0.68      0.71      0.68       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "f1_score is -0.7989821882951654\n",
            "accuracy is 0.684\n",
            "error rate is 0.31599999999999995\n",
            "roc_auc_score is 0.5468979220441589\n",
            "gini is 0.09379584408831776\n",
            "[[ 28 129]\n",
            " [ 29 314]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       157\n",
            "           1       0.71      0.92      0.80       343\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.60      0.55      0.53       500\n",
            "weighted avg       0.64      0.68      0.63       500\n",
            "\n",
            "11\n",
            "11\n",
            "[[11, 0.29200000000000004], [14, 0.272], [9, 0.31599999999999995]]\n",
            "<class 'list'>\n",
            "res and smallest key\n",
            "OrderedDict([(1, [[11.0, 0.29200000000000004], [14.0, 0.272], [9.0, 0.31599999999999995]])])\n",
            "[11.0, 0.29200000000000004]\n",
            "round_robin_flag\n",
            "26\n",
            "X_best_t\n",
            "[14.0, 0.272]\n",
            "vecetor from Dict_vector_cardinality_accuracy\n",
            "[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "f1_score is -0.8186666666666667\n",
            "accuracy is 0.728\n",
            "error rate is 0.272\n",
            "roc_auc_score is 0.6290505283095951\n",
            "gini is 0.25810105661919014\n",
            "[[ 57 100]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.46       157\n",
            "           1       0.75      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.68      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.70       500\n",
            "\n",
            "X_r1_for_xor[1]\n",
            "0\n",
            "f1_score is -0.826379542395693\n",
            "accuracy is 0.742\n",
            "error rate is 0.258\n",
            "roc_auc_score is 0.6513435219401682\n",
            "gini is 0.3026870438803364\n",
            "[[ 64  93]\n",
            " [ 36 307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.65      0.66       500\n",
            "weighted avg       0.73      0.74      0.72       500\n",
            "\n",
            "[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]]\n",
            "[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]]\n",
            "[[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.31599999999999995], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 13, 0.272], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.264], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 10, 0.31200000000000006], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 10, 0.32799999999999996], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.32199999999999995], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], 14, 0.272], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], 13, 0.276], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], 13, 0.276], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.28200000000000003], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.28200000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 12, 0.31200000000000006], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], 11, 0.30800000000000005], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], 11, 0.30800000000000005], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.246]]\n",
            "[[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]]]\n",
            "[[7, 0.29200000000000004], [7, 0.29200000000000004], [10, 0.262], [10, 0.262], [16, 0.248], [16, 0.248], [15, 0.256], [15, 0.256], [9, 0.31599999999999995], [16, 0.248], [14, 0.262], [13, 0.272], [13, 0.266], [13, 0.266], [12, 0.272], [13, 0.27], [10, 0.274], [14, 0.264], [13, 0.27], [13, 0.27], [10, 0.31200000000000006], [11, 0.28200000000000003], [11, 0.28200000000000003], [10, 0.32799999999999996], [11, 0.32199999999999995], [13, 0.274], [13, 0.274], [14, 0.272], [11, 0.28200000000000003], [10, 0.33599999999999997], [10, 0.33599999999999997], [12, 0.28800000000000003], [12, 0.28800000000000003], [11, 0.29200000000000004], [11, 0.29200000000000004], [13, 0.276], [13, 0.276], [13, 0.28200000000000003], [13, 0.28200000000000003], [12, 0.28800000000000003], [13, 0.266], [11, 0.30000000000000004], [11, 0.30000000000000004], [14, 0.28400000000000003], [12, 0.28800000000000003], [13, 0.29400000000000004], [12, 0.31200000000000006], [11, 0.30800000000000005], [11, 0.30800000000000005], [14, 0.246]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame([[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], 7, 0.29200000000000004], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], 10, 0.262], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 15, 0.256], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 9, 0.31599999999999995], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 16, 0.248], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 14, 0.262], [[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0], 13, 0.272], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], 12, 0.272], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], 10, 0.274], [[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.264], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1], 13, 0.27], [[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], 10, 0.31200000000000006], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 10, 0.32799999999999996], [[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], 11, 0.32199999999999995], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0], 13, 0.274], [[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0], 14, 0.272], [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1], 11, 0.28200000000000003], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 10, 0.33599999999999997], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], 11, 0.29200000000000004], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], 13, 0.276], [[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], 13, 0.276], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.28200000000000003], [[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.28200000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 13, 0.266], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], 11, 0.30000000000000004], [[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], 14, 0.28400000000000003], [[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0], 12, 0.28800000000000003], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 13, 0.29400000000000004], [[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 12, 0.31200000000000006], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], 11, 0.30800000000000005], [[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1], 11, 0.30800000000000005], [[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], 14, 0.246]])\n",
        "pd.set_option(\"max_colwidth\", 100)\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3mZIrn5LEC0A",
        "outputId": "39fdf9af-9453-4359-b220-51e2ef1486de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                    0  \\\n",
              "0   [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "1   [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "2   [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
              "3   [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
              "4   [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "5   [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "6   [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "7   [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "8   [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
              "9   [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "10  [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "11  [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
              "12  [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "13  [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "14  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]   \n",
              "15  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
              "16  [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]   \n",
              "17  [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "18  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
              "19  [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
              "20  [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
              "21  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "22  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "23  [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "24  [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]   \n",
              "25  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "26  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "27  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]   \n",
              "28  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]   \n",
              "29  [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "30  [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "31  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
              "32  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
              "33  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "34  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]   \n",
              "35  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]   \n",
              "36  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]   \n",
              "37  [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "38  [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "39  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]   \n",
              "40  [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "41  [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "42  [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]   \n",
              "43  [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]   \n",
              "44  [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]   \n",
              "45  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "46  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "47  [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]   \n",
              "48  [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]   \n",
              "49  [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
              "\n",
              "     1     2  \n",
              "0    7 0.292  \n",
              "1    7 0.292  \n",
              "2   10 0.262  \n",
              "3   10 0.262  \n",
              "4   16 0.248  \n",
              "5   16 0.248  \n",
              "6   15 0.256  \n",
              "7   15 0.256  \n",
              "8    9 0.316  \n",
              "9   16 0.248  \n",
              "10  14 0.262  \n",
              "11  13 0.272  \n",
              "12  13 0.266  \n",
              "13  13 0.266  \n",
              "14  12 0.272  \n",
              "15  13 0.270  \n",
              "16  10 0.274  \n",
              "17  14 0.264  \n",
              "18  13 0.270  \n",
              "19  13 0.270  \n",
              "20  10 0.312  \n",
              "21  11 0.282  \n",
              "22  11 0.282  \n",
              "23  10 0.328  \n",
              "24  11 0.322  \n",
              "25  13 0.274  \n",
              "26  13 0.274  \n",
              "27  14 0.272  \n",
              "28  11 0.282  \n",
              "29  10 0.336  \n",
              "30  10 0.336  \n",
              "31  12 0.288  \n",
              "32  12 0.288  \n",
              "33  11 0.292  \n",
              "34  11 0.292  \n",
              "35  13 0.276  \n",
              "36  13 0.276  \n",
              "37  13 0.282  \n",
              "38  13 0.282  \n",
              "39  12 0.288  \n",
              "40  13 0.266  \n",
              "41  11 0.300  \n",
              "42  11 0.300  \n",
              "43  14 0.284  \n",
              "44  12 0.288  \n",
              "45  13 0.294  \n",
              "46  12 0.312  \n",
              "47  11 0.308  \n",
              "48  11 0.308  \n",
              "49  14 0.246  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09ba7b8e-5f40-4746-be0b-385afa4ded00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>7</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>7</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>15</td>\n",
              "      <td>0.256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>9</td>\n",
              "      <td>0.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>10</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>13</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>12</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]</td>\n",
              "      <td>11</td>\n",
              "      <td>0.308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>14</td>\n",
              "      <td>0.246</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09ba7b8e-5f40-4746-be0b-385afa4ded00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09ba7b8e-5f40-4746-be0b-385afa4ded00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09ba7b8e-5f40-4746-be0b-385afa4ded00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_t_plus_1_fitness_1 = [[7, 0.29200000000000004], [7, 0.29200000000000004], [10, 0.262], [10, 0.262], [16, 0.248], [16, 0.248], [15, 0.256], [15, 0.256], [9, 0.31599999999999995], [16, 0.248], [14, 0.262], [13, 0.272], [13, 0.266], [13, 0.266], [12, 0.272], [13, 0.27], [10, 0.274], [14, 0.264], [13, 0.27], [13, 0.27], [10, 0.31200000000000006], [11, 0.28200000000000003], [11, 0.28200000000000003], [10, 0.32799999999999996], [11, 0.32199999999999995], [13, 0.274], [13, 0.274], [14, 0.272], [11, 0.28200000000000003], [10, 0.33599999999999997], [10, 0.33599999999999997], [12, 0.28800000000000003], [12, 0.28800000000000003], [11, 0.29200000000000004], [11, 0.29200000000000004], [13, 0.276], [13, 0.276], [13, 0.28200000000000003], [13, 0.28200000000000003], [12, 0.28800000000000003], [13, 0.266], [11, 0.30000000000000004], [11, 0.30000000000000004], [14, 0.28400000000000003], [12, 0.28800000000000003], [13, 0.29400000000000004], [12, 0.31200000000000006], [11, 0.30800000000000005], [11, 0.30800000000000005], [14, 0.246]]\n",
        "#import operator\n",
        "#list1 = sorted(P_t_plus_1_fitness_1, key=operator.itemgetter(0, 1))\n",
        "#res, smallest_key=non_dominated_sorting(list1)\n",
        "#res, smallest_key=non_dominated_sorting(P_t_plus_1_fitness_1)\n",
        "#res"
      ],
      "metadata": {
        "id": "fLnmNGMTERi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=P_t_plus_1_fitness_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy7Eb-JlEWto",
        "outputId": "e43b9284-27be-43da-9526-9e7117543247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0, 2, 49],\n",
              "  [1, 3, 4, 6],\n",
              "  [8, 10, 12, 14, 16, 5, 7],\n",
              "  [17, 13, 20, 21, 9],\n",
              "  [40, 23, 22],\n",
              "  [15, 29, 28],\n",
              "  [18, 30, 31, 33],\n",
              "  [19, 32, 34],\n",
              "  [11, 39, 41],\n",
              "  [25, 27, 44, 42],\n",
              "  [26, 47],\n",
              "  [35, 48],\n",
              "  [36, 24, 46],\n",
              "  [37],\n",
              "  [38],\n",
              "  [43, 45],\n",
              "  []],\n",
              " [[[7, 0.29200000000000004], [10, 0.262], [14, 0.246]],\n",
              "  [[7, 0.29200000000000004], [10, 0.262], [16, 0.248], [15, 0.256]],\n",
              "  [[9, 0.31599999999999995],\n",
              "   [14, 0.262],\n",
              "   [13, 0.266],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274],\n",
              "   [16, 0.248],\n",
              "   [15, 0.256]],\n",
              "  [[14, 0.264],\n",
              "   [13, 0.266],\n",
              "   [10, 0.31200000000000006],\n",
              "   [11, 0.28200000000000003],\n",
              "   [16, 0.248]],\n",
              "  [[13, 0.266], [10, 0.32799999999999996], [11, 0.28200000000000003]],\n",
              "  [[13, 0.27], [10, 0.33599999999999997], [11, 0.28200000000000003]],\n",
              "  [[13, 0.27],\n",
              "   [10, 0.33599999999999997],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[13, 0.27], [12, 0.28800000000000003], [11, 0.29200000000000004]],\n",
              "  [[13, 0.272], [12, 0.28800000000000003], [11, 0.30000000000000004]],\n",
              "  [[13, 0.274],\n",
              "   [14, 0.272],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.30000000000000004]],\n",
              "  [[13, 0.274], [11, 0.30800000000000005]],\n",
              "  [[13, 0.276], [11, 0.30800000000000005]],\n",
              "  [[13, 0.276], [11, 0.32199999999999995], [12, 0.31200000000000006]],\n",
              "  [[13, 0.28200000000000003]],\n",
              "  [[13, 0.28200000000000003]],\n",
              "  [[14, 0.28400000000000003], [13, 0.29400000000000004]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Optimal_front = [\n",
        "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "\n",
        "#[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "#[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "#[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "#[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "\n",
        "#[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "#[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "#[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
        "#[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
        "#[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "#[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
        "#[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
        "]"
      ],
      "metadata": {
        "id": "OZ-ObHsqEWxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPS(S=Optimal_front, optimal_sol=[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T7r0LMrERnc",
        "outputId": "cdf8272d-8671-4194-a0da-0ded8c1807c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "14\n",
            "12\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "f1_score is -0.8264900662251655\n",
            "accuracy is 0.738\n",
            "error rate is 0.262\n",
            "roc_auc_score is 0.6363391580472044\n",
            "gini is 0.27267831609440885\n",
            "[[ 57 100]\n",
            " [ 31 312]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47       157\n",
            "           1       0.76      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "f1_score is -0.8218085106382979\n",
            "accuracy is 0.732\n",
            "error rate is 0.268\n",
            "roc_auc_score is 0.6319659802046387\n",
            "gini is 0.26393196040927736\n",
            "[[ 57 100]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.36      0.46       157\n",
            "           1       0.76      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.63      0.64       500\n",
            "weighted avg       0.71      0.73      0.71       500\n",
            "\n",
            "f1_score is -0.823529411764706\n",
            "accuracy is 0.736\n",
            "error rate is 0.264\n",
            "roc_auc_score is 0.6400623943845054\n",
            "gini is 0.2801247887690108\n",
            "[[ 60  97]\n",
            " [ 35 308]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.38      0.48       157\n",
            "           1       0.76      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.70      0.64      0.65       500\n",
            "weighted avg       0.72      0.74      0.71       500\n",
            "\n",
            "0.006000000000000005\n",
            "0.0040000000000000036\n",
            "0.0020000000000000018\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n",
            "f1_score is -0.8233731739707835\n",
            "accuracy is 0.734\n",
            "error rate is 0.266\n",
            "roc_auc_score is 0.6334237061521606\n",
            "gini is 0.2668474123043212\n",
            "[[ 57 100]\n",
            " [ 33 310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.36      0.46       157\n",
            "           1       0.76      0.90      0.82       343\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.69      0.63      0.64       500\n",
            "weighted avg       0.72      0.73      0.71       500\n",
            "\n",
            "0.248\n",
            "0.266\n",
            "False False True\n",
            "it saves both Xh and Xhhat into Pt\n",
            "X_h is: \n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "X_h_hat is: \n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOph0weygK4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zApuRKHgK7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For PPT"
      ],
      "metadata": {
        "id": "LTZae-gMTtqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Round 1, i.e., Generation 2"
      ],
      "metadata": {
        "id": "SIq-FGvTUo5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Generation_2 = [[15, 0.262], [14, 0.264],[7, 0.29200000000000004], [12, 0.272], [10, 0.274], [16, 0.248], [15, 0.256], [10, 0.262],\n",
        "                [9, 0.31599999999999995], [11, 0.28200000000000003], [10, 0.33599999999999997], [12, 0.28800000000000003], [14, 0.28400000000000003],\n",
        "                [11, 0.29200000000000004], [13, 0.29000000000000004], [11, 0.31599999999999995], [12, 0.30000000000000004], [13, 0.29400000000000004],\n",
        "                [12, 0.30200000000000005], [11, 0.31999999999999995], [14, 0.29600000000000004], [12, 0.30200000000000005], [15, 0.30000000000000004],\n",
        "                [13, 0.30400000000000005], [12, 0.31200000000000006], [13, 0.30400000000000005], [12, 0.312 ],\n",
        "                [13, 0.30400000000000005], [16, 0.30400000000000005],[13, 0.30800000000000005]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                [15, 0.32999999999999996], [15, 0.32999999999999996],   [11, 0.31599999999999995],\n",
        "                  [15, 0.262],  [12, 0.30200000000000005],\n",
        "                    [16, 0.30400000000000005],\n",
        "                 [16, 0.30400000000000005], [7, 0.29200000000000004],   [13, 0.29400000000000004],\n",
        "                [14, 0.29600000000000004], [12, 0.30200000000000005], [12, 0.30200000000000005], [12, 0.30200000000000005], [14, 0.31200000000000006],\n",
        "                 [14, 0.31799999999999995],  [14, 0.28400000000000003],\n",
        "                [11, 0.29200000000000004],  [11, 0.28200000000000003],  [12, 0.272],   [10, 0.274],\n",
        "                ]\n"
      ],
      "metadata": {
        "id": "FW9mqGxlUhen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generation_2 = [[15, 0.262], [14, 0.264],[7, 0.29200000000000004], [12, 0.272], [10, 0.274], [16, 0.248], [15, 0.256], [10, 0.262],\n",
        "                [9, 0.31599999999999995], [11, 0.28200000000000003], [10, 0.33599999999999997], [12, 0.28800000000000003], [14, 0.28400000000000003],\n",
        "                [11, 0.29200000000000004], [13, 0.29000000000000004], [11, 0.31599999999999995], [12, 0.30000000000000004], [13, 0.29400000000000004],\n",
        "                [12, 0.30200000000000005], [11, 0.31999999999999995], [14, 0.29600000000000004], [12, 0.30200000000000005], [15, 0.30000000000000004],\n",
        "                [13, 0.30400000000000005], [12, 0.31200000000000006], [13, 0.30400000000000005], [16, 0.30400000000000005],[13, 0.30800000000000005]]"
      ],
      "metadata": {
        "id": "qc1zZf-4T6rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Generation_2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHtPP_XRVgeB",
        "outputId": "61e1c9c4-2b66-43c2-e9ee-0d6329577adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=Generation_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJssmZYrUWel",
        "outputId": "840c63c4-fb8e-42b2-b420-2f74b67a1c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[2, 5, 6, 7],\n",
              "  [8, 0, 1, 3, 4],\n",
              "  [9, 10],\n",
              "  [11, 12, 13],\n",
              "  [14, 15, 16],\n",
              "  [17, 19, 18],\n",
              "  [20, 21],\n",
              "  [22, 23, 24],\n",
              "  [25],\n",
              "  [26, 27],\n",
              "  []],\n",
              " [[[7, 0.29200000000000004], [16, 0.248], [15, 0.256], [10, 0.262]],\n",
              "  [[9, 0.31599999999999995],\n",
              "   [15, 0.262],\n",
              "   [14, 0.264],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274]],\n",
              "  [[11, 0.28200000000000003], [10, 0.33599999999999997]],\n",
              "  [[12, 0.28800000000000003],\n",
              "   [14, 0.28400000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[13, 0.29000000000000004],\n",
              "   [11, 0.31599999999999995],\n",
              "   [12, 0.30000000000000004]],\n",
              "  [[13, 0.29400000000000004],\n",
              "   [11, 0.31999999999999995],\n",
              "   [12, 0.30200000000000005]],\n",
              "  [[14, 0.29600000000000004], [12, 0.30200000000000005]],\n",
              "  [[15, 0.30000000000000004],\n",
              "   [13, 0.30400000000000005],\n",
              "   [12, 0.31200000000000006]],\n",
              "  [[13, 0.30400000000000005]],\n",
              "  [[16, 0.30400000000000005], [13, 0.30800000000000005]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Round 2, i.e., Generation 3"
      ],
      "metadata": {
        "id": "5jYYIGIRUYk2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VV_8Bec8UWh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generation_3 = [[7, 0.29200000000000004], [10, 0.262], [16, 0.248], [15, 0.256], [9, 0.31599999999999995], [14, 0.262], [13, 0.266],  [12, 0.272], [10, 0.274],\n",
        "                [14, 0.264],   [13, 0.27],  [11, 0.28200000000000003], [10, 0.33599999999999997], [13, 0.274], [12, 0.28800000000000003], [14, 0.28400000000000003],\n",
        "                [11, 0.29200000000000004], [12, 0.28800000000000003], [11, 0.30000000000000004], [13, 0.29400000000000004], [12, 0.30000000000000004],\n",
        "                [11, 0.31200000000000006], [12, 0.30200000000000005], [11, 0.31399999999999995], [14, 0.29400000000000004],\n",
        "                [11, 0.31599999999999995], [14, 0.29600000000000004]]"
      ],
      "metadata": {
        "id": "1LPcr_S0JKFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=Generation_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pZ5x1RlUWlq",
        "outputId": "bd36022d-a20e-40c5-8964-e2c021e625a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0, 1, 2, 3],\n",
              "  [4, 5, 6, 7, 8],\n",
              "  [9, 10, 11, 12],\n",
              "  [13, 14, 16],\n",
              "  [15, 17, 18],\n",
              "  [19, 20, 21],\n",
              "  [24, 22, 23],\n",
              "  [26, 25],\n",
              "  []],\n",
              " [[[7, 0.29200000000000004], [10, 0.262], [16, 0.248], [15, 0.256]],\n",
              "  [[9, 0.31599999999999995],\n",
              "   [14, 0.262],\n",
              "   [13, 0.266],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274]],\n",
              "  [[14, 0.264],\n",
              "   [13, 0.27],\n",
              "   [11, 0.28200000000000003],\n",
              "   [10, 0.33599999999999997]],\n",
              "  [[13, 0.274], [12, 0.28800000000000003], [11, 0.29200000000000004]],\n",
              "  [[14, 0.28400000000000003],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.30000000000000004]],\n",
              "  [[13, 0.29400000000000004],\n",
              "   [12, 0.30000000000000004],\n",
              "   [11, 0.31200000000000006]],\n",
              "  [[14, 0.29400000000000004],\n",
              "   [12, 0.30200000000000005],\n",
              "   [11, 0.31399999999999995]],\n",
              "  [[14, 0.29600000000000004], [11, 0.31599999999999995]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Round 3, i.e., Generation 4"
      ],
      "metadata": {
        "id": "YRbnCZs1T8Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRZFgrpyTrgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generation_4 = [[7, 0.29200000000000004], [10, 0.262], [16, 0.248],[14,0.246],\n",
        "                [15, 0.256], [9, 0.31599999999999995], [14, 0.262], [13, 0.266], [12, 0.272], [10, 0.274], [14, 0.264], [13, 0.27],  [10, 0.31200000000000006],\n",
        "                [11, 0.28200000000000003], [11, 0.28200000000000003], [13, 0.274], [14, 0.272], [10, 0.33599999999999997], [12, 0.28800000000000003], [11, 0.29200000000000004],\n",
        "                [13, 0.276], [13, 0.28200000000000003], [12, 0.28800000000000003],  [11, 0.30000000000000004], [14, 0.28400000000000003], [13, 0.29400000000000004],\n",
        "                [11, 0.30800000000000005]]"
      ],
      "metadata": {
        "id": "a0d_9fCz00_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=Generation_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTnNkqwqTrjm",
        "outputId": "ab33603f-1874-4ba8-99db-8b545a9a63ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0, 1, 3],\n",
              "  [5, 7, 8, 9, 2, 4, 6],\n",
              "  [11, 12, 13, 10],\n",
              "  [15, 17, 14, 16],\n",
              "  [20, 18, 19],\n",
              "  [21, 22, 23],\n",
              "  [24, 25, 26],\n",
              "  []],\n",
              " [[[7, 0.29200000000000004], [10, 0.262], [14, 0.246]],\n",
              "  [[9, 0.31599999999999995],\n",
              "   [13, 0.266],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274],\n",
              "   [16, 0.248],\n",
              "   [15, 0.256],\n",
              "   [14, 0.262]],\n",
              "  [[13, 0.27],\n",
              "   [10, 0.31200000000000006],\n",
              "   [11, 0.28200000000000003],\n",
              "   [14, 0.264]],\n",
              "  [[13, 0.274],\n",
              "   [10, 0.33599999999999997],\n",
              "   [11, 0.28200000000000003],\n",
              "   [14, 0.272]],\n",
              "  [[13, 0.276], [12, 0.28800000000000003], [11, 0.29200000000000004]],\n",
              "  [[13, 0.28200000000000003],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.30000000000000004]],\n",
              "  [[14, 0.28400000000000003],\n",
              "   [13, 0.29400000000000004],\n",
              "   [11, 0.30800000000000005]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Round 4, i.e., Generation 5"
      ],
      "metadata": {
        "id": "924xU8hYUAt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For PPT#\n",
        "Generation_5 = [[7, 0.29200000000000004], [10, 0.262], [14, 0.246], [16, 0.248],  [15, 0.256], [9, 0.31599999999999995], [14, 0.262],\n",
        "                [13, 0.266], [12, 0.272], [10, 0.274], [14, 0.264], [10, 0.31200000000000006], [11, 0.28200000000000003], [13, 0.27],\n",
        "                [10, 0.33599999999999997], [12, 0.28800000000000003], [11, 0.29200000000000004], [13, 0.272], [12, 0.28800000000000003],\n",
        "                [11, 0.30000000000000004], [13, 0.274], [14, 0.272], [11, 0.30800000000000005], [13, 0.276],[11, 0.32199999999999995],\n",
        "                [12, 0.31200000000000006], [13, 0.28200000000000003]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #[10, 0.32799999999999996],\n",
        " #[14, 0.28400000000000003],\n",
        " #[13, 0.29400000000000004],\n"
      ],
      "metadata": {
        "id": "2WpsrhTtgK-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_non_dominated_sort(data=Generation_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVC6Fd_hEC3V",
        "outputId": "05f3b115-d5ff-49ca-963a-effdeb226ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0, 1, 2],\n",
              "  [5, 7, 8, 9, 3, 4, 6],\n",
              "  [13, 11, 12, 10],\n",
              "  [17, 14, 15, 16],\n",
              "  [20, 21, 18, 19],\n",
              "  [23, 22],\n",
              "  [26, 24, 25],\n",
              "  []],\n",
              " [[[7, 0.29200000000000004], [10, 0.262], [14, 0.246]],\n",
              "  [[9, 0.31599999999999995],\n",
              "   [13, 0.266],\n",
              "   [12, 0.272],\n",
              "   [10, 0.274],\n",
              "   [16, 0.248],\n",
              "   [15, 0.256],\n",
              "   [14, 0.262]],\n",
              "  [[13, 0.27],\n",
              "   [10, 0.31200000000000006],\n",
              "   [11, 0.28200000000000003],\n",
              "   [14, 0.264]],\n",
              "  [[13, 0.272],\n",
              "   [10, 0.33599999999999997],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.29200000000000004]],\n",
              "  [[13, 0.274],\n",
              "   [14, 0.272],\n",
              "   [12, 0.28800000000000003],\n",
              "   [11, 0.30000000000000004]],\n",
              "  [[13, 0.276], [11, 0.30800000000000005]],\n",
              "  [[13, 0.28200000000000003],\n",
              "   [11, 0.32199999999999995],\n",
              "   [12, 0.31200000000000006]],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model"
      ],
      "metadata": {
        "id": "QxfI7Ym1oSTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_r,a,b=Calculate_f1_for_X_rn(dataset_train=train_up_without_target, target_train = train_up['Creditability'], dataset_test = test_up_without_target ,\\\n",
        "                              target_test = test_up['Creditability'],X_rn=[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0])\n",
        "print(X_r)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSGPZq9YjhH4",
        "outputId": "18da559a-ff56-4076-f2aa-8505ddded7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "14\n",
            "0.246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWM7aHwJ_l0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GslbajzP_l_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For plotting\n",
        "from sklearn.model_selection import train_test_split # train test split\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_r = [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] #0.246\n",
        "feature_set=[]\n",
        "for i in range(len(X_r)):\n",
        "    #print(i)\n",
        "    if X_r[i]==1:\n",
        "        feature_set.append(train_up_without_target.columns[i])\n",
        "# print(feature_set)\n",
        "if(len(feature_set)==0):\n",
        "    num_feature = 0\n",
        "    f1_score = 0\n",
        "else:\n",
        "    X_=train_up_without_target[feature_set]\n",
        "\n",
        "print(feature_set)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "model.fit(train_up_without_target[feature_set], train_up['Creditability'])\n",
        "y_pred = model.predict(test_up_without_target[feature_set])\n",
        "y_pred_proba = model.predict_proba(test_up_without_target[feature_set])\n",
        "\n",
        "f1_score=f1_score(test_up['Creditability'], y_pred) * -1 #this is to make it minimization problem\n",
        "#roc_auc_score = roc_auc_score(y, y_proba)\n",
        "\n",
        "\n",
        "\n",
        "print(\"f1_score is \" +str(f1_score))\n",
        "score = accuracy_score(test_up['Creditability'], y_pred)\n",
        "accuracy_score = score\n",
        "print(\"accuracy is \" + str(score))\n",
        "print(\"error rate is \" + str(1-score))\n",
        "error_rate = 1-score\n",
        "print(\"roc_auc_score is \" + str(roc_auc_score(test_up['Creditability'], y_pred)))\n",
        "print(\"gini is \" + str((2*roc_auc_score(test_up['Creditability'], y_pred))-1))\n",
        "print(confusion_matrix(test_up['Creditability'], y_pred))\n",
        "print(classification_report(test_up['Creditability'], y_pred))\n",
        "\n",
        "auc = metrics.roc_auc_score(test_up['Creditability'], y_pred_proba[:,1])\n",
        "#false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n",
        "false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(test_up['Creditability'], y_pred_proba[:,1])\n",
        "plt.figure(figsize=(8, 6), dpi=100)\n",
        "plt.axis('scaled')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.title(\"AUC ROC Curve\")\n",
        "plt.plot(false_positive_rate, true_positive_rate, 'g')\n",
        "plt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgreen', alpha=0.7)\n",
        "plt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=12, weight='bold', color='blue')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "B4lgKPGyqOmz",
        "outputId": "3e8ca6b5-d149-496a-e9c4-d29663e2bbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Duration.of.Credit..month.', 'Credit.Amount', 'Value.Savings.Stocks', 'Instalment.per.cent', 'Age..years.', 'No.of.dependents', 'Account.Balance_2', 'Account.Balance_3', 'Payment.Status.of.Previous.Credit_3', 'Purpose_3', 'Sex...Marital.Status_2', 'Sex...Marital.Status_3', 'Guarantors_2', 'Type.of.apartment_3']\n",
            "f1_score is -0.8348993288590604\n",
            "accuracy is 0.754\n",
            "error rate is 0.246\n",
            "roc_auc_score is 0.663543852481848\n",
            "gini is 0.327087704963696\n",
            "[[ 66  91]\n",
            " [ 32 311]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52       157\n",
            "           1       0.77      0.91      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "qW8PFgzg_r4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp_feat= list(OrderedDict(sorted(model.get_booster().get_score(importance_type=\"total_gain\").items())))"
      ],
      "metadata": {
        "id": "dwF9JMNjqbMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp_feat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS8PKqIyqbQo",
        "outputId": "d5461eaf-783b-4c17-fb87-270e5cee3cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Account.Balance_2',\n",
              " 'Account.Balance_3',\n",
              " 'Age..years.',\n",
              " 'Credit.Amount',\n",
              " 'Duration.of.Credit..month.',\n",
              " 'Guarantors_2',\n",
              " 'Instalment.per.cent',\n",
              " 'No.of.dependents',\n",
              " 'Payment.Status.of.Previous.Credit_3',\n",
              " 'Purpose_3',\n",
              " 'Sex...Marital.Status_2',\n",
              " 'Sex...Marital.Status_3',\n",
              " 'Type.of.apartment_3',\n",
              " 'Value.Savings.Stocks']"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "booster = model.get_booster()"
      ],
      "metadata": {
        "id": "Vx4wwDOkeICC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "booster.get_score(importance_type=\"total_gain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ06GJUP_5UT",
        "outputId": "8a14b55b-a153-4a72-877f-15e3d3bec6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Account.Balance_3': 248.05719440099998,\n",
              " 'Duration.of.Credit..month.': 254.91042855900002,\n",
              " 'Credit.Amount': 431.3298603669997,\n",
              " 'Instalment.per.cent': 61.190249159999986,\n",
              " 'No.of.dependents': 58.59033488700001,\n",
              " 'Age..years.': 127.54460292300003,\n",
              " 'Value.Savings.Stocks': 90.27802570000003,\n",
              " 'Payment.Status.of.Previous.Credit_3': 46.872327348,\n",
              " 'Guarantors_2': 31.902575867000007,\n",
              " 'Sex...Marital.Status_2': 25.513431633000003,\n",
              " 'Type.of.apartment_3': 4.993226410000001,\n",
              " 'Account.Balance_2': 4.443081674,\n",
              " 'Purpose_3': 9.504100686000001,\n",
              " 'Sex...Marital.Status_3': 7.300894259}"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "from matplotlib import pyplot\n",
        "plot_importance(model,importance_type='gain')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sdPAa5nNAQWz",
        "outputId": "768866f7-9d23-4663-a889-aeb90e4467d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For tuned hyperparameter"
      ],
      "metadata": {
        "id": "UayA3TAqsImy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_r = [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0] #0.248\n",
        "#X_r = [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] #0.246\n",
        "feature_set=[]\n",
        "for i in range(len(X_r)):\n",
        "    #print(i)\n",
        "    if X_r[i]==1:\n",
        "        feature_set.append(train_up_without_target.columns[i])\n",
        "# print(feature_set)\n",
        "if(len(feature_set)==0):\n",
        "    num_feature = 0\n",
        "    f1_score = 0\n",
        "else:\n",
        "    X_=train_up_without_target[feature_set]\n",
        "\n",
        "print(feature_set)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq4TI0brqo95",
        "outputId": "6186fa3f-5dc0-41b8-e345-c00667cfed93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Duration.of.Credit..month.', 'Credit.Amount', 'Value.Savings.Stocks', 'Instalment.per.cent', 'Age..years.', 'No.of.dependents', 'Account.Balance_2', 'Account.Balance_3', 'Payment.Status.of.Previous.Credit_3', 'Purpose_3', 'Purpose_4', 'Sex...Marital.Status_2', 'Sex...Marital.Status_3', 'Guarantors_2', 'Most.valuable.available.asset_2', 'Type.of.apartment_3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "sm5Vjc3l77xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=10, learning_rate=0.075,min_samples_split = 0.1,min_samples_leaf = 0.1, max_depth = 3\n",
        "#                              ,eval_metric=[\"auc\", \"error\"])"
      ],
      "metadata": {
        "id": "XFQEn_EX8PX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBClassifier()"
      ],
      "metadata": {
        "id": "njE0uFcO90kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)"
      ],
      "metadata": {
        "id": "bjefw52r8iWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBClassifier(subsample = 0.4, reg_lambda = 0.1, reg_alpha=0.1, n_estimators=200, min_child_weight=5,  max_depth = 6, learning_rate = 0.1,gamma = 0.9, colsample_bytree=0.45  )"
      ],
      "metadata": {
        "id": "OkXvHo6USN7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters:  {'subsample': 0.05, 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 8, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.45}"
      ],
      "metadata": {
        "id": "V-9CpAUZSPkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters:  {'subsample': 0.4, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.9, 'colsample_bytree': 0.45}"
      ],
      "metadata": {
        "id": "niP1-EirV3md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.fit(train_up_without_target[feature_set], train_up['Creditability'])\n",
        "preds = xgb_model.predict(test_up_without_target[feature_set])"
      ],
      "metadata": {
        "id": "v1uLmvCMrKfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # train test split\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "f1_score=f1_score(test_up['Creditability'], preds) * -1 #this is to make it minimization problem\n",
        "#roc_auc_score = roc_auc_score(y, y_proba)\n",
        "\n",
        "\n",
        "\n",
        "print(\"f1_score is \" +str(f1_score))\n",
        "score = accuracy_score(test_up['Creditability'], preds)\n",
        "accuracy_score = score\n",
        "print(\"accuracy is \" + str(score))\n",
        "print(\"error rate is \" + str(1-score))\n",
        "error_rate = 1-score\n",
        "print(\"roc_auc_score is \" + str(roc_auc_score(test_up['Creditability'], preds)))\n",
        "print(\"gini is \" + str((2*roc_auc_score(test_up['Creditability'], preds))-1))\n",
        "print(confusion_matrix(test_up['Creditability'], preds))\n",
        "print(classification_report(test_up['Creditability'], preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxrgAA4WrV5g",
        "outputId": "dbedeb09-b386-4df6-9199-b93c0c0a85df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0KFWjtfsbGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "7xL_v0Be_OMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "\n",
        "# Define the hyperparameters to tune and their possible values\n",
        "param_grid = {\n",
        "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"n_estimators\": [100, 500, 1000],\n",
        "    \"min_child_weight\": [1, 5, 10],\n",
        "    \"subsample\": [0.5, 0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.5, 0.8, 1.0],\n",
        "    \"gamma\": [0, 0.1, 0.5],\n",
        "    \"reg_alpha\": [0, 0.1, 1],\n",
        "    \"reg_lambda\": [0, 0.1, 1]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(train_up_without_target[feature_set], train_up['Creditability'])\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "4EITfcje_R1T",
        "outputId": "5429793f-b526-4789-ed94-f2be3a60eebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-0b0004a22e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Use GridSearchCV to find the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_up_without_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_up\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Creditability'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Print the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    726\u001b[0m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n\u001b[0m\u001b[1;32m    729\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    213\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0m\u001b[1;32m   1109\u001b[0m                                                     dtrain.handle))\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7MzCEGOFx1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomized SEarch CV\n"
      ],
      "metadata": {
        "id": "SKexxgKWF5EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "\n",
        "# Define the hyperparameters to tune and their distributions\n",
        "param_dist = {\n",
        "    \"learning_rate\": np.arange(0.05, 0.31, 0.05),\n",
        "    \"max_depth\": [3, 4, 5, 6, 7, 8],\n",
        "    \"n_estimators\": [50, 100, 200, 300, 400, 500],\n",
        "    \"min_child_weight\": [1, 2, 3, 4, 5],\n",
        "    \"subsample\": np.arange(0.05, 1.05, 0.05),\n",
        "    \"colsample_bytree\": np.arange(0.05, 1.05, 0.05),\n",
        "    \"gamma\": np.arange(0, 1.05, 0.05),\n",
        "    \"reg_alpha\": [0, 0.1, 1, 10],\n",
        "    \"reg_lambda\": [0, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters\n",
        "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=1000, cv=5, scoring='accuracy')\n",
        "random_search.fit(train_up_without_target[feature_set], train_up['Creditability'])\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters: \", random_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFfhyWdoF1_l",
        "outputId": "67e71813-a13b-4d01-af70-f764c43e797c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'subsample': 0.4, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.9, 'colsample_bytree': 0.45}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38_g382hF9aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weights"
      ],
      "metadata": {
        "id": "nWowT0821Uro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a new column based on values in the 'data' column\n",
        "def categorize(x):\n",
        "  if x ==1:\n",
        "      return 2\n",
        "  else:\n",
        "      return 10"
      ],
      "metadata": {
        "id": "2Hk08y7l2ixu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_up_without_target_with_weight = train_up_without_target"
      ],
      "metadata": {
        "id": "LZQoEKCF24Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_up_without_target_with_weight['weight'] = train_up['Creditability'].apply(categorize)"
      ],
      "metadata": {
        "id": "BsQSdROW27Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_up_without_target_with_weight.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "8JUZ1Fki2mU1",
        "outputId": "343c9d60-dd44-4831-cf8d-7dfa1300fd82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Duration.of.Credit..month.  Credit.Amount  Value.Savings.Stocks  \\\n",
              "497                           6           2108                     1   \n",
              "756                          15            950                     1   \n",
              "580                          42           7174                     4   \n",
              "833                          36           7980                     4   \n",
              "602                          24           2028                     1   \n",
              "\n",
              "     Length.of.current.employment  Instalment.per.cent  \\\n",
              "497                             3                    2   \n",
              "756                             4                    4   \n",
              "580                             3                    4   \n",
              "833                             1                    4   \n",
              "602                             3                    2   \n",
              "\n",
              "     Duration.in.Current.address  Age..years.  No.of.Credits.at.this.Bank  \\\n",
              "497                            2           29                           1   \n",
              "756                            3           33                           2   \n",
              "580                            3           30                           1   \n",
              "833                            4           27                           2   \n",
              "602                            2           30                           2   \n",
              "\n",
              "     No.of.dependents  Account.Balance_2  Account.Balance_3  \\\n",
              "497                 1                  0                  1   \n",
              "756                 2                  0                  0   \n",
              "580                 1                  0                  0   \n",
              "833                 1                  0                  1   \n",
              "602                 1                  0                  1   \n",
              "\n",
              "     Payment.Status.of.Previous.Credit_2  Payment.Status.of.Previous.Credit_3  \\\n",
              "497                                    1                                    0   \n",
              "756                                    0                                    0   \n",
              "580                                    1                                    0   \n",
              "833                                    0                                    1   \n",
              "602                                    0                                    1   \n",
              "\n",
              "     Purpose_2  Purpose_3  Purpose_4  Sex...Marital.Status_2  \\\n",
              "497          0          1          0                       0   \n",
              "756          0          0          1                       1   \n",
              "580          0          1          0                       0   \n",
              "833          0          0          1                       1   \n",
              "602          1          0          0                       1   \n",
              "\n",
              "     Sex...Marital.Status_3  Guarantors_2  Most.valuable.available.asset_2  \\\n",
              "497                       1             0                                0   \n",
              "756                       0             0                                0   \n",
              "580                       0             0                                0   \n",
              "833                       0             0                                0   \n",
              "602                       0             0                                1   \n",
              "\n",
              "     Most.valuable.available.asset_3  Most.valuable.available.asset_4  \\\n",
              "497                                0                                0   \n",
              "756                                1                                0   \n",
              "580                                1                                0   \n",
              "833                                1                                0   \n",
              "602                                0                                0   \n",
              "\n",
              "     Concurrent.Credits_2  Type.of.apartment_2  Type.of.apartment_3  \\\n",
              "497                     1                    0                    0   \n",
              "756                     1                    0                    0   \n",
              "580                     1                    1                    0   \n",
              "833                     1                    0                    0   \n",
              "602                     1                    1                    0   \n",
              "\n",
              "     Foreign.Worker_2  Telephone_2  weight  \n",
              "497                 0            0       2  \n",
              "756                 0            0      10  \n",
              "580                 0            1      10  \n",
              "833                 0            1      10  \n",
              "602                 0            0       2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6b7fb53-088f-42b7-8b7b-4b7796fe96cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration.of.Credit..month.</th>\n",
              "      <th>Credit.Amount</th>\n",
              "      <th>Value.Savings.Stocks</th>\n",
              "      <th>Length.of.current.employment</th>\n",
              "      <th>Instalment.per.cent</th>\n",
              "      <th>Duration.in.Current.address</th>\n",
              "      <th>Age..years.</th>\n",
              "      <th>No.of.Credits.at.this.Bank</th>\n",
              "      <th>No.of.dependents</th>\n",
              "      <th>Account.Balance_2</th>\n",
              "      <th>Account.Balance_3</th>\n",
              "      <th>Payment.Status.of.Previous.Credit_2</th>\n",
              "      <th>Payment.Status.of.Previous.Credit_3</th>\n",
              "      <th>Purpose_2</th>\n",
              "      <th>Purpose_3</th>\n",
              "      <th>Purpose_4</th>\n",
              "      <th>Sex...Marital.Status_2</th>\n",
              "      <th>Sex...Marital.Status_3</th>\n",
              "      <th>Guarantors_2</th>\n",
              "      <th>Most.valuable.available.asset_2</th>\n",
              "      <th>Most.valuable.available.asset_3</th>\n",
              "      <th>Most.valuable.available.asset_4</th>\n",
              "      <th>Concurrent.Credits_2</th>\n",
              "      <th>Type.of.apartment_2</th>\n",
              "      <th>Type.of.apartment_3</th>\n",
              "      <th>Foreign.Worker_2</th>\n",
              "      <th>Telephone_2</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>6</td>\n",
              "      <td>2108</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>15</td>\n",
              "      <td>950</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>42</td>\n",
              "      <td>7174</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>36</td>\n",
              "      <td>7980</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>24</td>\n",
              "      <td>2028</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6b7fb53-088f-42b7-8b7b-4b7796fe96cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6b7fb53-088f-42b7-8b7b-4b7796fe96cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6b7fb53-088f-42b7-8b7b-4b7796fe96cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For plotting\n",
        "from sklearn.model_selection import train_test_split # train test split\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_r = [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] #0.246\n",
        "X_r = [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "feature_set=[]\n",
        "for i in range(len(X_r)):\n",
        "    #print(i)\n",
        "    if X_r[i]==1:\n",
        "        feature_set.append(train_up_without_target.columns[i])\n",
        "# print(feature_set)\n",
        "if(len(feature_set)==0):\n",
        "    num_feature = 0\n",
        "    f1_score = 0\n",
        "else:\n",
        "    X_=train_up_without_target[feature_set]\n",
        "\n",
        "print(feature_set)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', weight = train_up_without_target_with_weight['weight'])\n",
        "#model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', scale_pos_weight=0.1)\n",
        "\n",
        "model.fit(train_up_without_target[feature_set], train_up['Creditability'])\n",
        "y_pred = model.predict(test_up_without_target[feature_set])\n",
        "y_pred_proba = model.predict_proba(test_up_without_target[feature_set])\n",
        "\n",
        "f1_score=f1_score(test_up['Creditability'], preds) * -1 #this is to make it minimization problem\n",
        "#roc_auc_score = roc_auc_score(y, y_proba)\n",
        "\n",
        "\n",
        "\n",
        "print(\"f1_score is \" +str(f1_score))\n",
        "score = accuracy_score(test_up['Creditability'], preds)\n",
        "accuracy_score = score\n",
        "print(\"accuracy is \" + str(score))\n",
        "print(\"error rate is \" + str(1-score))\n",
        "error_rate = 1-score\n",
        "print(\"roc_auc_score is \" + str(roc_auc_score(test_up['Creditability'], preds)))\n",
        "print(\"gini is \" + str((2*roc_auc_score(test_up['Creditability'], preds))-1))\n",
        "print(confusion_matrix(test_up['Creditability'], preds))\n",
        "print(classification_report(test_up['Creditability'], preds))\n",
        "\n",
        "auc = metrics.roc_auc_score(test_up['Creditability'], y_pred_proba[:,1])\n",
        "#false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n",
        "false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(test_up['Creditability'], y_pred_proba[:,1])\n",
        "plt.figure(figsize=(8, 6), dpi=100)\n",
        "plt.axis('scaled')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.title(\"AUC ROC Curve\")\n",
        "plt.plot(false_positive_rate, true_positive_rate, 'g')\n",
        "plt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgreen', alpha=0.7)\n",
        "plt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=12, weight='bold', color='blue')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "4FbFjsEKF9eF",
        "outputId": "4dbabdab-7858-47be-a60d-6454277ea172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Duration.of.Credit..month.', 'Credit.Amount', 'Value.Savings.Stocks', 'Instalment.per.cent', 'Age..years.', 'No.of.dependents', 'Account.Balance_2', 'Account.Balance_3', 'Payment.Status.of.Previous.Credit_3', 'Purpose_3', 'Sex...Marital.Status_2', 'Sex...Marital.Status_3', 'Guarantors_2', 'Type.of.apartment_3']\n",
            "f1_score is -0.8328840970350404\n",
            "accuracy is 0.752\n",
            "error rate is 0.248\n",
            "roc_auc_score is 0.6638131139626005\n",
            "gini is 0.3276262279252009\n",
            "[[ 67  90]\n",
            " [ 34 309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.43      0.52       157\n",
            "           1       0.77      0.90      0.83       343\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.72      0.66      0.68       500\n",
            "weighted avg       0.74      0.75      0.73       500\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Csyz36X62iDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_y4hP6bKF2DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "IrsrecjDFxL5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JIGKVUU-BFK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"loss\":[\"deviance\"],\n",
        "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
        "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
        "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
        "    \"max_depth\":[3,5,8],\n",
        "    \"max_features\":[\"log2\",\"sqrt\"],\n",
        "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
        "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
        "    \"n_estimators\":[10]\n",
        "    }"
      ],
      "metadata": {
        "id": "OfJS95_UB6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################################################"
      ],
      "metadata": {
        "id": "V-K2GGfhEI12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrmat = train_up_without_target.corr()"
      ],
      "metadata": {
        "id": "YdWStZdcEJ0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrmat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "EaysGbHmEO65",
        "outputId": "2e6da2c7-6f14-4ec8-c5ca-526f88ae669a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Duration.of.Credit..month.  \\\n",
              "Duration.of.Credit..month.                                1.000   \n",
              "Credit.Amount                                             0.577   \n",
              "Value.Savings.Stocks                                      0.023   \n",
              "Length.of.current.employment                              0.058   \n",
              "Instalment.per.cent                                       0.088   \n",
              "Duration.in.Current.address                               0.037   \n",
              "Age..years.                                              -0.065   \n",
              "No.of.Credits.at.this.Bank                               -0.016   \n",
              "No.of.dependents                                         -0.053   \n",
              "Account.Balance_2                                         0.067   \n",
              "Account.Balance_3                                        -0.095   \n",
              "Payment.Status.of.Previous.Credit_2                      -0.104   \n",
              "Payment.Status.of.Previous.Credit_3                       0.043   \n",
              "Purpose_2                                                -0.098   \n",
              "Purpose_3                                                -0.019   \n",
              "Purpose_4                                                 0.012   \n",
              "Sex...Marital.Status_2                                    0.157   \n",
              "Sex...Marital.Status_3                                   -0.096   \n",
              "Guarantors_2                                              0.011   \n",
              "Most.valuable.available.asset_2                          -0.074   \n",
              "Most.valuable.available.asset_3                           0.100   \n",
              "Most.valuable.available.asset_4                           0.240   \n",
              "Concurrent.Credits_2                                     -0.045   \n",
              "Type.of.apartment_2                                      -0.110   \n",
              "Type.of.apartment_3                                       0.200   \n",
              "Foreign.Worker_2                                         -0.107   \n",
              "Telephone_2                                               0.143   \n",
              "\n",
              "                                     Credit.Amount  Value.Savings.Stocks  \\\n",
              "Duration.of.Credit..month.                   0.577                 0.023   \n",
              "Credit.Amount                                1.000                 0.038   \n",
              "Value.Savings.Stocks                         0.038                 1.000   \n",
              "Length.of.current.employment                -0.032                 0.116   \n",
              "Instalment.per.cent                         -0.282                 0.038   \n",
              "Duration.in.Current.address                  0.001                 0.145   \n",
              "Age..years.                                  0.052                 0.061   \n",
              "No.of.Credits.at.this.Bank                  -0.041                -0.001   \n",
              "No.of.dependents                             0.021                 0.038   \n",
              "Account.Balance_2                            0.132                -0.028   \n",
              "Account.Balance_3                           -0.117                 0.201   \n",
              "Payment.Status.of.Previous.Credit_2         -0.089                -0.005   \n",
              "Payment.Status.of.Previous.Credit_3          0.050                 0.040   \n",
              "Purpose_2                                   -0.075                -0.053   \n",
              "Purpose_3                                   -0.172                 0.037   \n",
              "Purpose_4                                    0.070                -0.028   \n",
              "Sex...Marital.Status_2                       0.175                 0.042   \n",
              "Sex...Marital.Status_3                      -0.147                -0.021   \n",
              "Guarantors_2                                -0.008                -0.138   \n",
              "Most.valuable.available.asset_2             -0.035                 0.036   \n",
              "Most.valuable.available.asset_3              0.024                -0.008   \n",
              "Most.valuable.available.asset_4              0.314                 0.003   \n",
              "Concurrent.Credits_2                        -0.078                 0.080   \n",
              "Type.of.apartment_2                         -0.155                -0.049   \n",
              "Type.of.apartment_3                          0.248                 0.021   \n",
              "Foreign.Worker_2                             0.034                -0.063   \n",
              "Telephone_2                                  0.285                 0.106   \n",
              "\n",
              "                                     Length.of.current.employment  \\\n",
              "Duration.of.Credit..month.                                  0.058   \n",
              "Credit.Amount                                              -0.032   \n",
              "Value.Savings.Stocks                                        0.116   \n",
              "Length.of.current.employment                                1.000   \n",
              "Instalment.per.cent                                         0.151   \n",
              "Duration.in.Current.address                                 0.242   \n",
              "Age..years.                                                 0.300   \n",
              "No.of.Credits.at.this.Bank                                  0.085   \n",
              "No.of.dependents                                            0.085   \n",
              "Account.Balance_2                                          -0.104   \n",
              "Account.Balance_3                                           0.083   \n",
              "Payment.Status.of.Previous.Credit_2                        -0.118   \n",
              "Payment.Status.of.Previous.Credit_3                         0.134   \n",
              "Purpose_2                                                  -0.109   \n",
              "Purpose_3                                                   0.091   \n",
              "Purpose_4                                                  -0.046   \n",
              "Sex...Marital.Status_2                                      0.229   \n",
              "Sex...Marital.Status_3                                     -0.108   \n",
              "Guarantors_2                                               -0.026   \n",
              "Most.valuable.available.asset_2                            -0.009   \n",
              "Most.valuable.available.asset_3                            -0.008   \n",
              "Most.valuable.available.asset_4                             0.135   \n",
              "Concurrent.Credits_2                                       -0.019   \n",
              "Type.of.apartment_2                                        -0.065   \n",
              "Type.of.apartment_3                                         0.176   \n",
              "Foreign.Worker_2                                           -0.038   \n",
              "Telephone_2                                                 0.066   \n",
              "\n",
              "                                     Instalment.per.cent  \\\n",
              "Duration.of.Credit..month.                         0.088   \n",
              "Credit.Amount                                     -0.282   \n",
              "Value.Savings.Stocks                               0.038   \n",
              "Length.of.current.employment                       0.151   \n",
              "Instalment.per.cent                                1.000   \n",
              "Duration.in.Current.address                        0.090   \n",
              "Age..years.                                        0.053   \n",
              "No.of.Credits.at.this.Bank                         0.050   \n",
              "No.of.dependents                                  -0.114   \n",
              "Account.Balance_2                                 -0.082   \n",
              "Account.Balance_3                                  0.071   \n",
              "Payment.Status.of.Previous.Credit_2               -0.046   \n",
              "Payment.Status.of.Previous.Credit_3                0.042   \n",
              "Purpose_2                                         -0.091   \n",
              "Purpose_3                                          0.188   \n",
              "Purpose_4                                         -0.065   \n",
              "Sex...Marital.Status_2                             0.116   \n",
              "Sex...Marital.Status_3                             0.050   \n",
              "Guarantors_2                                       0.015   \n",
              "Most.valuable.available.asset_2                   -0.041   \n",
              "Most.valuable.available.asset_3                    0.046   \n",
              "Most.valuable.available.asset_4                    0.053   \n",
              "Concurrent.Credits_2                               0.036   \n",
              "Type.of.apartment_2                                0.015   \n",
              "Type.of.apartment_3                                0.054   \n",
              "Foreign.Worker_2                                  -0.127   \n",
              "Telephone_2                                        0.035   \n",
              "\n",
              "                                     Duration.in.Current.address  Age..years.  \\\n",
              "Duration.of.Credit..month.                                 0.037       -0.065   \n",
              "Credit.Amount                                              0.001        0.052   \n",
              "Value.Savings.Stocks                                       0.145        0.061   \n",
              "Length.of.current.employment                               0.242        0.300   \n",
              "Instalment.per.cent                                        0.090        0.053   \n",
              "Duration.in.Current.address                                1.000        0.273   \n",
              "Age..years.                                                0.273        1.000   \n",
              "No.of.Credits.at.this.Bank                                 0.065        0.129   \n",
              "No.of.dependents                                           0.078        0.126   \n",
              "Account.Balance_2                                         -0.071       -0.110   \n",
              "Account.Balance_3                                         -0.032        0.078   \n",
              "Payment.Status.of.Previous.Credit_2                       -0.119       -0.176   \n",
              "Payment.Status.of.Previous.Credit_3                        0.105        0.198   \n",
              "Purpose_2                                                 -0.007       -0.129   \n",
              "Purpose_3                                                 -0.095        0.020   \n",
              "Purpose_4                                                  0.059        0.040   \n",
              "Sex...Marital.Status_2                                     0.047        0.158   \n",
              "Sex...Marital.Status_3                                    -0.089       -0.127   \n",
              "Guarantors_2                                              -0.023       -0.077   \n",
              "Most.valuable.available.asset_2                            0.035       -0.009   \n",
              "Most.valuable.available.asset_3                           -0.059       -0.196   \n",
              "Most.valuable.available.asset_4                            0.197        0.258   \n",
              "Concurrent.Credits_2                                       0.016       -0.047   \n",
              "Type.of.apartment_2                                       -0.346       -0.020   \n",
              "Type.of.apartment_3                                        0.240        0.295   \n",
              "Foreign.Worker_2                                           0.019        0.002   \n",
              "Telephone_2                                                0.057        0.177   \n",
              "\n",
              "                                     No.of.Credits.at.this.Bank  \\\n",
              "Duration.of.Credit..month.                               -0.016   \n",
              "Credit.Amount                                            -0.041   \n",
              "Value.Savings.Stocks                                     -0.001   \n",
              "Length.of.current.employment                              0.085   \n",
              "Instalment.per.cent                                       0.050   \n",
              "Duration.in.Current.address                               0.065   \n",
              "Age..years.                                               0.129   \n",
              "No.of.Credits.at.this.Bank                                1.000   \n",
              "No.of.dependents                                          0.048   \n",
              "Account.Balance_2                                        -0.075   \n",
              "Account.Balance_3                                         0.100   \n",
              "Payment.Status.of.Previous.Credit_2                      -0.608   \n",
              "Payment.Status.of.Previous.Credit_3                       0.612   \n",
              "Purpose_2                                                -0.135   \n",
              "Purpose_3                                                -0.013   \n",
              "Purpose_4                                                 0.079   \n",
              "Sex...Marital.Status_2                                    0.048   \n",
              "Sex...Marital.Status_3                                   -0.056   \n",
              "Guarantors_2                                             -0.071   \n",
              "Most.valuable.available.asset_2                          -0.038   \n",
              "Most.valuable.available.asset_3                           0.033   \n",
              "Most.valuable.available.asset_4                           0.007   \n",
              "Concurrent.Credits_2                                      0.017   \n",
              "Type.of.apartment_2                                       0.048   \n",
              "Type.of.apartment_3                                       0.016   \n",
              "Foreign.Worker_2                                         -0.049   \n",
              "Telephone_2                                              -0.014   \n",
              "\n",
              "                                     No.of.dependents  Account.Balance_2  \\\n",
              "Duration.of.Credit..month.                     -0.053              0.067   \n",
              "Credit.Amount                                   0.021              0.132   \n",
              "Value.Savings.Stocks                            0.038             -0.028   \n",
              "Length.of.current.employment                    0.085             -0.104   \n",
              "Instalment.per.cent                            -0.114             -0.082   \n",
              "Duration.in.Current.address                     0.078             -0.071   \n",
              "Age..years.                                     0.126             -0.110   \n",
              "No.of.Credits.at.this.Bank                      0.048             -0.075   \n",
              "No.of.dependents                                1.000             -0.061   \n",
              "Account.Balance_2                              -0.061              1.000   \n",
              "Account.Balance_3                              -0.016             -0.612   \n",
              "Payment.Status.of.Previous.Credit_2            -0.047              0.028   \n",
              "Payment.Status.of.Previous.Credit_3             0.029             -0.058   \n",
              "Purpose_2                                      -0.098             -0.061   \n",
              "Purpose_3                                      -0.069              0.028   \n",
              "Purpose_4                                       0.114              0.073   \n",
              "Sex...Marital.Status_2                          0.248             -0.063   \n",
              "Sex...Marital.Status_3                         -0.099              0.081   \n",
              "Guarantors_2                                    0.013              0.066   \n",
              "Most.valuable.available.asset_2                -0.004             -0.074   \n",
              "Most.valuable.available.asset_3                -0.096             -0.004   \n",
              "Most.valuable.available.asset_4                 0.144              0.036   \n",
              "Concurrent.Credits_2                           -0.064             -0.026   \n",
              "Type.of.apartment_2                            -0.064             -0.019   \n",
              "Type.of.apartment_3                             0.202             -0.013   \n",
              "Foreign.Worker_2                                0.049             -0.023   \n",
              "Telephone_2                                    -0.031              0.030   \n",
              "\n",
              "                                     Account.Balance_3  \\\n",
              "Duration.of.Credit..month.                      -0.095   \n",
              "Credit.Amount                                   -0.117   \n",
              "Value.Savings.Stocks                             0.201   \n",
              "Length.of.current.employment                     0.083   \n",
              "Instalment.per.cent                              0.071   \n",
              "Duration.in.Current.address                     -0.032   \n",
              "Age..years.                                      0.078   \n",
              "No.of.Credits.at.this.Bank                       0.100   \n",
              "No.of.dependents                                -0.016   \n",
              "Account.Balance_2                               -0.612   \n",
              "Account.Balance_3                                1.000   \n",
              "Payment.Status.of.Previous.Credit_2             -0.043   \n",
              "Payment.Status.of.Previous.Credit_3              0.155   \n",
              "Purpose_2                                       -0.017   \n",
              "Purpose_3                                        0.096   \n",
              "Purpose_4                                       -0.129   \n",
              "Sex...Marital.Status_2                           0.028   \n",
              "Sex...Marital.Status_3                          -0.065   \n",
              "Guarantors_2                                    -0.128   \n",
              "Most.valuable.available.asset_2                 -0.013   \n",
              "Most.valuable.available.asset_3                  0.071   \n",
              "Most.valuable.available.asset_4                 -0.059   \n",
              "Concurrent.Credits_2                             0.089   \n",
              "Type.of.apartment_2                              0.126   \n",
              "Type.of.apartment_3                             -0.017   \n",
              "Foreign.Worker_2                                -0.091   \n",
              "Telephone_2                                     -0.001   \n",
              "\n",
              "                                     Payment.Status.of.Previous.Credit_2  \\\n",
              "Duration.of.Credit..month.                                        -0.104   \n",
              "Credit.Amount                                                     -0.089   \n",
              "Value.Savings.Stocks                                              -0.005   \n",
              "Length.of.current.employment                                      -0.118   \n",
              "Instalment.per.cent                                               -0.046   \n",
              "Duration.in.Current.address                                       -0.119   \n",
              "Age..years.                                                       -0.176   \n",
              "No.of.Credits.at.this.Bank                                        -0.608   \n",
              "No.of.dependents                                                  -0.047   \n",
              "Account.Balance_2                                                  0.028   \n",
              "Account.Balance_3                                                 -0.043   \n",
              "Payment.Status.of.Previous.Credit_2                                1.000   \n",
              "Payment.Status.of.Previous.Credit_3                               -0.861   \n",
              "Purpose_2                                                          0.075   \n",
              "Purpose_3                                                          0.072   \n",
              "Purpose_4                                                         -0.095   \n",
              "Sex...Marital.Status_2                                            -0.120   \n",
              "Sex...Marital.Status_3                                             0.123   \n",
              "Guarantors_2                                                       0.089   \n",
              "Most.valuable.available.asset_2                                    0.009   \n",
              "Most.valuable.available.asset_3                                   -0.003   \n",
              "Most.valuable.available.asset_4                                   -0.092   \n",
              "Concurrent.Credits_2                                               0.122   \n",
              "Type.of.apartment_2                                               -0.019   \n",
              "Type.of.apartment_3                                               -0.082   \n",
              "Foreign.Worker_2                                                  -0.039   \n",
              "Telephone_2                                                       -0.063   \n",
              "\n",
              "                                     Payment.Status.of.Previous.Credit_3  \\\n",
              "Duration.of.Credit..month.                                         0.043   \n",
              "Credit.Amount                                                      0.050   \n",
              "Value.Savings.Stocks                                               0.040   \n",
              "Length.of.current.employment                                       0.134   \n",
              "Instalment.per.cent                                                0.042   \n",
              "Duration.in.Current.address                                        0.105   \n",
              "Age..years.                                                        0.198   \n",
              "No.of.Credits.at.this.Bank                                         0.612   \n",
              "No.of.dependents                                                   0.029   \n",
              "Account.Balance_2                                                 -0.058   \n",
              "Account.Balance_3                                                  0.155   \n",
              "Payment.Status.of.Previous.Credit_2                               -0.861   \n",
              "Payment.Status.of.Previous.Credit_3                                1.000   \n",
              "Purpose_2                                                         -0.072   \n",
              "Purpose_3                                                         -0.020   \n",
              "Purpose_4                                                          0.034   \n",
              "Sex...Marital.Status_2                                             0.090   \n",
              "Sex...Marital.Status_3                                            -0.088   \n",
              "Guarantors_2                                                      -0.130   \n",
              "Most.valuable.available.asset_2                                    0.035   \n",
              "Most.valuable.available.asset_3                                   -0.044   \n",
              "Most.valuable.available.asset_4                                    0.066   \n",
              "Concurrent.Credits_2                                               0.018   \n",
              "Type.of.apartment_2                                                0.076   \n",
              "Type.of.apartment_3                                                0.058   \n",
              "Foreign.Worker_2                                                   0.023   \n",
              "Telephone_2                                                        0.070   \n",
              "\n",
              "                                     Purpose_2  Purpose_3  Purpose_4  \\\n",
              "Duration.of.Credit..month.              -0.098     -0.019      0.012   \n",
              "Credit.Amount                           -0.075     -0.172      0.070   \n",
              "Value.Savings.Stocks                    -0.053      0.037     -0.028   \n",
              "Length.of.current.employment            -0.109      0.091     -0.046   \n",
              "Instalment.per.cent                     -0.091      0.188     -0.065   \n",
              "Duration.in.Current.address             -0.007     -0.095      0.059   \n",
              "Age..years.                             -0.129      0.020      0.040   \n",
              "No.of.Credits.at.this.Bank              -0.135     -0.013      0.079   \n",
              "No.of.dependents                        -0.098     -0.069      0.114   \n",
              "Account.Balance_2                       -0.061      0.028      0.073   \n",
              "Account.Balance_3                       -0.017      0.096     -0.129   \n",
              "Payment.Status.of.Previous.Credit_2      0.075      0.072     -0.095   \n",
              "Payment.Status.of.Previous.Credit_3     -0.072     -0.020      0.034   \n",
              "Purpose_2                                1.000     -0.343     -0.349   \n",
              "Purpose_3                               -0.343      1.000     -0.567   \n",
              "Purpose_4                               -0.349     -0.567      1.000   \n",
              "Sex...Marital.Status_2                  -0.058     -0.023      0.017   \n",
              "Sex...Marital.Status_3                  -0.083      0.113     -0.018   \n",
              "Guarantors_2                             0.044      0.018     -0.016   \n",
              "Most.valuable.available.asset_2          0.169     -0.109     -0.013   \n",
              "Most.valuable.available.asset_3         -0.027      0.036     -0.063   \n",
              "Most.valuable.available.asset_4         -0.077      0.009     -0.009   \n",
              "Concurrent.Credits_2                    -0.025      0.072     -0.067   \n",
              "Type.of.apartment_2                      0.003      0.064      0.028   \n",
              "Type.of.apartment_3                     -0.077      0.017     -0.055   \n",
              "Foreign.Worker_2                         0.001     -0.094      0.109   \n",
              "Telephone_2                             -0.061     -0.113      0.095   \n",
              "\n",
              "                                     Sex...Marital.Status_2  \\\n",
              "Duration.of.Credit..month.                            0.157   \n",
              "Credit.Amount                                         0.175   \n",
              "Value.Savings.Stocks                                  0.042   \n",
              "Length.of.current.employment                          0.229   \n",
              "Instalment.per.cent                                   0.116   \n",
              "Duration.in.Current.address                           0.047   \n",
              "Age..years.                                           0.158   \n",
              "No.of.Credits.at.this.Bank                            0.048   \n",
              "No.of.dependents                                      0.248   \n",
              "Account.Balance_2                                    -0.063   \n",
              "Account.Balance_3                                     0.028   \n",
              "Payment.Status.of.Previous.Credit_2                  -0.120   \n",
              "Payment.Status.of.Previous.Credit_3                   0.090   \n",
              "Purpose_2                                            -0.058   \n",
              "Purpose_3                                            -0.023   \n",
              "Purpose_4                                             0.017   \n",
              "Sex...Marital.Status_2                                1.000   \n",
              "Sex...Marital.Status_3                               -0.366   \n",
              "Guarantors_2                                         -0.000   \n",
              "Most.valuable.available.asset_2                      -0.051   \n",
              "Most.valuable.available.asset_3                       0.010   \n",
              "Most.valuable.available.asset_4                       0.162   \n",
              "Concurrent.Credits_2                                 -0.035   \n",
              "Type.of.apartment_2                                   0.090   \n",
              "Type.of.apartment_3                                   0.141   \n",
              "Foreign.Worker_2                                      0.038   \n",
              "Telephone_2                                           0.068   \n",
              "\n",
              "                                     Sex...Marital.Status_3  Guarantors_2  \\\n",
              "Duration.of.Credit..month.                           -0.096         0.011   \n",
              "Credit.Amount                                        -0.147        -0.008   \n",
              "Value.Savings.Stocks                                 -0.021        -0.138   \n",
              "Length.of.current.employment                         -0.108        -0.026   \n",
              "Instalment.per.cent                                   0.050         0.015   \n",
              "Duration.in.Current.address                          -0.089        -0.023   \n",
              "Age..years.                                          -0.127        -0.077   \n",
              "No.of.Credits.at.this.Bank                           -0.056        -0.071   \n",
              "No.of.dependents                                     -0.099         0.013   \n",
              "Account.Balance_2                                     0.081         0.066   \n",
              "Account.Balance_3                                    -0.065        -0.128   \n",
              "Payment.Status.of.Previous.Credit_2                   0.123         0.089   \n",
              "Payment.Status.of.Previous.Credit_3                  -0.088        -0.130   \n",
              "Purpose_2                                            -0.083         0.044   \n",
              "Purpose_3                                             0.113         0.018   \n",
              "Purpose_4                                            -0.018        -0.016   \n",
              "Sex...Marital.Status_2                               -0.366        -0.000   \n",
              "Sex...Marital.Status_3                                1.000         0.085   \n",
              "Guarantors_2                                          0.085         1.000   \n",
              "Most.valuable.available.asset_2                       0.052         0.094   \n",
              "Most.valuable.available.asset_3                      -0.057        -0.116   \n",
              "Most.valuable.available.asset_4                      -0.123         0.026   \n",
              "Concurrent.Credits_2                                  0.040        -0.053   \n",
              "Type.of.apartment_2                                  -0.037        -0.066   \n",
              "Type.of.apartment_3                                  -0.096        -0.042   \n",
              "Foreign.Worker_2                                      0.011         0.175   \n",
              "Telephone_2                                          -0.012        -0.079   \n",
              "\n",
              "                                     Most.valuable.available.asset_2  \\\n",
              "Duration.of.Credit..month.                                    -0.074   \n",
              "Credit.Amount                                                 -0.035   \n",
              "Value.Savings.Stocks                                           0.036   \n",
              "Length.of.current.employment                                  -0.009   \n",
              "Instalment.per.cent                                           -0.041   \n",
              "Duration.in.Current.address                                    0.035   \n",
              "Age..years.                                                   -0.009   \n",
              "No.of.Credits.at.this.Bank                                    -0.038   \n",
              "No.of.dependents                                              -0.004   \n",
              "Account.Balance_2                                             -0.074   \n",
              "Account.Balance_3                                             -0.013   \n",
              "Payment.Status.of.Previous.Credit_2                            0.009   \n",
              "Payment.Status.of.Previous.Credit_3                            0.035   \n",
              "Purpose_2                                                      0.169   \n",
              "Purpose_3                                                     -0.109   \n",
              "Purpose_4                                                     -0.013   \n",
              "Sex...Marital.Status_2                                        -0.051   \n",
              "Sex...Marital.Status_3                                         0.052   \n",
              "Guarantors_2                                                   0.094   \n",
              "Most.valuable.available.asset_2                                1.000   \n",
              "Most.valuable.available.asset_3                               -0.374   \n",
              "Most.valuable.available.asset_4                               -0.210   \n",
              "Concurrent.Credits_2                                           0.017   \n",
              "Type.of.apartment_2                                            0.041   \n",
              "Type.of.apartment_3                                           -0.159   \n",
              "Foreign.Worker_2                                               0.128   \n",
              "Telephone_2                                                   -0.045   \n",
              "\n",
              "                                     Most.valuable.available.asset_3  \\\n",
              "Duration.of.Credit..month.                                     0.100   \n",
              "Credit.Amount                                                  0.024   \n",
              "Value.Savings.Stocks                                          -0.008   \n",
              "Length.of.current.employment                                  -0.008   \n",
              "Instalment.per.cent                                            0.046   \n",
              "Duration.in.Current.address                                   -0.059   \n",
              "Age..years.                                                   -0.196   \n",
              "No.of.Credits.at.this.Bank                                     0.033   \n",
              "No.of.dependents                                              -0.096   \n",
              "Account.Balance_2                                             -0.004   \n",
              "Account.Balance_3                                              0.071   \n",
              "Payment.Status.of.Previous.Credit_2                           -0.003   \n",
              "Payment.Status.of.Previous.Credit_3                           -0.044   \n",
              "Purpose_2                                                     -0.027   \n",
              "Purpose_3                                                      0.036   \n",
              "Purpose_4                                                     -0.063   \n",
              "Sex...Marital.Status_2                                         0.010   \n",
              "Sex...Marital.Status_3                                        -0.057   \n",
              "Guarantors_2                                                  -0.116   \n",
              "Most.valuable.available.asset_2                               -0.374   \n",
              "Most.valuable.available.asset_3                                1.000   \n",
              "Most.valuable.available.asset_4                               -0.319   \n",
              "Concurrent.Credits_2                                          -0.015   \n",
              "Type.of.apartment_2                                            0.170   \n",
              "Type.of.apartment_3                                           -0.265   \n",
              "Foreign.Worker_2                                              -0.118   \n",
              "Telephone_2                                                    0.042   \n",
              "\n",
              "                                     Most.valuable.available.asset_4  \\\n",
              "Duration.of.Credit..month.                                     0.240   \n",
              "Credit.Amount                                                  0.314   \n",
              "Value.Savings.Stocks                                           0.003   \n",
              "Length.of.current.employment                                   0.135   \n",
              "Instalment.per.cent                                            0.053   \n",
              "Duration.in.Current.address                                    0.197   \n",
              "Age..years.                                                    0.258   \n",
              "No.of.Credits.at.this.Bank                                     0.007   \n",
              "No.of.dependents                                               0.144   \n",
              "Account.Balance_2                                              0.036   \n",
              "Account.Balance_3                                             -0.059   \n",
              "Payment.Status.of.Previous.Credit_2                           -0.092   \n",
              "Payment.Status.of.Previous.Credit_3                            0.066   \n",
              "Purpose_2                                                     -0.077   \n",
              "Purpose_3                                                      0.009   \n",
              "Purpose_4                                                     -0.009   \n",
              "Sex...Marital.Status_2                                         0.162   \n",
              "Sex...Marital.Status_3                                        -0.123   \n",
              "Guarantors_2                                                   0.026   \n",
              "Most.valuable.available.asset_2                               -0.210   \n",
              "Most.valuable.available.asset_3                               -0.319   \n",
              "Most.valuable.available.asset_4                                1.000   \n",
              "Concurrent.Credits_2                                          -0.083   \n",
              "Type.of.apartment_2                                           -0.454   \n",
              "Type.of.apartment_3                                            0.813   \n",
              "Foreign.Worker_2                                              -0.079   \n",
              "Telephone_2                                                    0.157   \n",
              "\n",
              "                                     Concurrent.Credits_2  \\\n",
              "Duration.of.Credit..month.                         -0.045   \n",
              "Credit.Amount                                      -0.078   \n",
              "Value.Savings.Stocks                                0.080   \n",
              "Length.of.current.employment                       -0.019   \n",
              "Instalment.per.cent                                 0.036   \n",
              "Duration.in.Current.address                         0.016   \n",
              "Age..years.                                        -0.047   \n",
              "No.of.Credits.at.this.Bank                          0.017   \n",
              "No.of.dependents                                   -0.064   \n",
              "Account.Balance_2                                  -0.026   \n",
              "Account.Balance_3                                   0.089   \n",
              "Payment.Status.of.Previous.Credit_2                 0.122   \n",
              "Payment.Status.of.Previous.Credit_3                 0.018   \n",
              "Purpose_2                                          -0.025   \n",
              "Purpose_3                                           0.072   \n",
              "Purpose_4                                          -0.067   \n",
              "Sex...Marital.Status_2                             -0.035   \n",
              "Sex...Marital.Status_3                              0.040   \n",
              "Guarantors_2                                       -0.053   \n",
              "Most.valuable.available.asset_2                     0.017   \n",
              "Most.valuable.available.asset_3                    -0.015   \n",
              "Most.valuable.available.asset_4                    -0.083   \n",
              "Concurrent.Credits_2                                1.000   \n",
              "Type.of.apartment_2                                 0.003   \n",
              "Type.of.apartment_3                                -0.086   \n",
              "Foreign.Worker_2                                   -0.036   \n",
              "Telephone_2                                         0.018   \n",
              "\n",
              "                                     Type.of.apartment_2  Type.of.apartment_3  \\\n",
              "Duration.of.Credit..month.                        -0.110                0.200   \n",
              "Credit.Amount                                     -0.155                0.248   \n",
              "Value.Savings.Stocks                              -0.049                0.021   \n",
              "Length.of.current.employment                      -0.065                0.176   \n",
              "Instalment.per.cent                                0.015                0.054   \n",
              "Duration.in.Current.address                       -0.346                0.240   \n",
              "Age..years.                                       -0.020                0.295   \n",
              "No.of.Credits.at.this.Bank                         0.048                0.016   \n",
              "No.of.dependents                                  -0.064                0.202   \n",
              "Account.Balance_2                                 -0.019               -0.013   \n",
              "Account.Balance_3                                  0.126               -0.017   \n",
              "Payment.Status.of.Previous.Credit_2               -0.019               -0.082   \n",
              "Payment.Status.of.Previous.Credit_3                0.076                0.058   \n",
              "Purpose_2                                          0.003               -0.077   \n",
              "Purpose_3                                          0.064                0.017   \n",
              "Purpose_4                                          0.028               -0.055   \n",
              "Sex...Marital.Status_2                             0.090                0.141   \n",
              "Sex...Marital.Status_3                            -0.037               -0.096   \n",
              "Guarantors_2                                      -0.066               -0.042   \n",
              "Most.valuable.available.asset_2                    0.041               -0.159   \n",
              "Most.valuable.available.asset_3                    0.170               -0.265   \n",
              "Most.valuable.available.asset_4                   -0.454                0.813   \n",
              "Concurrent.Credits_2                               0.003               -0.086   \n",
              "Type.of.apartment_2                                1.000               -0.550   \n",
              "Type.of.apartment_3                               -0.550                1.000   \n",
              "Foreign.Worker_2                                  -0.002               -0.066   \n",
              "Telephone_2                                       -0.048                0.119   \n",
              "\n",
              "                                     Foreign.Worker_2  Telephone_2  \n",
              "Duration.of.Credit..month.                     -0.107        0.143  \n",
              "Credit.Amount                                   0.034        0.285  \n",
              "Value.Savings.Stocks                           -0.063        0.106  \n",
              "Length.of.current.employment                   -0.038        0.066  \n",
              "Instalment.per.cent                            -0.127        0.035  \n",
              "Duration.in.Current.address                     0.019        0.057  \n",
              "Age..years.                                     0.002        0.177  \n",
              "No.of.Credits.at.this.Bank                     -0.049       -0.014  \n",
              "No.of.dependents                                0.049       -0.031  \n",
              "Account.Balance_2                              -0.023        0.030  \n",
              "Account.Balance_3                              -0.091       -0.001  \n",
              "Payment.Status.of.Previous.Credit_2            -0.039       -0.063  \n",
              "Payment.Status.of.Previous.Credit_3             0.023        0.070  \n",
              "Purpose_2                                       0.001       -0.061  \n",
              "Purpose_3                                      -0.094       -0.113  \n",
              "Purpose_4                                       0.109        0.095  \n",
              "Sex...Marital.Status_2                          0.038        0.068  \n",
              "Sex...Marital.Status_3                          0.011       -0.012  \n",
              "Guarantors_2                                    0.175       -0.079  \n",
              "Most.valuable.available.asset_2                 0.128       -0.045  \n",
              "Most.valuable.available.asset_3                -0.118        0.042  \n",
              "Most.valuable.available.asset_4                -0.079        0.157  \n",
              "Concurrent.Credits_2                           -0.036        0.018  \n",
              "Type.of.apartment_2                            -0.002       -0.048  \n",
              "Type.of.apartment_3                            -0.066        0.119  \n",
              "Foreign.Worker_2                                1.000       -0.040  \n",
              "Telephone_2                                    -0.040        1.000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92baab89-65c3-4219-9a7c-17e894bd4b7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration.of.Credit..month.</th>\n",
              "      <th>Credit.Amount</th>\n",
              "      <th>Value.Savings.Stocks</th>\n",
              "      <th>Length.of.current.employment</th>\n",
              "      <th>Instalment.per.cent</th>\n",
              "      <th>Duration.in.Current.address</th>\n",
              "      <th>Age..years.</th>\n",
              "      <th>No.of.Credits.at.this.Bank</th>\n",
              "      <th>No.of.dependents</th>\n",
              "      <th>Account.Balance_2</th>\n",
              "      <th>Account.Balance_3</th>\n",
              "      <th>Payment.Status.of.Previous.Credit_2</th>\n",
              "      <th>Payment.Status.of.Previous.Credit_3</th>\n",
              "      <th>Purpose_2</th>\n",
              "      <th>Purpose_3</th>\n",
              "      <th>Purpose_4</th>\n",
              "      <th>Sex...Marital.Status_2</th>\n",
              "      <th>Sex...Marital.Status_3</th>\n",
              "      <th>Guarantors_2</th>\n",
              "      <th>Most.valuable.available.asset_2</th>\n",
              "      <th>Most.valuable.available.asset_3</th>\n",
              "      <th>Most.valuable.available.asset_4</th>\n",
              "      <th>Concurrent.Credits_2</th>\n",
              "      <th>Type.of.apartment_2</th>\n",
              "      <th>Type.of.apartment_3</th>\n",
              "      <th>Foreign.Worker_2</th>\n",
              "      <th>Telephone_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Duration.of.Credit..month.</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.037</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>0.067</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>-0.104</td>\n",
              "      <td>0.043</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.157</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.074</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.240</td>\n",
              "      <td>-0.045</td>\n",
              "      <td>-0.110</td>\n",
              "      <td>0.200</td>\n",
              "      <td>-0.107</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Credit.Amount</th>\n",
              "      <td>0.577</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.038</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.052</td>\n",
              "      <td>-0.041</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.132</td>\n",
              "      <td>-0.117</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>-0.172</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.175</td>\n",
              "      <td>-0.147</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.314</td>\n",
              "      <td>-0.078</td>\n",
              "      <td>-0.155</td>\n",
              "      <td>0.248</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Value.Savings.Stocks</th>\n",
              "      <td>0.023</td>\n",
              "      <td>0.038</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.061</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.038</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.201</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.040</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>0.037</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.042</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>-0.138</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.080</td>\n",
              "      <td>-0.049</td>\n",
              "      <td>0.021</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>0.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Length.of.current.employment</th>\n",
              "      <td>0.058</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.116</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.151</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.085</td>\n",
              "      <td>-0.104</td>\n",
              "      <td>0.083</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>0.134</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>0.091</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.229</td>\n",
              "      <td>-0.108</td>\n",
              "      <td>-0.026</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.135</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>0.176</td>\n",
              "      <td>-0.038</td>\n",
              "      <td>0.066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Instalment.per.cent</th>\n",
              "      <td>0.088</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.151</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-0.114</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.071</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.042</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>0.188</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.015</td>\n",
              "      <td>-0.041</td>\n",
              "      <td>0.046</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.054</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>0.035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Duration.in.Current.address</th>\n",
              "      <td>0.037</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.090</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.273</td>\n",
              "      <td>0.065</td>\n",
              "      <td>0.078</td>\n",
              "      <td>-0.071</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>-0.119</td>\n",
              "      <td>0.105</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.047</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.059</td>\n",
              "      <td>0.197</td>\n",
              "      <td>0.016</td>\n",
              "      <td>-0.346</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age..years.</th>\n",
              "      <td>-0.065</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.273</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.129</td>\n",
              "      <td>0.126</td>\n",
              "      <td>-0.110</td>\n",
              "      <td>0.078</td>\n",
              "      <td>-0.176</td>\n",
              "      <td>0.198</td>\n",
              "      <td>-0.129</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.158</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>0.258</td>\n",
              "      <td>-0.047</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.295</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>No.of.Credits.at.this.Bank</th>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.041</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.065</td>\n",
              "      <td>0.129</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.048</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>0.100</td>\n",
              "      <td>-0.608</td>\n",
              "      <td>0.612</td>\n",
              "      <td>-0.135</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.048</td>\n",
              "      <td>-0.056</td>\n",
              "      <td>-0.071</td>\n",
              "      <td>-0.038</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.016</td>\n",
              "      <td>-0.049</td>\n",
              "      <td>-0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>No.of.dependents</th>\n",
              "      <td>-0.053</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.085</td>\n",
              "      <td>-0.114</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.126</td>\n",
              "      <td>0.048</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.061</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.047</td>\n",
              "      <td>0.029</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.069</td>\n",
              "      <td>0.114</td>\n",
              "      <td>0.248</td>\n",
              "      <td>-0.099</td>\n",
              "      <td>0.013</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>0.144</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>0.202</td>\n",
              "      <td>0.049</td>\n",
              "      <td>-0.031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Account.Balance_2</th>\n",
              "      <td>0.067</td>\n",
              "      <td>0.132</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>-0.104</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>-0.071</td>\n",
              "      <td>-0.110</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>-0.061</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.612</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.061</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.073</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>0.081</td>\n",
              "      <td>0.066</td>\n",
              "      <td>-0.074</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-0.026</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Account.Balance_3</th>\n",
              "      <td>-0.095</td>\n",
              "      <td>-0.117</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.071</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.100</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.612</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.043</td>\n",
              "      <td>0.155</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>0.096</td>\n",
              "      <td>-0.129</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>-0.128</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.071</td>\n",
              "      <td>-0.059</td>\n",
              "      <td>0.089</td>\n",
              "      <td>0.126</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>-0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Payment.Status.of.Previous.Credit_2</th>\n",
              "      <td>-0.104</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>-0.119</td>\n",
              "      <td>-0.176</td>\n",
              "      <td>-0.608</td>\n",
              "      <td>-0.047</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.043</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.861</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>-0.120</td>\n",
              "      <td>0.123</td>\n",
              "      <td>0.089</td>\n",
              "      <td>0.009</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.092</td>\n",
              "      <td>0.122</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>-0.039</td>\n",
              "      <td>-0.063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Payment.Status.of.Previous.Credit_3</th>\n",
              "      <td>0.043</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.105</td>\n",
              "      <td>0.198</td>\n",
              "      <td>0.612</td>\n",
              "      <td>0.029</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>0.155</td>\n",
              "      <td>-0.861</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.090</td>\n",
              "      <td>-0.088</td>\n",
              "      <td>-0.130</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Purpose_2</th>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>-0.129</td>\n",
              "      <td>-0.135</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.061</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>0.075</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>-0.349</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.169</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>-0.025</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Purpose_3</th>\n",
              "      <td>-0.019</td>\n",
              "      <td>-0.172</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.091</td>\n",
              "      <td>0.188</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>0.020</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.069</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.567</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.018</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.017</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>-0.113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Purpose_4</th>\n",
              "      <td>0.012</td>\n",
              "      <td>0.070</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.114</td>\n",
              "      <td>0.073</td>\n",
              "      <td>-0.129</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.349</td>\n",
              "      <td>-0.567</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.017</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>-0.067</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>0.109</td>\n",
              "      <td>0.095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex...Marital.Status_2</th>\n",
              "      <td>0.157</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.229</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.047</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.248</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.120</td>\n",
              "      <td>0.090</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.017</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.051</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.162</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex...Marital.Status_3</th>\n",
              "      <td>-0.096</td>\n",
              "      <td>-0.147</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>-0.108</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>-0.056</td>\n",
              "      <td>-0.099</td>\n",
              "      <td>0.081</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>0.123</td>\n",
              "      <td>-0.088</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>0.113</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.052</td>\n",
              "      <td>-0.057</td>\n",
              "      <td>-0.123</td>\n",
              "      <td>0.040</td>\n",
              "      <td>-0.037</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Guarantors_2</th>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>-0.138</td>\n",
              "      <td>-0.026</td>\n",
              "      <td>0.015</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>-0.071</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.066</td>\n",
              "      <td>-0.128</td>\n",
              "      <td>0.089</td>\n",
              "      <td>-0.130</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.018</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.085</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.094</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>0.026</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>-0.042</td>\n",
              "      <td>0.175</td>\n",
              "      <td>-0.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Most.valuable.available.asset_2</th>\n",
              "      <td>-0.074</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>-0.041</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>-0.038</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-0.074</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.169</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.051</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.094</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>-0.210</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.041</td>\n",
              "      <td>-0.159</td>\n",
              "      <td>0.128</td>\n",
              "      <td>-0.045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Most.valuable.available.asset_3</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.024</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.059</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>0.033</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>0.071</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>0.010</td>\n",
              "      <td>-0.057</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.319</td>\n",
              "      <td>-0.015</td>\n",
              "      <td>0.170</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>0.042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Most.valuable.available.asset_4</th>\n",
              "      <td>0.240</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.197</td>\n",
              "      <td>0.258</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-0.059</td>\n",
              "      <td>-0.092</td>\n",
              "      <td>0.066</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>0.009</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.162</td>\n",
              "      <td>-0.123</td>\n",
              "      <td>0.026</td>\n",
              "      <td>-0.210</td>\n",
              "      <td>-0.319</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>-0.454</td>\n",
              "      <td>0.813</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>0.157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Concurrent.Credits_2</th>\n",
              "      <td>-0.045</td>\n",
              "      <td>-0.078</td>\n",
              "      <td>0.080</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.016</td>\n",
              "      <td>-0.047</td>\n",
              "      <td>0.017</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-0.026</td>\n",
              "      <td>0.089</td>\n",
              "      <td>0.122</td>\n",
              "      <td>0.018</td>\n",
              "      <td>-0.025</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.067</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>0.040</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>0.017</td>\n",
              "      <td>-0.015</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.086</td>\n",
              "      <td>-0.036</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Type.of.apartment_2</th>\n",
              "      <td>-0.110</td>\n",
              "      <td>-0.155</td>\n",
              "      <td>-0.049</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>0.015</td>\n",
              "      <td>-0.346</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.048</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>0.126</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.090</td>\n",
              "      <td>-0.037</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.170</td>\n",
              "      <td>-0.454</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.550</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>-0.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Type.of.apartment_3</th>\n",
              "      <td>0.200</td>\n",
              "      <td>0.248</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.176</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.295</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.202</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.058</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>0.017</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>0.141</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>-0.042</td>\n",
              "      <td>-0.159</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>0.813</td>\n",
              "      <td>-0.086</td>\n",
              "      <td>-0.550</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>0.119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foreign.Worker_2</th>\n",
              "      <td>-0.107</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>-0.038</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.002</td>\n",
              "      <td>-0.049</td>\n",
              "      <td>0.049</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>-0.039</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>0.109</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.128</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>-0.036</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Telephone_2</th>\n",
              "      <td>0.143</td>\n",
              "      <td>0.285</td>\n",
              "      <td>0.106</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.177</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>-0.031</td>\n",
              "      <td>0.030</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>0.070</td>\n",
              "      <td>-0.061</td>\n",
              "      <td>-0.113</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.068</td>\n",
              "      <td>-0.012</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>-0.045</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.157</td>\n",
              "      <td>0.018</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>0.119</td>\n",
              "      <td>-0.040</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92baab89-65c3-4219-9a7c-17e894bd4b7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92baab89-65c3-4219-9a7c-17e894bd4b7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92baab89-65c3-4219-9a7c-17e894bd4b7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "HEf3bTwLETuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize =(20, 12))\n",
        "sns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1,annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "ZwAHBUmEEWWh",
        "outputId": "d4c06adb-fc29-4d7e-a632-33e62a798d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f13388615e0>"
            ]
          },
          "metadata": {},
          "execution_count": 309
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1CCpXt9LEhW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}